---
title: "Feature engineering"
author: "Prof. Maria Tackett"
date: "2022-10-03"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— Week 06](https://sta210-fa22.netlify.app/weeks/week-06.html)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
execute:
  freeze: auto
  echo: true
  warning: false
  message: false
knitr:
  opts_chunk: 
    R.options:      
    width: 200
---

```{r setup}
#| include: false

library(countdown)

knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = 0.618,
  fig.retina = 3,
  dpi = 300,
  fig.align = "center"
)
```

## Announcements

[Click here](https://sakai.duke.edu/access/content/group/e6f58eb4-029a-4130-bfa3-e5555d967a43/ARC_Presentation_STATS210.pptx) for slides from presentation about the Academic Resource Center.

## Topics

-   Understanding categorical predictors and interaction terms

-   Feature engineering

## Computational setup

```{r}
#| echo: true

# load packages
library(tidyverse)
library(tidymodels)
library(openintro)
library(patchwork)
library(knitr)
library(kableExtra)
library(colorblindr)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_bw(base_size = 20))
```

# Types of predictors

## Data: Peer-to-peer lender

Today's data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the `loan50` data frame in the **openintro** R package.

```{r}
#| echo: false
loan50 |>
  select(annual_income, debt_to_income, verified_income, interest_rate)
```

## Variables

**Predictors**:

::: nonincremental
-   `annual_income`: Annual income
-   `debt_to_income`: Debt-to-income ratio, i.e. the percentage of a borrower's total debt divided by their total income
-   `verified_income`: Whether borrower's income source and amount have been verified (`Not Verified`, `Source Verified`, `Verified`)
:::

**Outcome**: `interest_rate`: Interest rate for the loan

## Outcome: `interest_rate`

```{r}
#| echo: false
ggplot(loan50, aes(x = interest_rate)) +
  geom_density(fill = "steelblue") +
  labs(title = "Distribution of interest rate")
```

```{r}
#| echo: false
loan50 |>
  summarise(
    min = min(interest_rate),
    median = median(interest_rate),
    max = max(interest_rate),
    iqr = IQR(interest_rate)
  ) |>
  kable()
```

## Predictors {.small}

```{r}
#| echo: false
#| out.width: "100%"
p1 <- ggplot(loan50, aes(y = verified_income)) +
  geom_bar() +
  labs(title = "Verified Income", 
       y = "")

p2 <- ggplot(loan50, aes(x = debt_to_income)) +
  geom_histogram(binwidth = 0.25) +
  labs(title = "",
       x = "Debt to income ratio")

p3 <- ggplot(loan50, aes(x = annual_income)) +
  geom_histogram(binwidth = 20000) +
  labs(title = "",
       x = "Annual income")

p1 + p2 / p3
```

## Data manipulation 1: Rescale income

```{r}
#| echo: true

loan50 <- loan50 |>
  mutate(annual_income_th = annual_income / 1000)

ggplot(loan50, aes(x = annual_income_th)) +
  geom_histogram(binwidth = 20) +
  labs(title = "Annual income (in $1000s)", 
       x = "")
```

## Data manipulation 2: Mean-center numeric predictors

```{r}
#| echo: true
loan50 <- loan50 |>
  mutate(
    debt_inc_cent = debt_to_income - mean(debt_to_income), 
    annual_income_th_cent = annual_income_th - mean(annual_income_th)
    )
```

## Data manipulation 3: Create indicator variables for `verified_income`

```{r}
#| echo: true

loan50 <- loan50 |>
  mutate(
    not_verified = if_else(verified_income == "Not Verified", 1, 0),
    source_verified = if_else(verified_income == "Source Verified", 1, 0),
    verified = if_else(verified_income == "Verified", 1, 0)
  )
```

## Interest rate vs. annual income

The lines are not parallel indicating there is an **interaction effect**. The slope of annual income differs based on the income verification.

```{r}
#| echo: false

p1 <- ggplot(loan50, 
             aes(x = annual_income_th, y = interest_rate)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Annual income (in $1000s)",
    y = "Interest rate"
  )

p2 <- ggplot(loan50, 
             aes(x = annual_income_th, y = interest_rate,
                 color = verified_income)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Annual income (in $1000s)", y = NULL, color = NULL) +
  theme(legend.position = c(0.6, 0.9)) +
  scale_color_OkabeIto()

p1 + p2 +
  plot_annotation(title = "Interest rate vs. annual income")
```

## Data manipulation 4: Create interaction variables {.smaller}

Defining the interaction variable in the model formula as `verified_income * annual_income_th_cent` is an implicit data manipulation step as well

```{r}
#| echo: false
library(hardhat)

framed <- model_frame(interest_rate ~ debt_inc_cent  +  debt_inc_cent + annual_income_th_cent + verified_income * annual_income_th_cent, data = loan50)

model_matrix(framed$terms, framed$data) |>
  glimpse()
```

## Interaction term in the model {.midi}

```{r}
#| echo: true
int_cent_int_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(interest_rate ~ debt_inc_cent  +  verified_income + 
        annual_income_th_cent + verified_income * annual_income_th_cent,
      data = loan50)
```

```{r}
#| echo: false
tidy(int_cent_int_fit) |>
  kable(digits = 3) |>
  row_spec(c(6,7), background = "#dce5b2")
```

## Interpreting interaction terms

-   What the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.
-   Interpreting `annual_income` for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant.

## Understanding the model {.midi}

$$
\begin{aligned}
\hat{interest\_rate} &= 9.484 + 0.691 \times debt\_inc\_cent\\ &- 0.007 \times annual\_income\_th\_cent \\ &+ 2.157 \times SourceVerified + 7.181 \times Verified \\ &- 0.016 \times annual\_inc\_th\_cent \times SourceVerified\\ &- 0.032 \times annual\_inc\_th\_cent \times Verified
\end{aligned}
$$

::: question
1.  What is $p$, the number of predictor terms in the model?
2.  Write the equation of the model to predict interest rate for applicants with *Not Verified* income.
3.  Write the equation of the model to predict interest rate for applicants with *Verified* income.
:::

# Feature engineering

## Topics

::: nonincremental
-   Review: Training and testing splits
-   Feature engineering with recipes
:::

## Computational setup

```{r}
#| echo: true

# load packages
library(tidyverse)
library(tidymodels)
library(gghighlight)
library(knitr)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))
```

# Introduction

## The Office

![](images/11/the-office.jpeg){fig-alt="Photo of the main characters from the television show \"The Office\"" fig-align="center"}

## Data

The data come from [data.world](https://data.world/anujjain7/the-office-imdb-ratings-dataset), by way of [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-03-17/readme.md)

```{r}
#| echo: true

office_ratings <- read_csv("data/office_ratings.csv")
office_ratings
```

## IMDB ratings

```{r}
#| echo: false
#| 
ggplot(office_ratings, aes(x = imdb_rating)) +
  geom_histogram(binwidth = 0.25) +
  labs(
    title = "The Office ratings",
    x = "IMDB rating"
  )
```

## IMDB ratings vs. number of votes

```{r}
#| fig.asp: 0.5
#| echo: false
office_ratings |>
  mutate(season = as_factor(season)) |>
  ggplot(aes(x = total_votes, y = imdb_rating, color = season)) +
  geom_jitter(alpha = 0.7) +
  labs(
    title = "The Office ratings",
    x = "Total votes",
    y = "IMDB rating",
    color = "Season"
  ) +
  theme(legend.position = c(0.9, 0.5)) +
  scale_color_viridis_d()
```

## Outliers

```{r}
#| fig.asp: 0.5
#| echo: false
ggplot(office_ratings, aes(x = total_votes, y = imdb_rating)) +
  geom_jitter() +
  gghighlight(total_votes > 4000, label_key = title) +
  labs(
    title = "The Office ratings",
    x = "Total votes",
    y = "IMDB rating"
  )
```

## IMDB ratings vs. air date

```{r}
#| echo: false
office_ratings |>
  mutate(season = as_factor(season)) |>
  ggplot(aes(x = air_date, y = imdb_rating, 
             color = season, size = total_votes)) +
  geom_point() +
  labs(x = "Air date", y = "IMDB rating",
       title = "The Office Ratings",
       size = "Total votes") +
  scale_color_viridis_d()
```

## IMDB ratings vs. seasons

```{r}
#| echo: false
office_ratings |>
  mutate(season = as_factor(season)) |>
  ggplot(aes(x = season, y = imdb_rating, color = season)) +
  geom_boxplot() +
  geom_jitter() +
  guides(color = "none") +
  labs(
    title = "The Office ratings",
    x = "Season",
    y = "IMDB rating"
  ) +
  scale_color_viridis_d()
```

# Modeling

## Spending our data

-   There are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.

-   Doing all of this on the entire data we have available leaves us with no other data to assess our choices

-   We can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we've done so far)

## Train / test

**Step 1:** Create an initial split:

```{r}
#| echo: true

set.seed(123)
office_split <- initial_split(office_ratings) # prop = 3/4 by default
```

. . .

<br>

**Step 2:** Save training data

```{r}
#| echo: true

office_train <- training(office_split)
dim(office_train)
```

. . .

<br>

**Step 3:** Save testing data

```{r}
#| echo: true

office_test  <- testing(office_split)
dim(office_test)
```

## Training data

```{r}
#| echo: true

office_train
```

## Feature engineering

-   We prefer simple (parsimonious) models when possible, but **parsimony** does not mean sacrificing accuracy (or predictive performance) in the interest of simplicity

-   Variables that go into the model and how they are represented are just as critical to success of the model

-   **Feature engineering** allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance)

## Feature engineering with dplyr

```{r}
#| echo: false
options(dplyr.print_max = 6, dplyr.print_min = 6)
```

```{r}
#| echo: true

office_train |>
  mutate(
    season = as_factor(season),
    month = lubridate::month(air_date),
    wday = lubridate::wday(air_date)
  )
```

. . .

::: question
Can you identify any potential problems with this approach?
:::

```{r}
#| echo: false
options(dplyr.print_max = 10, dplyr.print_min = 10)
```

## Modeling workflow

::: columns
::: {.column width="70%"}
-   Create a **recipe** for feature engineering steps to be applied to the training data

-   Fit the model to the training data after these steps have been applied

-   Using the model estimates from the training data, predict outcomes for the test data

-   Evaluate the performance of the model on the test data
:::

::: {.column width="30%"}
![](images/11/recipes.png){width="100%"}
:::
:::

# Building recipes

## Initiate a recipe

```{r}
#| echo: true
#| code-line-numbers: "|2|3"

office_rec <- recipe(
  imdb_rating ~ .,    # formula
  data = office_train # data for cataloging names and types of variables
  )

office_rec
```

## Step 1: Alter roles

`title` isn't a predictor, but we might want to keep it around as an ID

```{r}
#| echo: true
#| code-line-numbers: "|2"

office_rec <- office_rec |>
  update_role(title, new_role = "ID")

office_rec
```

## Step 2: Add features

New features for day of week and month

```{r}
#| echo: true
#| code-line-numbers: "|2"

office_rec <- office_rec |>
  step_date(air_date, features = c("dow", "month"))

office_rec
```

## Step 3: Add more features {.midi}

Identify holidays in `air_date`, then remove `air_date`

```{r}
#| echo: true
#| code-line-numbers: "|2,3,4,5,6"

office_rec <- office_rec |>
  step_holiday(
    air_date, 
    holidays = c("USThanksgivingDay", "USChristmasDay", "USNewYearsDay", "USIndependenceDay"), 
    keep_original_cols = FALSE
  )

office_rec
```

## Step 4: Convert numbers to factors {.midi}

Convert `season` to factor

```{r}
#| echo: true
#| code-line-numbers: "|2"

office_rec <- office_rec |>
  step_num2factor(season, levels = as.character(1:9))

office_rec
```

## Step 5: Make dummy variables {.midi}

Convert all nominal (categorical) predictors to factors

```{r}
#| echo: true
#| code-line-numbers: "|2"

office_rec <- office_rec |>
  step_dummy(all_nominal_predictors())

office_rec
```

## Step 6: Remove zero variance predictors {.midi}

Remove all predictors that contain only a single value

```{r}
#| echo: true
#| code-line-numbers: "|2"

office_rec <- office_rec |>
  step_zv(all_predictors())

office_rec
```

## Putting it all together {.small}

```{r}
#| label: recipe-altogether
#| echo: true
#| results: hide

office_rec <- recipe(imdb_rating ~ ., data = office_train) |>
  # make title's role ID
  update_role(title, new_role = "ID") |>
  # extract day of week and month of air_date
  step_date(air_date, features = c("dow", "month")) |>
  # identify holidays and add indicators
  step_holiday(
    air_date, 
    holidays = c("USThanksgivingDay", "USChristmasDay", "USNewYearsDay", "USIndependenceDay"), 
    keep_original_cols = FALSE
  ) |>
  # turn season into factor
  step_num2factor(season, levels = as.character(1:9)) |>
  # make dummy variables
  step_dummy(all_nominal_predictors()) |>
  # remove zero variance predictors
  step_zv(all_predictors())
```

## Putting it all together

```{r}
#| echo: true

office_rec
```

## Next step... {.midi}

We will complete the workflow to fit a model predicting IMDB ratings that includes the following predictors:

-   `episode`
-   `total_votes`
-   indicator variables for `season`
-   indicator variables for day of week aired (created using `air_date`)
-   indicator variables for month aired (created using `air_date`)

. . .

::: question
What feature will not end up in the final model? Why is it not included?
:::

## Recap

::: nonincremental
-   Review: Training and testing splits
-   Feature engineering with recipes
:::
