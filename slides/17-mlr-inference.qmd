---
title: "MLR Inference"
author: "Prof. Maria Tackett"
date: "2022-10-26"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— Week 09](https://sta210-fa22.netlify.app/weeks/week-09.html)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
execute:
  freeze: auto
  echo: true
  warning: false
  message: false
knitr:
  opts_chunk: 
    R.options:      
    width: 200
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 10, fig.asp = 0.618, out.width = "90%",
  fig.retina = 3, dpi = 300, fig.align = "center"
)

library(countdown)
```

## Announcements

-   See Gradescope for feedback on project topic ideas.

    -   Read comments carefully. Even if a data set is marked "usable", there may be suggestions about extensive data cleaning required to make it appropriate for the project.
    -   Attend office hours or talk with TAs in lab if you have questions.

-   See [Week 09](https://sta210-fa22.netlify.app/weeks/week-09.html) activities.

## Topics

-   Conduct a hypothesis test for $\beta_j$

-   Calculate a confidence interval for $\beta_j$

-   Inference pitfalls

## Computational setup

```{r}
#| warning: false

# load packages
library(tidyverse)
library(tidymodels)
library(knitr)      # for tables
library(patchwork)  # for laying out plots
library(rms)        # for vif

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_bw(base_size = 20))
```

## Modeling workflow

-   Split data into training and test sets.

-   Use cross validation on the training set to fit, evaluate, and compare candidate models. Choose a final model based on summary of cross validation results.

-   Refit the model using the entire training set and do "final" evaluation on the test set (make sure you have not overfit the model).

    -   Adjust as needed if there is evidence of overfit.

-   Use model fit on training set for inference and prediction.

## Data: `rail_trail` {.smaller}

::: nonincremental
-   The Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005.
-   Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.
:::

```{r}
#| echo: false
rail_trail <- read_csv(here::here("slides", "data/rail_trail.csv"))
rail_trail
```

Source: [Pioneer Valley Planning Commission](http://www.fvgreenway.org/pdfs/Northampton-Bikepath-Volume-Counts%20_05_LTA.pdf) via the **mosaicData** package.

## Variables {.smaller}

**Outcome**:

`volume` estimated number of trail users that day (number of breaks recorded)

. . .

**Predictors**

::: nonincremental
-   `hightemp` daily high temperature (in degrees Fahrenheit)
-   `avgtemp` average of daily low and daily high temperature (in degrees Fahrenheit)
-   `season` one of "Fall", "Spring", or "Summer"
-   `cloudcover` measure of cloud cover (in oktas)
-   `precip` measure of precipitation (in inches)
-   `day_type` one of "weekday" or "weekend"
:::

# Conduct a hypothesis test for $\beta_j$

## Review: Simple linear regression (SLR)

```{r}
ggplot(rail_trail, aes(x = hightemp, y = volume)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "High temp (F)", y = "Number of riders")
```

## SLR model summary

```{r}
rt_slr_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(volume ~ hightemp, data = rail_trail)

tidy(rt_slr_fit) |> kable()
```

## SLR hypothesis test {.midi}

```{r}
#| echo: false

tidy(rt_slr_fit) |> kable(digits = 2)
```

1.  **Set hypotheses:** $H_0: \beta_1 = 0$ vs. $H_A: \beta_1 \ne 0$

. . .

2.  **Calculate test statistic and p-value:** The test statistic is $t= 6.72$ . The p-value is calculated using a $t$ distribution with 88 degrees of freedom. The p-value is $\approx 0$ .

. . .

3.  **State the conclusion:** The p-value is small, so we reject $H_0$. The data provide strong evidence that high temperature is a helpful predictor for the number of daily riders, i.e. there is a linear relationship between high temperature and number of daily riders.

## Multiple linear regression

```{r}
rt_mlr_main_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(volume ~ hightemp + season, data = rail_trail)

tidy(rt_mlr_main_fit) |> kable(digits = 2)
```

## MLR hypothesis test: hightemp {.midi}

1.  **Set hypotheses:** $H_0: \beta_{hightemp} = 0$ vs. $H_A: \beta_{hightemp} \ne 0$, given `season` is in the model

. . .

2.  **Calculate test statistic and p-value:** The test statistic is $t = 6.43$. The p-value is calculated using a $t$ distribution with 86 (n - p - 1) degrees of freedom. The p-value is $\approx 0$.

. . .

3.  **State the conclusion:** The p-value is small, so we reject $H_0$. The data provide strong evidence that high temperature for the day is a useful predictor in a model that already contains the season as a predictor for number of daily riders.

## The model for `season = Spring` {.smaller}

```{r}
#| echo: false

tidy(rt_mlr_main_fit) |> kable(digits = 2)
```

<br>

. . .

$$
\begin{aligned}
\widehat{volume} &= -125.23 + 7.54 \times \texttt{hightemp} + 5.13 \times \texttt{seasonSpring} - 76.84 \times \texttt{seasonSummer} \\
&= -125.23 + 7.54 \times \texttt{hightemp} + 5.13 \times 1 - 76.84 \times 0 \\
&= -120.10 + 7.54 \times \texttt{hightemp}
\end{aligned}
$$

## The model for `season = Summer` {.smaller}

```{r}
#| echo: false

tidy(rt_mlr_main_fit) |> kable(digits = 2)
```

<br>

. . .

$$
\begin{aligned}
\widehat{volume} &= -125.23 + 7.54 \times \texttt{hightemp} + 5.13 \times \texttt{seasonSpring} - 76.84 \times \texttt{seasonSummer} \\
&= -125.23 + 7.54 \times \texttt{hightemp} + 5.13 \times 0 - 76.84 \times 1 \\
&= -202.07 + 7.54 \times \texttt{hightemp}
\end{aligned}
$$

## The model for `season = Fall` {.smaller}

```{r}
#| echo: false

tidy(rt_mlr_main_fit) |> kable(digits = 2)
```

<br>

. . .

$$
\begin{aligned}
\widehat{volume} &= -125.23 + 7.54 \times \texttt{hightemp} + 5.13 \times \texttt{seasonSpring} - 76.84 \times \texttt{seasonSummer} \\
&= -125.23 + 7.54 \times \texttt{hightemp} + 5.13 \times 0 - 76.84 \times 0 \\
&= -125.23 + 7.54 \times \texttt{hightemp}
\end{aligned}
$$

## The models

Same slope, different intercepts

-   `season = Spring`: $-120.10 + 7.54 \times \texttt{hightemp}$
-   `season = Summer`: $-202.07 + 7.54 \times \texttt{hightemp}$
-   `season = Fall`: $-125.23 + 7.54 \times \texttt{hightemp}$

## Application exercise

::: appex
ðŸ“‹ [AE 11: MLR Inference](../ae/ae-11-mlr-inference.html)
:::

::: question
**Ex 1.** Add an interaction effect between `hightemp` and `season` to the model. Do the data provide evidence of a significant interaction effect? Comment on the significance of the interaction terms.
:::

```{r}
#| echo: false

countdown(minutes = 8)
```

# Confidence interval for $\beta_j$

## Confidence interval for $\beta_j$ {.midi}

-   The $C%$ confidence interval for $\beta_j$ $$\hat{\beta}_j \pm t^* SE(\hat{\beta}_j)$$ where $t^*$ follows a $t$ distribution with $n - p - 1$ degrees of freedom.

-   Generically, we are $C%$ confident that the interval LB to UB contains the population coefficient of $x_j$.

-   In context, we are $C%$ confident that for every one unit increase in $x_j$, we expect $y$ to change by LB to UB units, holding all else constant.

## Confidence interval for $\beta_j$

```{r}
tidy(rt_mlr_main_fit, conf.int = TRUE) |>
  kable(digits= 2)
```

## CI for `hightemp` {.midi}

```{r}
#| echo: false

tidy(rt_mlr_main_fit, conf.int = TRUE) |>
  kable(digits = 2)
```

<br>

We are 95% confident that for every degree Fahrenheit the day is warmer, the number of riders increases by 5.21 to 9.87, on average, holding season constant.

## CI for `seasonSpring` {.midi}

```{r}
#| echo: false

tidy(rt_mlr_main_fit, conf.int = TRUE) |>
  kable(digits = 2)
```

<br>

We are 95% confident that the number of riders on a Spring day is lower by 63.1 to higher by 73.4 compared to a Fall day, on average, holding high temperature for the day constant.

. . .

::: question
Is `season` a significant predictor of the number of riders, after accounting for high temperature?
:::

# Inference pitfalls

## Large sample sizes

::: callout-caution
If the sample size is large enough, the test will likely result in rejecting $H_0: \beta_j = 0$ even $x_j$ has a very small effect on $y$.

::: nonincremental
-   Consider the **practical significance** of the result not just the statistical significance.

-   Use the confidence interval to draw conclusions instead of relying only p-values.
:::
:::

## Small sample sizes

::: callout-caution
If the sample size is small, there may not be enough evidence to reject $H_0: \beta_j=0$.

::: nonincremental
-   When you fail to reject the null hypothesis, **DON'T** immediately conclude that the variable has no association with the response.

-   There may be a linear association that is just not strong enough to detect given your data, or there may be a non-linear association.
:::
:::
