[
  {
    "objectID": "labs/lab-02.html",
    "href": "labs/lab-02.html",
    "title": "Lab 02: Ice duration and air temperature in Madison, WI",
    "section": "",
    "text": "Important\n\n\n\nDue:\n\nMonday, September 19, 11:59pm (Thursday labs)\nTuesday, September 20, 11:59pm (Friday labs)"
  },
  {
    "objectID": "labs/lab-02.html#learning-goals",
    "href": "labs/lab-02.html#learning-goals",
    "title": "Lab 02: Ice duration and air temperature in Madison, WI",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab you willâ€¦\n\nBe able to fit a simple linear regression model using R.\nBe able to interpret the slope and intercept for the model.\nBe able to use simulation-based inference to draw conclusions about the slope.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "labs/lab-03.html",
    "href": "labs/lab-03.html",
    "title": "Coffee grades",
    "section": "",
    "text": "Important\n\n\n\nDue:\n\nMonday, September 26 , 11:59pm (Thursday labs)\nTuesday, September 27, 11:59pm (Friday labs)"
  },
  {
    "objectID": "labs/lab-03.html#learning-goals",
    "href": "labs/lab-03.html#learning-goals",
    "title": "Coffee grades",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab you willâ€¦\n\nbe able to use mathematical models to conduct inference for the slope\nbe able to assess conditions for simple linear regression"
  },
  {
    "objectID": "labs/lab-03.html#packages",
    "href": "labs/lab-03.html#packages",
    "title": "Coffee grades",
    "section": "Packages",
    "text": "Packages\nThe follow packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "labs/lab-03.html#the-data",
    "href": "labs/lab-03.html#the-data",
    "title": "Coffee grades",
    "section": "The Data",
    "text": "The Data\nThe dataset for this lab comes from the Coffee Quality Database and was obtained from the #TidyTuesday GitHub repo. It includes information about the origin, producer, measures of various characteristics, and the quality measure for over 1,000 coffees. The coffees can be reasonably be treated as a random sample.\nThis lab will focus on the following variables:\n\nsweetness: Sweetness grade, 0 (least sweet) - 10 (most sweet)\nflavor: Flavor grade, 0 (worst flavor) - 10 (best flavor)\n\nClick here for the definitions of all variables in the data set. Click here for more details about how these measures are obtained.\n\ncoffee <- read_csv(\"data/coffee-grades.csv\")"
  },
  {
    "objectID": "labs/lab-03.html#grading-50-pts",
    "href": "labs/lab-03.html#grading-50-pts",
    "title": "Coffee grades",
    "section": "Grading (50 pts)",
    "text": "Grading (50 pts)\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n31\n\n\nReproducible report\n22"
  },
  {
    "objectID": "labs/lab-01.html",
    "href": "labs/lab-01.html",
    "title": "Lab 01: Ikea furniture",
    "section": "",
    "text": "Important\n\n\n\nDue:\n\nMonday, September 12, 11:59pm (Thursday labs)\nTuesday, September 13, 11:59pm (Friday labs)"
  },
  {
    "objectID": "labs/lab-01.html#learning-goals",
    "href": "labs/lab-01.html#learning-goals",
    "title": "Lab 01: Ikea furniture",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab, you willâ€¦\n\nBe familiar with the workflow using RStudio and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using GitHub\nBe able to create data visualizations using ggplot2 and use those visualizations to describe distributions\nBe gain to fit, interpret, and evaluate simple linear regression models"
  },
  {
    "objectID": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "href": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "title": "Lab 01: Ikea furniture",
    "section": "Clone the repo & start new RStudio project",
    "text": "Clone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta210-fa22 organization on GitHub. Click on the repo with the prefix lab-01-ikea-. It contains the starter documents you need to complete the lab.\n\n\n\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, youâ€™ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\n\n\n\nIn RStudio, go to File \\(\\rightarrow\\) New Project \\(\\rightarrow\\) Version Control \\(\\rightarrow\\) Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\n\n\n\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab."
  },
  {
    "objectID": "labs/lab-01.html#r-and-r-studio",
    "href": "labs/lab-01.html#r-and-r-studio",
    "title": "Lab 01: Ikea furniture",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of an Quarto (.Rmd) file.\n\n\n\n\n\n\nYAML\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for â€œYAML Ainâ€™t Markup Languageâ€. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.Rmd) file in your project, change the author name to your name, and render the document. Examine the rendered document.\n\n\n\n\nCommitting changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf youâ€™re happy with these changes, weâ€™ll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, â€œupdated author nameâ€) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou donâ€™t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow letâ€™s make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and youâ€™re good to go!\n\n\nPush changes\nNow that you have made an update and committed this change, itâ€™s time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push."
  },
  {
    "objectID": "weeks/week-08.html",
    "href": "weeks/week-08.html",
    "title": "Week 08",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-09.html",
    "href": "weeks/week-09.html",
    "title": "Week 09",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-04.html",
    "href": "weeks/week-04.html",
    "title": "Week 04",
    "section": "",
    "text": "Prepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\nðŸ“– IMS, Sec 24.4: Mathematical model for testing the slope\nðŸ“– IMS, Sec 24.5: Mathematical model, interval for the slope\nðŸ“– IMS, Sec 24.6: Checking model conditions\nðŸ“– IMS, Sec 24.7: Chapter review\nSep 19\n\n\nðŸ“– IMS, Sec 8.2: Many predictors in a model\nSep 21\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\nðŸ’» SLR: Mathematical models for inference\nSep 19\n\n\nðŸ’» SLR: Model conditions\nSep 21\n\n\nðŸ’» Multiple linear regression\nSep 21\n\n\nðŸ’» Lab 03\nSep 22 & 23\n\n\n\n\n\nPractice\n\n\n\n\n\n\nAE 05: Multiple linear regression\n\n\n\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\nðŸ“ HW 01\nWed, Sep 21, 11:59pm\n\n\nðŸ“ Lab 03\nMon, Sep 26, 11:59pm (Thu labs)\nTue, Sep 27, 11:59pm (Fri labs)\n\n\nðŸ“ Statistics experience\nFri, Dec 09, 11:59pm"
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-05.html",
    "href": "weeks/week-05.html",
    "title": "Week 05",
    "section": "",
    "text": "Prepare\nNo readings this week.\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\nðŸ’» MLR: Types of predictors\nSep 26\n\n\nðŸ’» Exam 01 review\nSep 28\n\n\n\n\n\nPractice\n\n\n\n\n\n\nðŸ“‹ AE 06: Prediction for MLR\n\n\nðŸ“‹ AE 07: Exam 01 review\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\nðŸ“ Exam 01\nFri, Sep 30, 11:59pm"
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-07.html",
    "href": "weeks/week-07.html",
    "title": "Week 07",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-06.html",
    "href": "weeks/week-06.html",
    "title": "Week 06",
    "section": "",
    "text": "Prepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\nðŸ“– Tidy Modeling in R - Chapter 8: Feature engineering with recipes\nOct 05\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\nðŸ’» Feature engineering\nOct 03\n\n\nðŸ’» Modeling workflow\nOct 05\n\n\n\n\n\nPractice\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\nðŸ“ Lab 04\nWed, Oct 12, 11:59pm (Thu lab)\nThu, Oct 13, 11:59pm (Fri lab)"
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-16.html",
    "href": "weeks/week-16.html",
    "title": "Week 16",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-02.html",
    "href": "weeks/week-02.html",
    "title": "Week 02",
    "section": "",
    "text": "Prepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\nðŸ“– Introduction to Modern Statistics (IMS), Ch 7: Linear regression with a single predictor\nSep 05 & 07\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\nðŸ’» SLR: Fitting models in R with tidymodels\nSep 05\n\n\nðŸ’» SLR: Prediction + model evaluation\nSep 07\n\n\nðŸ’» Lab 01\nSep 08 & 09\n\n\n\n\n\nPractice\n\n\n\n\n\n\nðŸ“‹ AE 02 - Bike rentals in Washigton, DC\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\nðŸ“ Lab 01\nMon, Sep 12, 11:59pm (Thu labs)\nTue, Sep 13, 11:59pm (Fri labs)\n\n\nðŸ“ Statistics experience\nFri, Dec 09, 11:59pm"
  },
  {
    "objectID": "weeks/week-03.html",
    "href": "weeks/week-03.html",
    "title": "Week 03",
    "section": "",
    "text": "Prepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\nðŸ“– IMS, Sec 24.2: Randomization test for the slope\nSep 12\n\n\nðŸ“– IMS, Sec 24.3: Bootstrap confidence interval for the slope\nðŸ“– IMS, Sec 24.4: Mathematical model for testing the slope\nSep 14\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\nðŸ’» SLR: Simulation-based inference (bootstrap confidence intervals)\nSep 12\n\n\nðŸ’» SLR: Simulation-based inference (hypothesis testing)\nSep 14\n\n\nðŸ’» Lab 02\nSep 15 & 16\n\n\n\n\n\nPractice\n\n\n\n\n\n\nðŸ“‹ AE 03: Bootstrap confidence intervals\n\n\nðŸ“‹ AE 04: Simulation-based hypothesis testing\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\nðŸ“ Lab 02\nMon, Sep 19, 11:59pm (Thu labs)\nTue, Sep 20, 11:59pm (Fri labs)\n\n\nðŸ“ HW 01\nWed, Sep 21, 11:59pm\n\n\nðŸ“ Statistics experience\nFri, Dec 09, 11:59pm"
  },
  {
    "objectID": "weeks/week-01.html",
    "href": "weeks/week-01.html",
    "title": "Week 01",
    "section": "",
    "text": "Participate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\nðŸ’» Welcome to STA 210!\nAug 29\n\n\nðŸ’» Simple Linear Regression\nAug 31\n\n\nðŸ’» Lab 00\nSep 01 & 02\n\n\n\n\n\nPractice\n\n\n\n\n\n\nðŸ“‹ AE 01-Movie Budgets\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\nðŸ“ Complete STA 210 Student Survey\ndue Fri, Sep 02 at 11:59pm\n\n\nðŸ“ Reserve STA 210 RStudio Docker Container\nMon, Sep 05 at the beginning of class"
  },
  {
    "objectID": "weeks/week-15.html",
    "href": "weeks/week-15.html",
    "title": "Week 15",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "weeks/week-14.html",
    "href": "weeks/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Participate\n\n\nPractice\n\n\nPerform"
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Education & median income in US Counties",
    "section": "",
    "text": "In this assignment, youâ€™ll use simple linear regression to examine the association between between the percent of adults with a bachelorâ€™s degree and the median household income for counties in the United States."
  },
  {
    "objectID": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "href": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Part 1: Exploratory data analysis",
    "text": "Part 1: Exploratory data analysis\n\nExercise 1\nCreate a histogram of the distribution of the response variable median_household_income and calculate appropriate summary statistics. Use the visualization and summary statistics to describe the distribution. Include an informative title and axis labels on the plot.\n\n\nExercise 2\nLetâ€™s view the data in another way. Use the code below to make a map of the United States with the color of the counties filled in based on the median household income. Fill in title and axis labels.\nThen use the plot answer the following:\n\nWhat are 2 - 3 observations you have from the map?\nWhat is a feature that is apparent in the map that wasnâ€™t as easily apparent from the histogram in the previous exercise? What is a feature that is apparent in the histogram that is not as easily apparent from the map?\n\n\ncounty_map_data <- left_join(county_data_sample, map_data_sample)\n\nggplot(data = map_data_all) +\n  geom_polygon(aes(x = long, y = lat, group = group),\n    fill = \"lightgray\", color = \"white\"\n    ) +\n  geom_polygon(data = county_map_data, aes(x = long, y = lat, group = group,\n    fill = median_household_income)\n    ) +\n  labs(\n    x = \"___\",\n    y = \"___\",\n    fill = \"___\",\n    title = \"___\"\n  ) +\n  scale_fill_viridis_c(labels = label_dollar()) +\n  coord_quickmap()\n\n\n\nExercise 3\nCreate a visualization of the relationship between bachelors and median_household_income . Use the visualization to describe the relationship between the two variables.\n\nIf you havenâ€™t yet done so, now is a good time to render your document and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-01.html#part-2-modeling",
    "href": "hw/hw-01.html#part-2-modeling",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Part 2: Modeling",
    "text": "Part 2: Modeling\n\nExercise 4\nWe will use a linear regression model to better quantify the relationship between bachelors and median_household_income.\nWrite the form of the statistical model we will use for this task using mathematical notation. Use variable names (bachelors and median_household_income) in the equation for your model1.\n\n\nExercise 5\n\nFit the linear model to understand variability in the median household income based on the percent of adults age 25 and older in the county with a bachelorâ€™s degree. Neatly display the model output with 3 digits.\nWrite the estimated regression equation using mathematical notation. Use variable names (bachelors and median_household_income) in the equation.\n\n\n\nExercise 6\nNow letâ€™s use the model coefficients to describe the relationship between these two variables.\n\nInterpret the slope. The interpretation should be written in a way that is meaningful in the context of the data.\nIs it meaningful to interpret the intercept for this data? If so, write the interpretation in the context of the data. Otherwise, briefly explain why not.\n\n\nNow is a good time to render your document again if you havenâ€™t done so recently and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-01.html#part-3-inference-for-the-u.s.",
    "href": "hw/hw-01.html#part-3-inference-for-the-u.s.",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Part 3: Inference for the U.S.",
    "text": "Part 3: Inference for the U.S.\nWe want to use the data from these 600 randomly selected counties to draw conclusions about the relationship between the percent of adults age 25 and older with a bachelorâ€™s degree and median household income for the over 3,000 counties in the United States.\n\nExercise 7\n\nWhat is the population of interest? What is the sample?\nIs it reasonable to treat the sample in this analysis as representative of the population? Briefly explain why or why not.\n\n\n\nExercise 8\nConduct a hypothesis test for the slope to assess whether there is sufficient evidence of a linear relationship between the percent of adults age 25 and older with a bachelorâ€™s degree and the median household income in a county. Use a randomization (permutation) test. In your response:\n\nState the null and alternative hypotheses in words and mathematical notation\nShow all relevant code and output used to conduct the test. Use set.seed(8).\nState the conclusion in the context of the data.\n\n\n\nExercise 9\nNext, construct a 95% confidence interval for the slope using bootstrapping with set.seed(9). Show all relevant code and output used to calculate the interval. Interpret the confidence interval in the context of the data.\n\n\nExercise 10\nComment on whether the hypothesis test and confidence interval support the general consensus that adults who have a completed a bachelorâ€™s degree generally earn higher income than adults who have not. A brief explanation is sufficient but it should be based on your conclusions from the hypothesis test and confidence interval.\n\nNow is a good time to render your document again if you havenâ€™t done so recently and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-01.html#part-4-model-comparison",
    "href": "hw/hw-01.html#part-4-model-comparison",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Part 4: Model comparison",
    "text": "Part 4: Model comparison\n\nExercise 11\nA researcher suggests that knowing the percentage of households in a county with a computer is a better indicator of median household income than the percentage of adults with a bachelorâ€™s degree.\n\nFit a linear model of the relationship between median_household_income and household_has_computer. Neatly display the model with 3 digits.\nEvaluate this model and the model fit in Exercise 5 to assess the researcherâ€™s claim.\nDo your analysis results support the researcherâ€™s claim? Briefly explain why or why not.\n\n\nBefore submitting, make sure you render your document and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-01.html#submission",
    "href": "hw/hw-01.html#submission",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember â€“ you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials âž¡ï¸ Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and youâ€™ll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be â€œcheckedâ€).\nSelect the first page of your PDF submission to be associated with the â€œWorkflow & formattingâ€ section."
  },
  {
    "objectID": "hw/hw-01.html#grading-50-points",
    "href": "hw/hw-01.html#grading-50-points",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Grading (50 points)",
    "text": "Grading (50 points)\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 11\n47\n\n\nWorkflow & formatting\n32"
  },
  {
    "objectID": "hw/stats-experience.html",
    "href": "hw/stats-experience.html",
    "title": "HW: Statistics Experience",
    "section": "",
    "text": "The world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1ï¸âƒ£ Have a statistics experience\n2ï¸âƒ£ Make a slide summarizing on your experience\nYou must complete both parts to receive credit."
  },
  {
    "objectID": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "HW: Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity youâ€™d like to do but youâ€™re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\nrstudio::conf talks\n\n2022 conference\n2021 conference\n2020 conference\n\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask your professor if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isnâ€™t on this list, ask your professor to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy Oâ€™Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some donâ€™t by Nate Silver\nList of books about data science ethics\n\nThis list is not exhaustive.\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\nâœ… Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\nâœ… The visualization should include features or customization that are beyond what weâ€™ve done in class .\nâœ… Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: Coding out loud\nWatch an episode of Coding out loud (either live or pre-recorded) and work through the project.\nA few guidelines:\nâœ… Create a GitHub repo for your Coding out loud submission. Your repo should include\n\nThe Quarto file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\nâœ… The final product (visualuzation, table, etc.) should include features or customization that are beyond what was achieved in the Coding out loud episode.\nâœ… Include the link to your GitHub repo in the slide summarizing your experience."
  },
  {
    "objectID": "hw/stats-experience.html#part-2-summarize-your-experience",
    "href": "hw/stats-experience.html#part-2-summarize-your-experience",
    "title": "HW: Statistics Experience",
    "section": "Part 2: Summarize your experience",
    "text": "Part 2: Summarize your experience\nMake one slide summarizing your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nName and brief description of the event/podcast/competition/etc.\nSomething you found new, interesting, or unexpected\nHow the event/podcast/competition/etc. connects to something weâ€™ve done in class.\nCitation or link to web page for event/competition/etc.\n\nClick here to see a template to help you get started on your slide. Your slide does not have to follow this exact format; it just needs to include the information mentioned above and be easily readable (i.e.Â use a reasonable font size!). Creativity is encouraged!"
  },
  {
    "objectID": "hw/stats-experience.html#submission",
    "href": "hw/stats-experience.html#submission",
    "title": "HW: Statistics Experience",
    "section": "Submission",
    "text": "Submission\nSubmit the reflection as a PDF under the Statistics Experience assignment on Gradescope by Fri, Dec 09 at 11:59pm. It must be submitted by the deadline on Gradescope to be considered for grading."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html",
    "href": "ae/ae-07-exam-01-review.html",
    "title": "AE 07: Exam 01 review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-07- to get started.\nThe AE is due on GitHub by Saturday, October 01 at 11:59pm."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#packages",
    "href": "ae/ae-07-exam-01-review.html#packages",
    "title": "AE 07: Exam 01 review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#restaurant-tips",
    "href": "ae/ae-07-exam-01-review.html#restaurant-tips",
    "title": "AE 07: Exam 01 review",
    "section": "Restaurant tips",
    "text": "Restaurant tips\nWhat factors are associated with the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St.Â Olaf who worked at a local restaurant.1\nThe variables weâ€™ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\nAlcohol: whether alcohol was purchased with meal\n\nView the data set to see the remaining variables.\n\ntips <- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "href": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "title": "AE 07: Exam 01 review",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\n\nVisualize, summarize, and describe the relationship between Party and Tip.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#modeling",
    "href": "ae/ae-07-exam-01-review.html#modeling",
    "title": "AE 07: Exam 01 review",
    "section": "Modeling",
    "text": "Modeling\nLetâ€™s start by fitting a model using Party to predict the Tip at this restaurant.\n\nWrite the statistical model.\nFit the regression line and write the regression equation. Name the model tips_fit and neatly display the results with 3 digits and the 95% confidence interval for the coefficients.\n\n\n# add your code here\n\n\nInterpret the slope.\nDoes it make sense to interpret the intercept? Explain your reasoning."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference",
    "href": "ae/ae-07-exam-01-review.html#inference",
    "title": "AE 07: Exam 01 review",
    "section": "Inference",
    "text": "Inference\n\nInference for the slope\n\nThe following code can be used to create a bootstrap distribution for the slope (and the intercept, though weâ€™ll focus primarily on the slope in our inference). Describe what each line of code does, supplemented by any visualizations that might help with your description.\n\n\nset.seed(1234)\n\nboot_dist <- tips |>\n  specify(Tip ~ Party) |>\n  generate(reps = 100, type = \"bootstrap\") |>\n  fit()\n\n\nUse the bootstrap distribution created in Exercise 6, boot_dist, to construct a 90% confidence interval for the slope using bootstrapping and the percentile method and interpret it in context of the data.\n\n\n# add your code here\n\n\nConduct a hypothesis test at the equivalent significance level using permutation with 100 reps. State the hypotheses and the significance level youâ€™re using explicitly. Also include a visualization of the null distribution of the slope with the observed slope marked as a vertical line.\n\n\nset.seed(1234)\n# add your code here\n\n\nCheck the relevant conditions for Exercises 7 and 8. Are there any violations in conditions that make you reconsider your inferential findings?\n\n\n# add your code here\n\n\nNow repeat Exercises 7 and 8 using approaches based on mathematical models. You can reference output from previous exercises and/or write new code as needed.\nCheck the relevant conditions for Exercise 10. Are there any violations in conditions that make you reconsider your inferential findings? You can reference previous graphs / conditions and add any new code as needed.\n\n\n# add your code here\n\n\n\nInference for a prediction\n\nBased on your model, predict the tip for a party of 4.\n\n\n# add your code here\n\n\nSuppose youâ€™re asked to construct a confidence and a prediction interval for your finding in the previous exercise. Which one would you expect to be wider and why? In your answer clearly state the difference between these intervals.\nNow construct the intervals and comment on whether your guess is confirmed.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#multiple-linear-regression",
    "href": "ae/ae-07-exam-01-review.html#multiple-linear-regression",
    "title": "AE 07: Exam 01 review",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nMake a plot to visualize the relationship between Party and Tip with the points colored by Alcohol. Describe any patterns that emerge.\n\n\n# add your code here\n\n\nFit a multiple linear regression model predicting Tip from Party and Alcohol. Display the results with kable() and three digits.\n\n\n# add your code here\n\n\nInterpret the coefficients of Party and Alcohol.\nAccording to this model, is the rate of change in tip amount the same for various sizes of parties regardless of alcohol consumption or are they different? Explain your reasoning.\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from todayâ€™s class.\nPush all your work to your ae-07- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-03-bootstrap.html",
    "href": "ae/ae-03-bootstrap.html",
    "title": "AE 03: Bootstrap confidence intervals",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03-bootstrap- to get started.\nThe AE is due on GitHub by Thursday, September 15 at 11:59pm."
  },
  {
    "objectID": "ae/ae-03-bootstrap.html#data",
    "href": "ae/ae-03-bootstrap.html#data",
    "title": "AE 03: Bootstrap confidence intervals",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    <chr> \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durhaâ€¦\n$ price      <dbl> 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, â€¦\n$ bed        <dbl> 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,â€¦\n$ bath       <dbl> 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,â€¦\n$ area       <dbl> 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,â€¦\n$ type       <chr> \"Single Family\", \"Single Family\", \"Single Family\", \"Single â€¦\n$ year_built <dbl> 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,â€¦\n$ heating    <chr> \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat pâ€¦\n$ cooling    <fct> central, central, central, central, central, central, centrâ€¦\n$ parking    <chr> \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Coveredâ€¦\n$ lot        <dbl> 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,â€¦\n$ hoa        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦\n$ url        <chr> \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-â€¦"
  },
  {
    "objectID": "ae/ae-03-bootstrap.html#exploratory-data-analysis",
    "href": "ae/ae-03-bootstrap.html#exploratory-data-analysis",
    "title": "AE 03: Bootstrap confidence intervals",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-03-bootstrap.html#model",
    "href": "ae/ae-03-bootstrap.html#model",
    "title": "AE 03: Bootstrap confidence intervals",
    "section": "Model",
    "text": "Model\n\ndf_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |>\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-03-bootstrap.html#bootstrap-confidence-interval",
    "href": "ae/ae-03-bootstrap.html#bootstrap-confidence-interval",
    "title": "AE 03: Bootstrap confidence intervals",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n\n1. Calculate the observed fit (slope)\n\nobserved_fit <- duke_forest |>\n  specify(price ~ area) |>\n  fit()\n\nobserved_fit\n\n# A tibble: 2 Ã— 2\n  term      estimate\n  <chr>        <dbl>\n1 intercept  116652.\n2 area          159.\n\n\n\n\n2 Take n bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(091222)\n\nboot_fits <- ______ |>\n  specify(______) |>\n  generate(reps = ____, type = \"bootstrap\") |>\n  fit()\n\nboot_fits\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n# Code for histogram\n\n\n\n\n3 Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = _____, \n  level = ____,\n  type = \"percentile\"\n)"
  },
  {
    "objectID": "ae/ae-03-bootstrap.html#changing-confidence-level",
    "href": "ae/ae-03-bootstrap.html#changing-confidence-level",
    "title": "AE 03: Bootstrap confidence intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nModify the code from Step 3 to create a 90% confidence interval.\n\n# Paste code for 90% confidence interval\n\n\n\nModify the code from Step 3 to create a 99% confidence interval.\n\n# Paste code for 90% confidence interval\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from todayâ€™s class.\nPush all your work to your ae-03- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-05-mlr.html",
    "href": "ae/ae-05-mlr.html",
    "title": "AE 05: Multiple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05- to get started.\nThe AE is due on GitHub by Saturday, September 24 at 11:59pm.\nThe data set contains the sales price and characteristics of 85 homes in Levittown, NY that sold between June 2010 and May 2011. Levittown was built right after WWII and was the first planned suburban community built using mass production techniques.\nThe variables used in this analysis are\nThe goal of the analysis is to use the characteristics of a house to understand variability in the sales price."
  },
  {
    "objectID": "ae/ae-05-mlr.html#exploratory-data-analysis",
    "href": "ae/ae-05-mlr.html#exploratory-data-analysis",
    "title": "AE 05: Multiple linear regression",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggpairs(levittown) +\n  theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, size = 10),\n    strip.text.y = element_text(angle = 0, hjust = 0)\n    )"
  },
  {
    "objectID": "ae/ae-05-mlr.html#linear-model",
    "href": "ae/ae-05-mlr.html#linear-model",
    "title": "AE 05: Multiple linear regression",
    "section": "Linear model",
    "text": "Linear model\nFit a linear model of housing prices versus the house characteristics in Levittown. Neatly display model using 3 digits.\n\n# fit model \n\n# display model with 3 digits"
  },
  {
    "objectID": "ae/ae-05-mlr.html#interpretation",
    "href": "ae/ae-05-mlr.html#interpretation",
    "title": "AE 05: Multiple linear regression",
    "section": "Interpretation",
    "text": "Interpretation\n\nInterpret the coefficient of bedrooms in the context of the data.\nThe intercept is the estimated sales price for what subset of houses? Be specific."
  },
  {
    "objectID": "ae/ae-05-mlr.html#prediction",
    "href": "ae/ae-05-mlr.html#prediction",
    "title": "AE 05: Multiple linear regression",
    "section": "Prediction",
    "text": "Prediction\nWhat is the predicted sale price for a house in Levittown, NY with 4 bedrooms, 2 bathrooms, 1,000 square feet of living area, 6,000 square foot lot size, built in 1947 with $7,403 in property taxes?\n\nReport the predicted value and appropriate interval.\n\n\n# create tibble for new observation \n\n# prediction + interval\n\n\nInterpret the interval in the context of the data.\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from todayâ€™s class.\nPush all your work to your ae-05- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-06-prediction.html",
    "href": "ae/ae-06-prediction.html",
    "title": "AE 06: Prediction for MLR",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-06- to get started.\nThe AE is due on GitHub by Thursday, September 29 at 11:59pm.\nThe data set contains the sales price and characteristics of 85 homes in Levittown, NY that sold between June 2010 and May 2011. Levittown was built right after WWII and was the first planned suburban community built using mass production techniques.\nThe variables used in this analysis are\nThe goal of the analysis is to use the characteristics of a house to understand variability in the sales price."
  },
  {
    "objectID": "ae/ae-06-prediction.html#linear-model",
    "href": "ae/ae-06-prediction.html#linear-model",
    "title": "AE 06: Prediction for MLR",
    "section": "Linear model",
    "text": "Linear model\n\nprice_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(sale_price ~ bedrooms + bathrooms + living_area + lot_size +\n        year_built + property_tax, data = levittown)\n\ntidy(price_fit) |>\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-7148818.957\n3820093.694\n-1.871\n0.065\n\n\nbedrooms\n-12291.011\n9346.727\n-1.315\n0.192\n\n\nbathrooms\n51699.236\n13094.170\n3.948\n0.000\n\n\nliving_area\n65.903\n15.979\n4.124\n0.000\n\n\nlot_size\n-0.897\n4.194\n-0.214\n0.831\n\n\nyear_built\n3760.898\n1962.504\n1.916\n0.059\n\n\nproperty_tax\n1.476\n2.832\n0.521\n0.604"
  },
  {
    "objectID": "ae/ae-06-prediction.html#prediction",
    "href": "ae/ae-06-prediction.html#prediction",
    "title": "AE 06: Prediction for MLR",
    "section": "Prediction",
    "text": "Prediction\nWhat is the predicted sale price for an individual house in Levittown, NY with 4 bedrooms, 2 bathrooms, 1,800 square feet of living area, 6,000 square foot lot size, built in 1947 with $7,403 in property taxes?\nReport the predicted value and appropriate interval.\n\n\n\n\n\n\nNote\n\n\n\nFill in the code, then make #| eval: true before rendering the document.\n\n\n\n# create tibble for new observation \nnew_house <- tibble(\n  bedrooms = ____, \n  bathrooms = ____, \n  _____\n  )\n\n# prediction + interval\nprediction(_________)\n\n\nInterpret the interval in the context of the data.\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from todayâ€™s class.\nPush all your work to your ae-06- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-04-sim-testing.html",
    "href": "ae/ae-04-sim-testing.html",
    "title": "AE 04: Simulation-based hypothesis testing",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04-bootstrap- to get started.\nThe AE is due on GitHub by Saturday, September 17 at 11:59pm."
  },
  {
    "objectID": "ae/ae-04-sim-testing.html#data",
    "href": "ae/ae-04-sim-testing.html#data",
    "title": "AE 04: Simulation-based hypothesis testing",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    <chr> \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durhaâ€¦\n$ price      <dbl> 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, â€¦\n$ bed        <dbl> 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,â€¦\n$ bath       <dbl> 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,â€¦\n$ area       <dbl> 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,â€¦\n$ type       <chr> \"Single Family\", \"Single Family\", \"Single Family\", \"Single â€¦\n$ year_built <dbl> 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,â€¦\n$ heating    <chr> \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat pâ€¦\n$ cooling    <fct> central, central, central, central, central, central, centrâ€¦\n$ parking    <chr> \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Coveredâ€¦\n$ lot        <dbl> 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,â€¦\n$ hoa        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦\n$ url        <chr> \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-â€¦"
  },
  {
    "objectID": "ae/ae-04-sim-testing.html#exploratory-data-analysis",
    "href": "ae/ae-04-sim-testing.html#exploratory-data-analysis",
    "title": "AE 04: Simulation-based hypothesis testing",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-04-sim-testing.html#model",
    "href": "ae/ae-04-sim-testing.html#model",
    "title": "AE 04: Simulation-based hypothesis testing",
    "section": "Model",
    "text": "Model\n\ndf_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |>\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-04-sim-testing.html#hypothesis-test",
    "href": "ae/ae-04-sim-testing.html#hypothesis-test",
    "title": "AE 04: Simulation-based hypothesis testing",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\n\n\n\nTip\n\n\n\nFor code chunks with fill-in-the-blank code, change code chunk option to #| eval: true once youâ€™ve filled in the code.\n\n\n\nState the null and alternative hypotheses\n[Add hypotheses in mathematical notation]\n\n\nGenerate null distribution using permutation\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(09142022)\n\nnull_dist <- _____ |>\n  specify(______) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = _____, type = \"permute\") |>\n  fit()\n\n\n\nVisualize distribution\n\n# Code for histogram of null distribution\n\n\n\nCalculate the p-value.\n\n# get observed fit \nobserved_fit <- duke_forest |>\n  specify(price ~ area) |>\n  fit()\n\n# calculate p-value\nget_p_value(\n  ____,\n  obs_stat = ____,\n  direction = \"two-sided\"\n)\n\n\nWhat does the warning message mean?\n\n\n\nState conclusion\n[Write your conclusion in the context of the data.]\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from todayâ€™s class.\nPush all your work to your ae-04- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-01-movies.html",
    "href": "ae/ae-01-movies.html",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "",
    "text": "Important\n\n\n\nThis application exercise is a demo only.\nYou do not have a corresponding repository for it and youâ€™re not expected to turn in anything for it.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB)."
  },
  {
    "objectID": "ae/ae-01-movies.html#data",
    "href": "ae/ae-01-movies.html#data",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies <- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies |>\n  slice(1:10)\n\n# A tibble: 10 Ã— 15\n   name   rating genre  year released score  votes director writer star  country\n   <chr>  <chr>  <chr> <dbl> <chr>    <dbl>  <dbl> <chr>    <chr>  <chr> <chr>  \n 1 The Sâ€¦ R      Drama  1980 June 13â€¦   8.4 9.27e5 Stanleyâ€¦ Stephâ€¦ Jackâ€¦ Unitedâ€¦\n 2 The Bâ€¦ R      Adveâ€¦  1980 July 2,â€¦   5.8 6.5 e4 Randal â€¦ Henryâ€¦ Brooâ€¦ Unitedâ€¦\n 3 Star â€¦ PG     Actiâ€¦  1980 June 20â€¦   8.7 1.2 e6 Irvin Kâ€¦ Leighâ€¦ Markâ€¦ Unitedâ€¦\n 4 Airplâ€¦ PG     Comeâ€¦  1980 July 2,â€¦   7.7 2.21e5 Jim Abrâ€¦ Jim Aâ€¦ Robeâ€¦ Unitedâ€¦\n 5 Caddyâ€¦ R      Comeâ€¦  1980 July 25â€¦   7.3 1.08e5 Harold â€¦ Brianâ€¦ Chevâ€¦ Unitedâ€¦\n 6 Fridaâ€¦ R      Horrâ€¦  1980 May 9, â€¦   6.4 1.23e5 Sean S.â€¦ Victoâ€¦ Betsâ€¦ Unitedâ€¦\n 7 The Bâ€¦ R      Actiâ€¦  1980 June 20â€¦   7.9 1.88e5 John Laâ€¦ Dan Aâ€¦ Johnâ€¦ Unitedâ€¦\n 8 Raginâ€¦ R      Biogâ€¦  1980 Decembeâ€¦   8.2 3.3 e5 Martin â€¦ Jake â€¦ Robeâ€¦ Unitedâ€¦\n 9 Superâ€¦ PG     Actiâ€¦  1980 June 19â€¦   6.8 1.01e5 Richardâ€¦ Jerryâ€¦ Geneâ€¦ Unitedâ€¦\n10 The Lâ€¦ R      Biogâ€¦  1980 May 16,â€¦   7   1   e4 Walter â€¦ Bill â€¦ Daviâ€¦ Unitedâ€¦\n# â€¦ with 4 more variables: budget <dbl>, gross <dbl>, company <chr>,\n#   runtime <dbl>"
  },
  {
    "objectID": "ae/ae-01-movies.html#analysis",
    "href": "ae/ae-01-movies.html#analysis",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Analysis",
    "text": "Analysis\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list <- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\n\nmovies |>\n  filter(genre %in% genre_list) |> \n  group_by(genre,year) |>\n  summarise(avg_gross = mean(gross)) |>\n  ggplot(mapping = aes(x = year, y = avg_gross, color=genre)) +\n    geom_point() + \n    geom_line() +\n    ylab(\"Average Gross Revenue (in US Dollars)\") +\n    ggtitle(\"Gross Revenue Over Time\") +\n    scale_color_viridis_d()\n\n\n\n\nWhat do you observe from the plot?\nNext, letâ€™s see the relationship between a movieâ€™s budget and its gross revenue.\n\nmovies |>\n  filter(genre %in% genre_list, budget > 0) |> \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point() +\n  geom_smooth(method=\"lm\",se=FALSE) + \n  xlab(\"Log-transformed Budget\")+\n  ylab(\"Log-transformed Gross Revenue\") +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d()"
  },
  {
    "objectID": "ae/ae-01-movies.html#exercises",
    "href": "ae/ae-01-movies.html#exercises",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nPost your response on ED Discussion.\n\nSection 001 (10:15am lecture)\nSection 002 (3:30pm lecture)\n\nIn the remaining time, discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)?"
  },
  {
    "objectID": "ae/ae-01-movies.html#references",
    "href": "ae/ae-01-movies.html#references",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "References",
    "text": "References\n\nhttps://github.com/danielgrijalva/movie-stats\nInternet Movie Database"
  },
  {
    "objectID": "ae/ae-01-movies.html#appendix",
    "href": "ae/ae-01-movies.html#appendix",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies |> \n  arrange(genre) |> \n  select(genre) |>\n  distinct() |>\n  datatable()"
  },
  {
    "objectID": "ae/ae-02-bikeshare.html",
    "href": "ae/ae-02-bikeshare.html",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-01-bikehsare to get started.\nThis AE will not be counted as part of the Application Exercises portion of the final course grade."
  },
  {
    "objectID": "ae/ae-02-bikeshare.html#data",
    "href": "ae/ae-02-bikeshare.html#data",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "Data",
    "text": "Data\nOur dataset contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare <- read_csv(\"data/dcbikeshare.csv\")"
  },
  {
    "objectID": "ae/ae-02-bikeshare.html#daily-counts-and-temperature",
    "href": "ae/ae-02-bikeshare.html#daily-counts-and-temperature",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "Daily counts and temperature",
    "text": "Daily counts and temperature\n\nExercise 1\nVisualize the distribution of daily bike rentals and temperature as well as the relationship between these two variables.\n\nggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250)\n\n\n\nggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point()\n\n\n\n\n\n\nExercise 2\nDescribe the distribution of daily bike rentals and the distribution of temperature based on the visualizations created in Exercise 1. Include the shape, center, spread, and presence of any potential outliers.\n[Add your answer here]\n\n\nExercise 3\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day.\n[Add your answer here]\n\n\nExercise 4\nDescribe the relationship between daily bike rentals and temperature based on the visualization created in Exercise 1. Comment on how we expect the number of bike rentals to change as the temperature increases.\n[Add your answer here]\n\n\nExercise 5\nSuppose you want to fit a model so you can use the temperature to predict the number of bike rentals. Would a model of the form\n\\[\\text{count} = \\beta_0 + \\beta_1 ~ \\text{temp\\_orig} + \\epsilon\\]\nbe the best fit for the data? Why or why not?\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-02-bikeshare.html#daily-counts-temperature-and-season",
    "href": "ae/ae-02-bikeshare.html#daily-counts-temperature-and-season",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "Daily counts, temperature, and season",
    "text": "Daily counts, temperature, and season\n\nExercise 6\nIn the raw data, seasons are coded as 1, 2, 3, 4 as numerical values, corresponding to winter, spring, summer, and fall respectively. Recode the season variable to make it a categorical variable (a factor) with levels corresponding to season names, making sure that the levels appear in a reasonable order in the variable (i.e., not alphabetical).\n\n# add code developed during livecoding here\n\n\n\nExercise 7\nNext, letâ€™s look at how the daily bike rentals differ by season. Letâ€™s visualize the distribution of bike rentals by season using density plots. You can think of a density plot as a â€œsmoothed out histogramâ€. Compare and contrast the distributions. Is this what you expected? Why or why not?\n\n# add code developed during livecoding here\n\n[Add your answer here]\n\n\nExercise 8\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, first create a scatter plot of daily bike rentals vs.Â temperature faceted by season.\n\n# add code developed during livecoding here\n\n\n\nExercise 9\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-02-bikeshare.html#modeling",
    "href": "ae/ae-02-bikeshare.html#modeling",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "Modeling",
    "text": "Modeling\n\nExercise 10\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here\n\n\n\nExercise 11\nUsing the data you filtered in Exercise 10, fit a linear model for predicting daily bike rentals from temperature for this season.\n\n# add code developed during livecoding here\n\n\n\nExercise 12\nUse the output to write out the estimated regression equation.\n[Add your answer here]\n\n\nExercise 13\nInterpret the slope in the context of the data.\n[Add your answer here]\n\n\nExercise 14\nInterpret the intercept in the context of the data.\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-02-bikeshare.html#synthesis",
    "href": "ae/ae-02-bikeshare.html#synthesis",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "Synthesis",
    "text": "Synthesis\n\nExercise 15\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2022. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?\n[Add your answer here]\n\nThe following exercises will be completed only if time permits.\n\n\nExercise 16\nPick another season. Based on the visualization in Exercise 8, would you expect the slope of the relationship between temperature and daily bike rentals to be smaller or larger than the slope of the model youâ€™ve been working with so far? Explain your reasoning.\n[Add your answer here]\n\n\nExercise 17\nFor this season you picked in Exercise 16, fit a linear model for predicting daily bike rentals from temperature. Note, you will need to filter your data for this season first. Use the output to write out the estimated regression equation and interpret the slope and the intercept of this model.\n\n# add your code here\n\n[Add your answer here]"
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help."
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyoneâ€™s office hours here."
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g.Â illness, accommodations, etc.), you may email Professor Tackett at maria.tackett@duke.edu. If you email me, please include â€œSTA 210â€ in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a studentâ€™s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. Contact CAPS at (919) 660-1000\nBlue Devils Care. A convenient and cost-effective way for Duke students to receive 24/7 mental health support through TalkNow. Go to bluedevilscare.duke.edu"
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For technology assistance requests, please go here. Please note that supplies are limited.\nNote that we will be using Dukeâ€™s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available."
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-sakai",
    "href": "support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission and discussion will take place on GitHub instead.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "R for Data Science by Hadley Wickham & Garrett Grolemund\nTidy Modeling with R by Max Kuhn & Julia Silge"
  },
  {
    "objectID": "computing-r-resources.html#rstudio-primers",
    "href": "computing-r-resources.html#rstudio-primers",
    "title": "Resources for learning R",
    "section": "RStudio Primers",
    "text": "RStudio Primers\nTutorials most relevant to this course:\n\nThe Basics\nWork with Data\nVisualize Data\nTidy your Data\n\nClick here for full list of tutorials."
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nRStudio Cheatsheets\nR Fun workshops and videos by Duke Center for Data and Visualization Sciences."
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "If this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, youâ€™ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance youâ€™ll use for the course."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 210: Regression Analysis",
    "section": "",
    "text": "Learn approaches for analyzing multivariate data sets, emphasizing analysis of variance, linear regression, and logistic regression. Learn techniques for checking the appropriateness of proposed models, such as residual analyses and case influence diagnostics, and techniques for selecting models. Gain experience dealing with the challenges that arise in practice through assignments that utilize real-world data. This class emphasizes data analysis over mathematical theory."
  },
  {
    "objectID": "index.html#class-meetings",
    "href": "index.html#class-meetings",
    "title": "STA 210: Regression Analysis",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\n\nLecture\nSection 001\nMon & Wed 10:15 - 11:30 am\nReuben-Cooke 130\n\n\n\nSection 002\nMon & Wed 3:30 - 4:45pm\nSocial Sciences 136\n\n\nLab\nLab 01\nThu 3:30 - 4:45pm\nPerkins Link #5\n\n\n\nLab 02\nThu 5:15 - 6:30pm\nPerkins Link #5\n\n\n\nLab 03\nFri 12 - 1:15pm\nPerkins Link #5\n\n\n\nLab 04\nFri 1:45 - 3pm\nOld Chemistry 003"
  },
  {
    "objectID": "index.html#teaching-team",
    "href": "index.html#teaching-team",
    "title": "STA 210: Regression Analysis",
    "section": "Teaching team",
    "text": "Teaching team\n\nInstructor\nMaria Tackett is an Assistant Professor of the Practice in the Department of Statistical Science at Duke University. Her work focuses on understanding how active learning strategies can be used to promote engagement and student motivation in undergraduate statistics courses. She also studies how classroom practices in introductory math and statistics courses impact studentsâ€™ sense of community, self-efficacy, and learning outcomes.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMondays 1 - 2pm\nOld Chem 118B or Zoom\n\n\nThursdays 10 - 11am\nZoom only\n\n\nor by appointment.\n\n\n\n\n\n\nTeaching assistants\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\nCarson Garcia\nTA for Lab 04\nMon 5 - 7pm\nZoom\n\n\nSara Meta\nTA for Lab 04\nFri 10am - 12pm\nZoom\n\n\nMedy Mu\nTue 4 - 6pm\nZoom\n\n\nGlenn Palmer\nHead TA\nTA for Lab 03\nFri 1:25 - 3:25pm\nOld Chemistry 203B\n\n\nBraden Scherting\nTA for Lab 02\nMon 2 - 3pm\nTue 3:15 - 4:15 pm\nOld Chemistry 203B\nOld Chemistry 203B\n\n\nLuke Vrotsos\nTA for Lab 01\nTue 6:30 - 8:30pm\nOld Chemistry 025\n\n\nBen Wallace\nTue 1:30 - 2:30\nFri 9 - 10am\nZoom\nOld Chemistry 203B\n\n\nAaditya Warrier\nWed 1 - 3pm\nZoom\n\n\nGrace Zhao\nTA for Lab 01\nTue 11a - 1pm\nZoom\n\n\n\nClick here for full list of office hours."
  },
  {
    "objectID": "teaching-team.html",
    "href": "teaching-team.html",
    "title": "mysite",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "slides/lab-02.html#reminders",
    "href": "slides/lab-02.html#reminders",
    "title": "Lab 02",
    "section": "Reminders",
    "text": "Reminders\n\n\nSelect the pages corresponding to each exercise when you when you submit the assignment on Gradescope.\n\nClick here for written and video instructions on submitting an assignment and marking pages on Gradescope.\n\nIn your write up:\n\nWrite all narrative in complete sentences.\nInclude an informative title and axis labels on graphs.\nWrite responses in the context of the data.\nDescribe distribution using shape, center, spread, and potential outliers. Describe relationships between variables using strength, direction, and shape."
  },
  {
    "objectID": "slides/lab-02.html#axis-labels-and-titles",
    "href": "slides/lab-02.html#axis-labels-and-titles",
    "title": "Lab 02",
    "section": "Axis labels and titles",
    "text": "Axis labels and titles\n\nBelow is a graph of association between flipper length in millimeters and body mass in grams of three species of penguins in Palmer Station, Antarctica. What are informative title and axis labels for this graph?"
  },
  {
    "objectID": "slides/lab-02.html#code-style",
    "href": "slides/lab-02.html#code-style",
    "title": "Lab 02",
    "section": "Code style",
    "text": "Code style\nWhich code chunk would you rather read?\n\n# code chunk 1\npenguins|>filter(!is.na(flipper_length_mm))|>group_by(species)|>summarise(min=min(flipper_length_mm),mean=mean(flipper_length_mm),sd=sd(flipper_length_mm),max=max(flipper_length_mm),n=n())\n\n\n\n\n# code chunk 2\npenguins |> \n  filter(!is.na(flipper_length_mm)) |> \n  group_by(species) |> \n  summarise(min = min(flipper_length_mm), \n            mean = mean(flipper_length_mm), \n            max = max(flipper_length_mm),\n            n = n())"
  },
  {
    "objectID": "slides/lab-02.html#code-style-contd",
    "href": "slides/lab-02.html#code-style-contd",
    "title": "Lab 02",
    "section": "Code style contâ€™d",
    "text": "Code style contâ€™d\nMake code easier to read and debug by\n\nPutting each element on a different line (start a new line after + and |>)\nPutting spaces before and after operators (+, -, *, =, |> )\nIn general, avoiding long lines of code, i.e.Â lines longer than 120 characters.\n\nSee the Tidyverse Style Guide for more tips on code styling."
  },
  {
    "objectID": "slides/lab-02.html#todays-lab",
    "href": "slides/lab-02.html#todays-lab",
    "title": "Lab 02",
    "section": "Todayâ€™s lab",
    "text": "Todayâ€™s lab\n\nRemember to use a reproducible workflow with regular commits (and informative commit messages).\n\nPush all update files after each commit!\n\nUse lectures and AEs from Week 02 and Week 03 as reference as you complete the lab.\n\n\n\n\n\nðŸ”— Week 03"
  },
  {
    "objectID": "slides/lab-03.html#reminders",
    "href": "slides/lab-03.html#reminders",
    "title": "Lab 03",
    "section": "Reminders",
    "text": "Reminders\nMake sure to do the following as you complete the assignment:\n\nWrite all narrative in complete sentences.\nUse informative axis titles and labels on all graphs.\nImplement version control in your reproducible workflow.\n\nThroughout the assignment periodically render your Quarto document to produce the updated PDF, commit the changes in the Git pane, and push the updated files to GitHub.\nBenchmark: Push changes to GitHub at least three times as you work on the assignment."
  },
  {
    "objectID": "slides/lab-03.html#todays-lab",
    "href": "slides/lab-03.html#todays-lab",
    "title": "Lab 03",
    "section": "Todayâ€™s lab",
    "text": "Todayâ€™s lab\n\nFocused on mathematical inference for simple linear regression and checking model conditions.\nRemember to mark all pages in your Gradescope submission. The first page should be marked for the â€œWorkflow & formattingâ€ and â€œReproducible reportâ€ sections.\nUse lectures and AEs from Week 04 as reference as you complete the lab.\n\n\n\n\n\nðŸ”— Week 04"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#announcements",
    "href": "slides/12-feature-engineering-pt2.html#announcements",
    "title": "Feature engineering",
    "section": "Announcements",
    "text": "Announcements\n\nClick here for slides from presentation about the Academic Resource Center.\nGroup labs start this week\nClick here for Week 06 activities."
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#topics",
    "href": "slides/12-feature-engineering-pt2.html#topics",
    "title": "Feature engineering",
    "section": "Topics",
    "text": "Topics\n\n\nFeature engineering with recipes\nWorkflows to bring together models and recipes\nRMSE and \\(R^2\\) for model evaluation on training and tests sets"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#computational-setup",
    "href": "slides/12-feature-engineering-pt2.html#computational-setup",
    "title": "Feature engineering",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gghighlight)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#the-office",
    "href": "slides/12-feature-engineering-pt2.html#the-office",
    "title": "Feature engineering",
    "section": "The Office",
    "text": "The Office"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#data-goal",
    "href": "slides/12-feature-engineering-pt2.html#data-goal",
    "title": "Feature engineering",
    "section": "Data & goal",
    "text": "Data & goal\n\nData: The data come from data.world, by way of TidyTuesday\nGoal: Predict imdb_rating from other variables in the dataset\n\n\n\n# A tibble: 188 Ã— 6\n   season episode title             imdb_rating total_votes air_date  \n    <dbl>   <dbl> <chr>                   <dbl>       <dbl> <date>    \n 1      1       1 Pilot                     7.6        3706 2005-03-24\n 2      1       2 Diversity Day             8.3        3566 2005-03-29\n 3      1       3 Health Care               7.9        2983 2005-04-05\n 4      1       4 The Alliance              8.1        2886 2005-04-12\n 5      1       5 Basketball                8.4        3179 2005-04-19\n 6      1       6 Hot Girl                  7.8        2852 2005-04-26\n 7      2       1 The Dundies               8.7        3213 2005-09-20\n 8      2       2 Sexual Harassment         8.2        2736 2005-09-27\n 9      2       3 Office Olympics           8.4        2742 2005-10-04\n10      2       4 The Fire                  8.4        2713 2005-10-11\n# â€¦ with 178 more rows"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#train-test",
    "href": "slides/12-feature-engineering-pt2.html#train-test",
    "title": "Feature engineering",
    "section": "Train / test",
    "text": "Train / test\nStep 1: Create an initial split:\n\nset.seed(123)\noffice_split <- initial_split(office_ratings) # prop = 3/4 by default\n\nStep 2: Save training data\n\noffice_train <- training(office_split)\ndim(office_train)\n\n[1] 141   6\n\n\nStep 3: Save testing data\n\noffice_test  <- testing(office_split)\ndim(office_test)\n\n[1] 47  6"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#training-data",
    "href": "slides/12-feature-engineering-pt2.html#training-data",
    "title": "Feature engineering",
    "section": "Training data",
    "text": "Training data\n\noffice_train\n\n# A tibble: 141 Ã— 6\n   season episode title               imdb_rating total_votes air_date  \n    <dbl>   <dbl> <chr>                     <dbl>       <dbl> <date>    \n 1      8      18 Last Day in Florida         7.8        1429 2012-03-08\n 2      9      14 Vandalism                   7.6        1402 2013-01-31\n 3      2       8 Performance Review          8.2        2416 2005-11-15\n 4      9       5 Here Comes Treble           7.1        1515 2012-10-25\n 5      3      22 Beach Games                 9.1        2783 2007-05-10\n 6      7       1 Nepotism                    8.4        1897 2010-09-23\n 7      3      15 Phyllis' Wedding            8.3        2283 2007-02-08\n 8      9      21 Livin' the Dream            8.9        2041 2013-05-02\n 9      9      18 Promos                      8          1445 2013-04-04\n10      8      12 Pool Party                  8          1612 2012-01-19\n# â€¦ with 131 more rows"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#recap-feature-engineering",
    "href": "slides/12-feature-engineering-pt2.html#recap-feature-engineering",
    "title": "Feature engineering",
    "section": "Recap: Feature engineering",
    "text": "Recap: Feature engineering\n\nWe prefer simple (parsimonious) models when possible, but parsimony does not mean sacrificing accuracy (or predictive performance) in the interest of simplicity\nVariables that go into the model and how they are represented are just as critical to success of the model\nFeature engineering allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance)"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#recap-modeling-workflow-revisited",
    "href": "slides/12-feature-engineering-pt2.html#recap-modeling-workflow-revisited",
    "title": "Feature engineering",
    "section": "Recap: Modeling workflow, revisited",
    "text": "Recap: Modeling workflow, revisited\n\nCreate a recipe for feature engineering steps to be applied to the training data\nFit the model to the training data after these steps have been applied\nUsing the model estimates from the training data, predict outcomes for the test data\nEvaluate the performance of the model on the test data"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#initiate-a-recipe",
    "href": "slides/12-feature-engineering-pt2.html#initiate-a-recipe",
    "title": "Feature engineering",
    "section": "Initiate a recipe",
    "text": "Initiate a recipe\n\noffice_rec <- recipe(\n  imdb_rating ~ .,    # formula\n  data = office_train # data for cataloguing names and types of variables\n  )\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          5"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-1-alter-roles",
    "href": "slides/12-feature-engineering-pt2.html#step-1-alter-roles",
    "title": "Feature engineering",
    "section": "Step 1: Alter roles",
    "text": "Step 1: Alter roles\ntitle isnâ€™t a predictor, but we might want to keep it around as an ID\n\noffice_rec <- office_rec |>\n  update_role(title, new_role = \"ID\")\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-2-add-features",
    "href": "slides/12-feature-engineering-pt2.html#step-2-add-features",
    "title": "Feature engineering",
    "section": "Step 2: Add features",
    "text": "Step 2: Add features\nNew features for day of week and month\n\noffice_rec <- office_rec |>\n  step_date(air_date, features = c(\"dow\", \"month\"))\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#working-with-recipes",
    "href": "slides/12-feature-engineering-pt2.html#working-with-recipes",
    "title": "Feature engineering",
    "section": "Working with recipes",
    "text": "Working with recipes\n\nWhen building recipes you in a pipeline, you donâ€™t get to see the effect of the recipe on your data, which can be unsettling\nYou can take a peek at what will happen when you ultimately apply the recipe to your data at the time of fitting the model\nThis requires two functions: prep() to train the recipe and bake() to apply it to your data\n\n\n\n\n\n\n\n\nNote\n\n\nThis is optional, weâ€™ll show the results for demonstrative purposes. It doesnâ€™t need to be part of your modeling pipeline, but it can be assuring to see the effects of the recipe steps as you build the recipe."
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-2-prep-and-bake",
    "href": "slides/12-feature-engineering-pt2.html#step-2-prep-and-bake",
    "title": "Feature engineering",
    "section": "Step 2: Prep and bake",
    "text": "Step 2: Prep and bake\n\n# determine required parameters to be estimated\noffice_rec_trained <- prep(office_rec)\n\n# apply recipe computations to data\nbake(office_rec_trained, office_train) |>\n  glimpse()\n\nRows: 141\nColumns: 8\n$ season         <dbl> 8, 9, 2, 9, 3, 7, 3, 9, 9, 8, 5, 5, 9, 6, 7, 6, 5, 2, 2â€¦\n$ episode        <dbl> 18, 14, 8, 5, 22, 1, 15, 21, 18, 12, 25, 26, 12, 1, 20,â€¦\n$ title          <fct> \"Last Day in Florida\", \"Vandalism\", \"Performance Reviewâ€¦\n$ total_votes    <dbl> 1429, 1402, 2416, 1515, 2783, 1897, 2283, 2041, 1445, 1â€¦\n$ air_date       <date> 2012-03-08, 2013-01-31, 2005-11-15, 2012-10-25, 2007-0â€¦\n$ imdb_rating    <dbl> 7.8, 7.6, 8.2, 7.1, 9.1, 8.4, 8.3, 8.9, 8.0, 8.0, 8.7, â€¦\n$ air_date_dow   <fct> Thu, Thu, Tue, Thu, Thu, Thu, Thu, Thu, Thu, Thu, Thu, â€¦\n$ air_date_month <fct> Mar, Jan, Nov, Oct, May, Sep, Feb, May, Apr, Jan, May, â€¦"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-3-add-more-features",
    "href": "slides/12-feature-engineering-pt2.html#step-3-add-more-features",
    "title": "Feature engineering",
    "section": "Step 3: Add more features",
    "text": "Step 3: Add more features\nIdentify holidays in air_date, then remove air_date\n\noffice_rec <- office_rec |>\n  step_holiday(\n    air_date, \n    holidays = c(\"USThanksgivingDay\", \"USChristmasDay\", \"USNewYearsDay\", \"USIndependenceDay\"), \n    keep_original_cols = FALSE\n  )\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-3-prep-and-bake",
    "href": "slides/12-feature-engineering-pt2.html#step-3-prep-and-bake",
    "title": "Feature engineering",
    "section": "Step 3: Prep and bake",
    "text": "Step 3: Prep and bake\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) |>\n  glimpse()\n\nRows: 141\nColumns: 11\n$ season                     <dbl> 8, 9, 2, 9, 3, 7, 3, 9, 9, 8, 5, 5, 9, 6, 7â€¦\n$ episode                    <dbl> 18, 14, 8, 5, 22, 1, 15, 21, 18, 12, 25, 26â€¦\n$ title                      <fct> \"Last Day in Florida\", \"Vandalism\", \"Perforâ€¦\n$ total_votes                <dbl> 1429, 1402, 2416, 1515, 2783, 1897, 2283, 2â€¦\n$ imdb_rating                <dbl> 7.8, 7.6, 8.2, 7.1, 9.1, 8.4, 8.3, 8.9, 8.0â€¦\n$ air_date_dow               <fct> Thu, Thu, Tue, Thu, Thu, Thu, Thu, Thu, Thuâ€¦\n$ air_date_month             <fct> Mar, Jan, Nov, Oct, May, Sep, Feb, May, Aprâ€¦\n$ air_date_USThanksgivingDay <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USChristmasDay    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USNewYearsDay     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USIndependenceDay <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-4-convert-numbers-to-factors",
    "href": "slides/12-feature-engineering-pt2.html#step-4-convert-numbers-to-factors",
    "title": "Feature engineering",
    "section": "Step 4: Convert numbers to factors",
    "text": "Step 4: Convert numbers to factors\nConvert season to factor\n\noffice_rec <- office_rec |>\n  step_num2factor(season, levels = as.character(1:9))\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date\nFactor variables from season"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-4-prep-and-bake",
    "href": "slides/12-feature-engineering-pt2.html#step-4-prep-and-bake",
    "title": "Feature engineering",
    "section": "Step 4: Prep and bake",
    "text": "Step 4: Prep and bake\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) |>\n  glimpse()\n\nRows: 141\nColumns: 11\n$ season                     <fct> 8, 9, 2, 9, 3, 7, 3, 9, 9, 8, 5, 5, 9, 6, 7â€¦\n$ episode                    <dbl> 18, 14, 8, 5, 22, 1, 15, 21, 18, 12, 25, 26â€¦\n$ title                      <fct> \"Last Day in Florida\", \"Vandalism\", \"Perforâ€¦\n$ total_votes                <dbl> 1429, 1402, 2416, 1515, 2783, 1897, 2283, 2â€¦\n$ imdb_rating                <dbl> 7.8, 7.6, 8.2, 7.1, 9.1, 8.4, 8.3, 8.9, 8.0â€¦\n$ air_date_dow               <fct> Thu, Thu, Tue, Thu, Thu, Thu, Thu, Thu, Thuâ€¦\n$ air_date_month             <fct> Mar, Jan, Nov, Oct, May, Sep, Feb, May, Aprâ€¦\n$ air_date_USThanksgivingDay <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USChristmasDay    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USNewYearsDay     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USIndependenceDay <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-5-make-dummy-variables",
    "href": "slides/12-feature-engineering-pt2.html#step-5-make-dummy-variables",
    "title": "Feature engineering",
    "section": "Step 5: Make dummy variables",
    "text": "Step 5: Make dummy variables\nConvert all nominal (categorical) predictors to factors\n\noffice_rec <- office_rec |>\n  step_dummy(all_nominal_predictors())\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date\nFactor variables from season\nDummy variables from all_nominal_predictors()"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-5-prep-and-bake",
    "href": "slides/12-feature-engineering-pt2.html#step-5-prep-and-bake",
    "title": "Feature engineering",
    "section": "Step 5: Prep and bake",
    "text": "Step 5: Prep and bake\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) |>\n  glimpse()\n\nRows: 141\nColumns: 33\n$ episode                    <dbl> 18, 14, 8, 5, 22, 1, 15, 21, 18, 12, 25, 26â€¦\n$ title                      <fct> \"Last Day in Florida\", \"Vandalism\", \"Perforâ€¦\n$ total_votes                <dbl> 1429, 1402, 2416, 1515, 2783, 1897, 2283, 2â€¦\n$ imdb_rating                <dbl> 7.8, 7.6, 8.2, 7.1, 9.1, 8.4, 8.3, 8.9, 8.0â€¦\n$ air_date_USThanksgivingDay <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USChristmasDay    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USNewYearsDay     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_USIndependenceDay <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ season_X2                  <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ season_X3                  <dbl> 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ season_X4                  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ season_X5                  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0â€¦\n$ season_X6                  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0â€¦\n$ season_X7                  <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1â€¦\n$ season_X8                  <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0â€¦\n$ season_X9                  <dbl> 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0â€¦\n$ air_date_dow_Mon           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_dow_Tue           <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_dow_Wed           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_dow_Thu           <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦\n$ air_date_dow_Fri           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_dow_Sat           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_month_Feb         <dbl> 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_month_Mar         <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_month_Apr         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1â€¦\n$ air_date_month_May         <dbl> 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0â€¦\n$ air_date_month_Jun         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_month_Jul         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_month_Aug         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_month_Sep         <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0â€¦\n$ air_date_month_Oct         <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_month_Nov         <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦\n$ air_date_month_Dec         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-6-remove-zero-variance-predictors",
    "href": "slides/12-feature-engineering-pt2.html#step-6-remove-zero-variance-predictors",
    "title": "Feature engineering",
    "section": "Step 6: Remove zero variance predictors",
    "text": "Step 6: Remove zero variance predictors\nRemove all predictors that contain only a single value\n\noffice_rec <- office_rec |>\n  step_zv(all_predictors())\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date\nFactor variables from season\nDummy variables from all_nominal_predictors()\nZero variance filter on all_predictors()"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#step-6-prep-and-bake",
    "href": "slides/12-feature-engineering-pt2.html#step-6-prep-and-bake",
    "title": "Feature engineering",
    "section": "Step 6: Prep and bake",
    "text": "Step 6: Prep and bake\n\noffice_rec_trained <- prep(office_rec)\nbake(office_rec_trained, office_train) |>\n  glimpse()\n\nRows: 141\nColumns: 22\n$ episode            <dbl> 18, 14, 8, 5, 22, 1, 15, 21, 18, 12, 25, 26, 12, 1,â€¦\n$ title              <fct> \"Last Day in Florida\", \"Vandalism\", \"Performance Reâ€¦\n$ total_votes        <dbl> 1429, 1402, 2416, 1515, 2783, 1897, 2283, 2041, 144â€¦\n$ imdb_rating        <dbl> 7.8, 7.6, 8.2, 7.1, 9.1, 8.4, 8.3, 8.9, 8.0, 8.0, 8â€¦\n$ season_X2          <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ season_X3          <dbl> 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ season_X4          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ season_X5          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, â€¦\n$ season_X6          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, â€¦\n$ season_X7          <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, â€¦\n$ season_X8          <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ season_X9          <dbl> 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, â€¦\n$ air_date_dow_Tue   <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ air_date_dow_Thu   <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n$ air_date_month_Feb <dbl> 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ air_date_month_Mar <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ air_date_month_Apr <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, â€¦\n$ air_date_month_May <dbl> 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, â€¦\n$ air_date_month_Sep <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, â€¦\n$ air_date_month_Oct <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, â€¦\n$ air_date_month_Nov <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, â€¦\n$ air_date_month_Dec <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#putting-it-all-together",
    "href": "slides/12-feature-engineering-pt2.html#putting-it-all-together",
    "title": "Feature engineering",
    "section": "Putting it all together",
    "text": "Putting it all together\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) |>\n  # make title's role ID\n  update_role(title, new_role = \"ID\") |>\n  # extract day of week and month of air_date\n  step_date(air_date, features = c(\"dow\", \"month\")) |>\n  # identify holidays and add indicators\n  step_holiday(\n    air_date, \n    holidays = c(\"USThanksgivingDay\", \"USChristmasDay\", \"USNewYearsDay\", \"USIndependenceDay\"), \n    keep_original_cols = FALSE\n  ) |>\n  # turn season into factor\n  step_num2factor(season, levels = as.character(1:9)) |>\n  # make dummy variables\n  step_dummy(all_nominal_predictors()) |>\n  # remove zero variance predictors\n  step_zv(all_predictors())"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#putting-it-all-together-1",
    "href": "slides/12-feature-engineering-pt2.html#putting-it-all-together-1",
    "title": "Feature engineering",
    "section": "Putting it all together",
    "text": "Putting it all together\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date\nFactor variables from season\nDummy variables from all_nominal_predictors()\nZero variance filter on all_predictors()"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#recipe-workflow",
    "href": "slides/12-feature-engineering-pt2.html#recipe-workflow",
    "title": "Feature engineering",
    "section": "Recipe workflow",
    "text": "Recipe workflow\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#specify-model",
    "href": "slides/12-feature-engineering-pt2.html#specify-model",
    "title": "Feature engineering",
    "section": "Specify model",
    "text": "Specify model\n\noffice_spec <- linear_reg() |>\n  set_engine(\"lm\")\n\noffice_spec\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#build-workflow",
    "href": "slides/12-feature-engineering-pt2.html#build-workflow",
    "title": "Feature engineering",
    "section": "Build workflow",
    "text": "Build workflow\nWorkflows bring together models and recipes so that they can be easily applied to both the training and test data.\n\noffice_wflow <- workflow() |>\n  add_model(office_spec) |>\n  add_recipe(office_rec)\n\n\nSee next slide for workflowâ€¦"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#view-workflow",
    "href": "slides/12-feature-engineering-pt2.html#view-workflow",
    "title": "Feature engineering",
    "section": "View workflow",
    "text": "View workflow\n\noffice_wflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: linear_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n5 Recipe Steps\n\nâ€¢ step_date()\nâ€¢ step_holiday()\nâ€¢ step_num2factor()\nâ€¢ step_dummy()\nâ€¢ step_zv()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#fit-model-to-training-data",
    "href": "slides/12-feature-engineering-pt2.html#fit-model-to-training-data",
    "title": "Feature engineering",
    "section": "Fit model to training data",
    "text": "Fit model to training data\n\noffice_fit <- office_wflow |>\n  fit(data = office_train)\n\ntidy(office_fit)\n\n# A tibble: 21 Ã— 5\n   term         estimate std.error statistic  p.value\n   <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)  6.40     0.510        12.5   1.51e-23\n 2 episode     -0.00393  0.0171       -0.230 8.18e- 1\n 3 total_votes  0.000375 0.0000414     9.07  2.75e-15\n 4 season_X2    0.811    0.327         2.48  1.44e- 2\n 5 season_X3    1.04     0.343         3.04  2.91e- 3\n 6 season_X4    1.09     0.295         3.70  3.32e- 4\n 7 season_X5    1.08     0.348         3.11  2.34e- 3\n 8 season_X6    1.00     0.367         2.74  7.18e- 3\n 9 season_X7    1.02     0.352         2.89  4.52e- 3\n10 season_X8    0.497    0.348         1.43  1.55e- 1\n# â€¦ with 11 more rows\n\n\n\n\nSo many predictors!"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#model-fit-summary",
    "href": "slides/12-feature-engineering-pt2.html#model-fit-summary",
    "title": "Feature engineering",
    "section": "Model fit summary",
    "text": "Model fit summary\n\ntidy(office_fit) |> print(n = 21)\n\n# A tibble: 21 Ã— 5\n   term                estimate std.error statistic  p.value\n   <chr>                  <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)         6.40     0.510        12.5   1.51e-23\n 2 episode            -0.00393  0.0171       -0.230 8.18e- 1\n 3 total_votes         0.000375 0.0000414     9.07  2.75e-15\n 4 season_X2           0.811    0.327         2.48  1.44e- 2\n 5 season_X3           1.04     0.343         3.04  2.91e- 3\n 6 season_X4           1.09     0.295         3.70  3.32e- 4\n 7 season_X5           1.08     0.348         3.11  2.34e- 3\n 8 season_X6           1.00     0.367         2.74  7.18e- 3\n 9 season_X7           1.02     0.352         2.89  4.52e- 3\n10 season_X8           0.497    0.348         1.43  1.55e- 1\n11 season_X9           0.621    0.345         1.80  7.41e- 2\n12 air_date_dow_Tue    0.382    0.422         0.904 3.68e- 1\n13 air_date_dow_Thu    0.284    0.389         0.731 4.66e- 1\n14 air_date_month_Feb -0.0597   0.132        -0.452 6.52e- 1\n15 air_date_month_Mar -0.0752   0.156        -0.481 6.31e- 1\n16 air_date_month_Apr  0.0954   0.177         0.539 5.91e- 1\n17 air_date_month_May  0.156    0.213         0.734 4.64e- 1\n18 air_date_month_Sep -0.0776   0.223        -0.348 7.28e- 1\n19 air_date_month_Oct -0.176    0.174        -1.01  3.13e- 1\n20 air_date_month_Nov -0.156    0.149        -1.05  2.98e- 1\n21 air_date_month_Dec  0.170    0.149         1.14  2.55e- 1"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#make-predictions-for-training-data",
    "href": "slides/12-feature-engineering-pt2.html#make-predictions-for-training-data",
    "title": "Feature engineering",
    "section": "Make predictions for training data",
    "text": "Make predictions for training data\n\noffice_train_pred <- predict(office_fit, office_train) |>\n  bind_cols(office_train)\n\noffice_train_pred\n\n# A tibble: 141 Ã— 7\n   .pred season episode title               imdb_rating total_votes air_date  \n   <dbl>  <dbl>   <dbl> <chr>                     <dbl>       <dbl> <date>    \n 1  7.57      8      18 Last Day in Florida         7.8        1429 2012-03-08\n 2  7.77      9      14 Vandalism                   7.6        1402 2013-01-31\n 3  8.31      2       8 Performance Review          8.2        2416 2005-11-15\n 4  7.67      9       5 Here Comes Treble           7.1        1515 2012-10-25\n 5  8.84      3      22 Beach Games                 9.1        2783 2007-05-10\n 6  8.33      7       1 Nepotism                    8.4        1897 2010-09-23\n 7  8.46      3      15 Phyllis' Wedding            8.3        2283 2007-02-08\n 8  8.14      9      21 Livin' the Dream            8.9        2041 2013-05-02\n 9  7.87      9      18 Promos                      8          1445 2013-04-04\n10  7.74      8      12 Pool Party                  8          1612 2012-01-19\n# â€¦ with 131 more rows"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#r-squared",
    "href": "slides/12-feature-engineering-pt2.html#r-squared",
    "title": "Feature engineering",
    "section": "R-squared",
    "text": "R-squared\nPercentage of variability in the IMDB ratings explained by the model.\n\n\nrsq(office_train_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.670\n\n\n\n\n\nAre models with high or low \\(R^2\\) more preferable?"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#rmse",
    "href": "slides/12-feature-engineering-pt2.html#rmse",
    "title": "Feature engineering",
    "section": "RMSE",
    "text": "RMSE\nAn alternative model performance statistic: root mean square error.\n\\[ RMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}} \\]\n\n\nrmse(office_train_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.302\n\n\n\n\n\nAre models with high or low RMSE are more preferable?"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#interpreting-rmse",
    "href": "slides/12-feature-engineering-pt2.html#interpreting-rmse",
    "title": "Feature engineering",
    "section": "Interpreting RMSE",
    "text": "Interpreting RMSE\n\nIs this RMSE considered low or high?\n\n\nrmse(office_train_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.302\n\n\n\n\nDependsâ€¦\n\noffice_train |>\n  summarise(min = min(imdb_rating), max = max(imdb_rating))\n\n# A tibble: 1 Ã— 2\n    min   max\n  <dbl> <dbl>\n1   6.7   9.7"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#but-really",
    "href": "slides/12-feature-engineering-pt2.html#but-really",
    "title": "Feature engineering",
    "section": "But, reallyâ€¦",
    "text": "But, reallyâ€¦\nwho cares about predictions on training data?"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#make-predictions-for-testing-data",
    "href": "slides/12-feature-engineering-pt2.html#make-predictions-for-testing-data",
    "title": "Feature engineering",
    "section": "Make predictions for testing data",
    "text": "Make predictions for testing data\n\noffice_test_pred <- predict(office_fit, office_test) |>\n  bind_cols(office_test)\n\noffice_test_pred\n\n# A tibble: 47 Ã— 7\n   .pred season episode title               imdb_rating total_votes air_date  \n   <dbl>  <dbl>   <dbl> <chr>                     <dbl>       <dbl> <date>    \n 1  8.03      1       2 Diversity Day               8.3        3566 2005-03-29\n 2  7.98      1       3 Health Care                 7.9        2983 2005-04-05\n 3  8.41      2       4 The Fire                    8.4        2713 2005-10-11\n 4  8.35      2       5 Halloween                   8.2        2561 2005-10-18\n 5  8.35      2       9 E-Mail Surveillance         8.4        2527 2005-11-22\n 6  8.68      2      12 The Injury                  9          3282 2006-01-12\n 7  8.32      2      14 The Carpet                  7.9        2342 2006-01-26\n 8  8.93      2      22 Casino Night                9.3        3644 2006-05-11\n 9  8.80      3       1 Gay Witch Hunt              8.9        3087 2006-09-21\n10  8.37      3       5 Initiation                  8.2        2254 2006-10-19\n# â€¦ with 37 more rows"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#evaluate-performance-for-testing-data",
    "href": "slides/12-feature-engineering-pt2.html#evaluate-performance-for-testing-data",
    "title": "Feature engineering",
    "section": "Evaluate performance for testing data",
    "text": "Evaluate performance for testing data\nRMSE of model fit to testing data\n\nrmse(office_test_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.411\n\n\nR-sq of model fit to testing data\n\nrsq(office_test_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.468"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#training-vs.-testing",
    "href": "slides/12-feature-engineering-pt2.html#training-vs.-testing",
    "title": "Feature engineering",
    "section": "Training vs.Â testing",
    "text": "Training vs.Â testing\n\n\n\n\n\n\n\n\n\n\n\n\nmetric\ntrain\ntest\ncomparison\n\n\n\n\nRMSE\n0.302\n0.411\nRMSE lower for training\n\n\nR-squared\n0.67\n0.468\nR-squared higher for training"
  },
  {
    "objectID": "slides/12-feature-engineering-pt2.html#evaluating-performance-on-training-data",
    "href": "slides/12-feature-engineering-pt2.html#evaluating-performance-on-training-data",
    "title": "Feature engineering",
    "section": "Evaluating performance on training data",
    "text": "Evaluating performance on training data\n\nThe training set does not have the capacity to be a good arbiter of performance.\nIt is not an independent piece of information; predicting the training set can only reflect what the model already knows.\nSuppose you give a class a test, then give them the answers, then provide the same test. The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test.\n\n\n\n\nðŸ”— Week 06"
  },
  {
    "objectID": "slides/08-mlr.html#computational-setup",
    "href": "slides/08-mlr.html#computational-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modelingt\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # for laying out plots\nlibrary(GGally)      # for pairwise plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "slides/08-mlr.html#house-prices-in-levittown",
    "href": "slides/08-mlr.html#house-prices-in-levittown",
    "title": "Multiple linear regression (MLR)",
    "section": "House prices in Levittown",
    "text": "House prices in Levittown\n\nThe data set contains the sales price and characteristics of 85 homes in Levittown, NY that sold between June 2010 and May 2011.\nLevittown was built right after WWII and was the first planned suburban community built using mass production techniques.\nThe article â€œLevittown, the prototypical American suburb â€“ a history of cities in 50 buildings, day 25â€ gives an overview of Levittownâ€™s controversial history."
  },
  {
    "objectID": "slides/08-mlr.html#analysis-goals",
    "href": "slides/08-mlr.html#analysis-goals",
    "title": "Multiple linear regression (MLR)",
    "section": "Analysis goals",
    "text": "Analysis goals\n\nWe would like to use the characteristics of a house to understand variability in the sales price.\nTo do so, we will fit a multiple linear regression model.\nUsing our model, we can answers questions such as\n\n\nWhat is the relationship between the characteristics of a house in Levittown and its sale price?\nGiven its characteristics, what is the expected sale price of a house in Levittown?"
  },
  {
    "objectID": "slides/08-mlr.html#the-data",
    "href": "slides/08-mlr.html#the-data",
    "title": "Multiple linear regression (MLR)",
    "section": "The data",
    "text": "The data\n\nlevittown <- read_csv(here::here(\"slides/data/homeprices.csv\"))\nlevittown\n\n# A tibble: 85 Ã— 7\n   bedrooms bathrooms living_area lot_size year_built property_tax sale_price\n      <dbl>     <dbl>       <dbl>    <dbl>      <dbl>        <dbl>      <dbl>\n 1        4       1          1380     6000       1948         8360     350000\n 2        4       2          1761     7400       1951         5754     360000\n 3        4       2          1564     6000       1948         8982     350000\n 4        5       2          2904     9898       1949        11664     375000\n 5        5       2.5        1942     7788       1948         8120     370000\n 6        4       2          1830     6000       1948         8197     335000\n 7        4       1          1585     6000       1948         6223     295000\n 8        4       1           941     6800       1951         2448     250000\n 9        4       1.5        1481     6000       1948         9087     299990\n10        3       2          1630     5998       1948         9430     375000\n# â€¦ with 75 more rows"
  },
  {
    "objectID": "slides/08-mlr.html#variables",
    "href": "slides/08-mlr.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nbedrooms: Number of bedrooms\nbathrooms: Number of bathrooms\nliving_area: Total living area of the house (in square feet)\nlot_size: Total area of the lot (in square feet)\nyear_built: Year the house was built\nproperty_tax: Annual property taxes (in USD)\n\n\nResponse: sale_price: Sales price (in USD)"
  },
  {
    "objectID": "slides/08-mlr.html#eda-response-variable",
    "href": "slides/08-mlr.html#eda-response-variable",
    "title": "Multiple linear regression (MLR)",
    "section": "EDA: Response variable",
    "text": "EDA: Response variable"
  },
  {
    "objectID": "slides/08-mlr.html#eda-predictor-variables",
    "href": "slides/08-mlr.html#eda-predictor-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "EDA: Predictor variables",
    "text": "EDA: Predictor variables"
  },
  {
    "objectID": "slides/08-mlr.html#eda-response-vs.-predictors",
    "href": "slides/08-mlr.html#eda-response-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "EDA: Response vs.Â Predictors",
    "text": "EDA: Response vs.Â Predictors"
  },
  {
    "objectID": "slides/08-mlr.html#eda-all-variables",
    "href": "slides/08-mlr.html#eda-all-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "EDA: All variables",
    "text": "EDA: All variables\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggpairs(levittown) +\n  theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, size = 10),\n    strip.text.y = element_text(angle = 0, hjust = 0)\n    )"
  },
  {
    "objectID": "slides/08-mlr.html#single-vs.-multiple-predictors",
    "href": "slides/08-mlr.html#single-vs.-multiple-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Single vs.Â multiple predictors",
    "text": "Single vs.Â multiple predictors\nSo far weâ€™ve used a single predictor variable to understand variation in a quantitative response variable\n\nNow we want to use multiple predictor variables to understand variation in a quantitative response variable"
  },
  {
    "objectID": "slides/08-mlr.html#multiple-linear-regression-mlr",
    "href": "slides/08-mlr.html#multiple-linear-regression-mlr",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\hat{\\text{sale_price}} ~ = & ~\n\\hat{\\beta}_0 + \\hat{\\beta}_1 \\text{bedrooms} + \\hat{\\beta}_2 \\text{bathrooms} + \\hat{\\beta}_3 \\text{living_area} \\\\\n&+ \\hat{\\beta}_4 \\text{lot_size} + \\hat{\\beta}_5 \\text{year_built} + \\hat{\\beta}_6 \\text{property_tax}\\end{aligned}\n\\]\nSimilar to simple linear regression, this model assumes that at each combination of the predictor variables, the values sale_price follow a Normal distribution."
  },
  {
    "objectID": "slides/08-mlr.html#regression-model",
    "href": "slides/08-mlr.html#regression-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Regression Model",
    "text": "Regression Model\nRecall: The simple linear regression model assumes\n\\[\nY|X\\sim N(\\beta_0 + \\beta_1 X, \\sigma_{\\epsilon}^2)\n\\]\n\nSimilarly: The multiple linear regression model assumes\n\\[\nY|X_1, X_2, \\ldots, X_p \\sim N(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p, \\sigma_{\\epsilon}^2)\n\\]"
  },
  {
    "objectID": "slides/08-mlr.html#the-mlr-model",
    "href": "slides/08-mlr.html#the-mlr-model",
    "title": "Multiple linear regression (MLR)",
    "section": "The MLR model",
    "text": "The MLR model\nFor a given observation \\((x_{i1}, x_{i2} \\ldots, x_{ip}, y_i)\\)\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip} + \\epsilon_{i} \\hspace{8mm} \\epsilon_i \\sim N(0,\\sigma_\\epsilon^2)\n\\]"
  },
  {
    "objectID": "slides/08-mlr.html#prediction",
    "href": "slides/08-mlr.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\nAt any combination of the predictors, the mean value of the response \\(Y\\), is\n\\[\n\\mu_{Y|X_1, \\ldots, X_p} = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_2 + \\dots + \\beta_p X_p\n\\]\n\nUsing multiple linear regression, we can estimate the mean response for any combination of predictors\n\\[\n\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{1} + \\hat{\\beta}_2 X_2 + \\dots + \\hat{\\beta}_p X_{p}\n\\]"
  },
  {
    "objectID": "slides/08-mlr.html#model-fit",
    "href": "slides/08-mlr.html#model-fit",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit",
    "text": "Model fit\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-7148818.957\n3820093.694\n-1.871\n0.065\n\n\nbedrooms\n-12291.011\n9346.727\n-1.315\n0.192\n\n\nbathrooms\n51699.236\n13094.170\n3.948\n0.000\n\n\nliving_area\n65.903\n15.979\n4.124\n0.000\n\n\nlot_size\n-0.897\n4.194\n-0.214\n0.831\n\n\nyear_built\n3760.898\n1962.504\n1.916\n0.059\n\n\nproperty_tax\n1.476\n2.832\n0.521\n0.604"
  },
  {
    "objectID": "slides/08-mlr.html#model-equation",
    "href": "slides/08-mlr.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\hat{\\text{price}} = & -7148818.957 - 12291.011 \\times \\text{bedrooms}\\\\[5pt]  \n&+ 51699.236 \\times \\text{bathrooms}  + 65.903 \\times \\text{living area}\\\\[5pt]\n&- 0.897 \\times \\text{lot size} +  3760.898 \\times \\text{year built}\\\\[5pt]\n&+ 1.476 \\times \\text{property tax}\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/08-mlr.html#interpreting-hatbeta_j",
    "href": "slides/08-mlr.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(y\\) when \\(x_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n\n\nExample: The estimated coefficient for living_area is 65.90. This means for each additional square foot of living area, we expect the sale price of a house in Levittown, NY to increase by $65.90, on average, holding all other predictor variables constant."
  },
  {
    "objectID": "slides/08-mlr.html#prediction-1",
    "href": "slides/08-mlr.html#prediction-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted sale price for a house in Levittown, NY with 3 bedrooms, 1 bathroom, 1,050 square feet of living area, 6,000 square foot lot size, built in 1948 with $6,306 in property taxes?\n\n\n\n-7148818.957 - 12291.011 * 3 + 51699.236 * 1 + \n  65.903 * 1050 - 0.897 * 6000 + 3760.898 * 1948 + \n  1.476 * 6306\n\n[1] 265360.4\n\n\n\nThe predicted sale price for a house in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes is $265,360."
  },
  {
    "objectID": "slides/08-mlr.html#prediction-revisit",
    "href": "slides/08-mlr.html#prediction-revisit",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction, revisit",
    "text": "Prediction, revisit\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_house <- tibble(\n  bedrooms = 3, bathrooms = 1, \n  living_area = 1050, lot_size = 6000, \n  year_built = 1948, property_tax = 6306\n  )\n\npredict(price_fit, new_house)\n\n# A tibble: 1 Ã— 1\n    .pred\n    <dbl>\n1 265360."
  },
  {
    "objectID": "slides/08-mlr.html#confidence-interval-for-hatmu_y",
    "href": "slides/08-mlr.html#confidence-interval-for-hatmu_y",
    "title": "Multiple linear regression (MLR)",
    "section": "Confidence interval for \\(\\hat{\\mu}_y\\)",
    "text": "Confidence interval for \\(\\hat{\\mu}_y\\)\n\nCalculate a 95% confidence interval for the estimated mean price of houses in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes.\n\n\n\npredict(price_fit, new_house, type = \"conf_int\", level = 0.95)\n\n# A tibble: 1 Ã— 2\n  .pred_lower .pred_upper\n        <dbl>       <dbl>\n1     238482.     292239."
  },
  {
    "objectID": "slides/08-mlr.html#prediction-interval-for-haty",
    "href": "slides/08-mlr.html#prediction-interval-for-haty",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction interval for \\(\\hat{y}\\)",
    "text": "Prediction interval for \\(\\hat{y}\\)\n\nCalculate a 95% prediction interval for an individual house in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes.\n\n\n\npredict(price_fit, new_house, type = \"pred_int\", level = 0.95)\n\n# A tibble: 1 Ã— 2\n  .pred_lower .pred_upper\n        <dbl>       <dbl>\n1     167277.     363444."
  },
  {
    "objectID": "slides/08-mlr.html#cautions",
    "href": "slides/08-mlr.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/08-mlr.html#recap",
    "href": "slides/08-mlr.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\n\nIntroduced multiple linear regression\nInterpreted a coefficient \\(\\hat{\\beta}_j\\)\nUsed the model to calculate predicted values and the corresponding intervals\n\n\n\n\n\nðŸ”— Week 04"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#announcements",
    "href": "slides/09-mlr-predictors.html#announcements",
    "title": "MLR: Types of predictors",
    "section": "Announcements",
    "text": "Announcements\n\nLab 03 due\n\nToday at 11:59pm (Thursday labs)\nTue, Sep 27 at 11:59pm (Friday labs)\n\nExam 01: Sep 28 - 30\n\nExam 01 review on Sep 28\nVideos for Weeks 01 - 05 available until Sep 28 at 11:59pm\n\nSee Week 05 for this weekâ€™s activities."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#topics",
    "href": "slides/09-mlr-predictors.html#topics",
    "title": "MLR: Types of predictors",
    "section": "Topics",
    "text": "Topics\n\nPrediction for multiple linear regression\nTypes of predictors for multiple linear regression\nMean-centering quantitative predictors\nUsing indicator variables for categorical predictors\nUsing interaction terms"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#computational-setup",
    "href": "slides/09-mlr-predictors.html#computational-setup",
    "title": "MLR: Types of predictors",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(colorblindr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#the-data",
    "href": "slides/09-mlr-predictors.html#the-data",
    "title": "MLR: Types of predictors",
    "section": "The data",
    "text": "The data\n\nlevittown <- read_csv(here::here(\"slides/data/homeprices.csv\"))\nlevittown\n\n# A tibble: 85 Ã— 7\n   bedrooms bathrooms living_area lot_size year_built property_tax sale_price\n      <dbl>     <dbl>       <dbl>    <dbl>      <dbl>        <dbl>      <dbl>\n 1        4       1          1380     6000       1948         8360     350000\n 2        4       2          1761     7400       1951         5754     360000\n 3        4       2          1564     6000       1948         8982     350000\n 4        5       2          2904     9898       1949        11664     375000\n 5        5       2.5        1942     7788       1948         8120     370000\n 6        4       2          1830     6000       1948         8197     335000\n 7        4       1          1585     6000       1948         6223     295000\n 8        4       1           941     6800       1951         2448     250000\n 9        4       1.5        1481     6000       1948         9087     299990\n10        3       2          1630     5998       1948         9430     375000\n# â€¦ with 75 more rows"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#variables",
    "href": "slides/09-mlr-predictors.html#variables",
    "title": "MLR: Types of predictors",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nbedrooms: Number of bedrooms\nbathrooms: Number of bathrooms\nliving_area: Total living area of the house (in square feet)\nlot_size: Total area of the lot (in square feet)\nyear_built: Year the house was built\nproperty_tax: Annual property taxes (in USD)\n\n\nResponse: sale_price: Sales price (in USD)"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#model-fit",
    "href": "slides/09-mlr-predictors.html#model-fit",
    "title": "MLR: Types of predictors",
    "section": "Model fit",
    "text": "Model fit\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    -7148818.957 \n    3820093.694 \n    -1.871 \n    0.065 \n  \n  \n    bedrooms \n    -12291.011 \n    9346.727 \n    -1.315 \n    0.192 \n  \n  \n    bathrooms \n    51699.236 \n    13094.170 \n    3.948 \n    0.000 \n  \n  \n    living_area \n    65.903 \n    15.979 \n    4.124 \n    0.000 \n  \n  \n    lot_size \n    -0.897 \n    4.194 \n    -0.214 \n    0.831 \n  \n  \n    year_built \n    3760.898 \n    1962.504 \n    1.916 \n    0.059 \n  \n  \n    property_tax \n    1.476 \n    2.832 \n    0.521 \n    0.604"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#prediction-1",
    "href": "slides/09-mlr-predictors.html#prediction-1",
    "title": "MLR: Types of predictors",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted sale price for a house in Levittown, NY with 3 bedrooms, 1 bathroom, 1,050 square feet of living area, 6,000 square foot lot size, built in 1948 with $6,306 in property taxes?\n\n\n\n-7148818.957 - 12291.011 * 3 + 51699.236 * 1 + \n  65.903 * 1050 - 0.897 * 6000 + 3760.898 * 1948 + \n  1.476 * 6306\n\n[1] 265360.4\n\n\n\nThe predicted sale price for a house in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes is $265,360."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#prediction-revisit",
    "href": "slides/09-mlr-predictors.html#prediction-revisit",
    "title": "MLR: Types of predictors",
    "section": "Prediction, revisit",
    "text": "Prediction, revisit\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_house <- tibble(\n  bedrooms = 3, bathrooms = 1, \n  living_area = 1050, lot_size = 6000, \n  year_built = 1948, property_tax = 6306\n  )\n\npredict(price_fit, new_house)\n\n# A tibble: 1 Ã— 1\n    .pred\n    <dbl>\n1 265360."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#confidence-interval-for-hatmu_y",
    "href": "slides/09-mlr-predictors.html#confidence-interval-for-hatmu_y",
    "title": "MLR: Types of predictors",
    "section": "Confidence interval for \\(\\hat{\\mu}_y\\)",
    "text": "Confidence interval for \\(\\hat{\\mu}_y\\)\n\nCalculate a 95% confidence interval for the estimated mean price of houses in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes.\n\n\n\npredict(price_fit, new_house, type = \"conf_int\", level = 0.95)\n\n# A tibble: 1 Ã— 2\n  .pred_lower .pred_upper\n        <dbl>       <dbl>\n1     238482.     292239."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#prediction-interval-for-haty",
    "href": "slides/09-mlr-predictors.html#prediction-interval-for-haty",
    "title": "MLR: Types of predictors",
    "section": "Prediction interval for \\(\\hat{y}\\)",
    "text": "Prediction interval for \\(\\hat{y}\\)\n\nCalculate a 95% prediction interval for an individual house in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes.\n\n\n\npredict(price_fit, new_house, type = \"pred_int\", level = 0.95)\n\n# A tibble: 1 Ã— 2\n  .pred_lower .pred_upper\n        <dbl>       <dbl>\n1     167277.     363444."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#cautions",
    "href": "slides/09-mlr-predictors.html#cautions",
    "title": "MLR: Types of predictors",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#data-peer-to-peer-lender",
    "href": "slides/09-mlr-predictors.html#data-peer-to-peer-lender",
    "title": "MLR: Types of predictors",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nTodayâ€™s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 Ã— 4\n   annual_income debt_to_income verified_income interest_rate\n           <dbl>          <dbl> <fct>                   <dbl>\n 1         59000         0.558  Not Verified            10.9 \n 2         60000         1.31   Not Verified             9.92\n 3         75000         1.06   Verified                26.3 \n 4         75000         0.574  Not Verified             9.92\n 5        254000         0.238  Not Verified             9.43\n 6         67000         1.08   Source Verified          9.92\n 7         28800         0.0997 Source Verified         17.1 \n 8         80000         0.351  Not Verified             6.08\n 9         34000         0.698  Not Verified             7.97\n10         80000         0.167  Source Verified         12.6 \n# â€¦ with 40 more rows"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#variables-1",
    "href": "slides/09-mlr-predictors.html#variables-1",
    "title": "MLR: Types of predictors",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income: Annual income\ndebt_to_income: Debt-to-income ratio, i.e.Â the percentage of a borrowerâ€™s total debt divided by their total income\nverified_income: Whether borrowerâ€™s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nOutcome: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#outcome-interest_rate",
    "href": "slides/09-mlr-predictors.html#outcome-interest_rate",
    "title": "MLR: Types of predictors",
    "section": "Outcome: interest_rate",
    "text": "Outcome: interest_rate\n\n\n\n\n\n \n  \n    min \n    median \n    max \n    iqr \n  \n \n\n  \n    5.31 \n    9.93 \n    26.3 \n    5.755"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#predictors",
    "href": "slides/09-mlr-predictors.html#predictors",
    "title": "MLR: Types of predictors",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#data-manipulation-1-rescale-income",
    "href": "slides/09-mlr-predictors.html#data-manipulation-1-rescale-income",
    "title": "MLR: Types of predictors",
    "section": "Data manipulation 1: Rescale income",
    "text": "Data manipulation 1: Rescale income\n\nloan50 <- loan50 |>\n  mutate(annual_income_th = annual_income / 1000)\n\nggplot(loan50, aes(x = annual_income_th)) +\n  geom_histogram(binwidth = 20) +\n  labs(title = \"Annual income (in $1000s)\", \n       x = \"\")"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#outcome-vs.-predictors",
    "href": "slides/09-mlr-predictors.html#outcome-vs.-predictors",
    "title": "MLR: Types of predictors",
    "section": "Outcome vs.Â predictors",
    "text": "Outcome vs.Â predictors"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#fit-regression-model",
    "href": "slides/09-mlr-predictors.html#fit-regression-model",
    "title": "MLR: Types of predictors",
    "section": "Fit regression model",
    "text": "Fit regression model\n\nint_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n      data = loan50)"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#summarize-model-results",
    "href": "slides/09-mlr-predictors.html#summarize-model-results",
    "title": "MLR: Types of predictors",
    "section": "Summarize model results",
    "text": "Summarize model results\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n    conf.low \n    conf.high \n  \n \n\n  \n    (Intercept) \n    10.726 \n    1.507 \n    7.116 \n    0.000 \n    7.690 \n    13.762 \n  \n  \n    debt_to_income \n    0.671 \n    0.676 \n    0.993 \n    0.326 \n    -0.690 \n    2.033 \n  \n  \n    verified_incomeSource Verified \n    2.211 \n    1.399 \n    1.581 \n    0.121 \n    -0.606 \n    5.028 \n  \n  \n    verified_incomeVerified \n    6.880 \n    1.801 \n    3.820 \n    0.000 \n    3.253 \n    10.508 \n  \n  \n    annual_income_th \n    -0.021 \n    0.011 \n    -1.804 \n    0.078 \n    -0.043 \n    0.002 \n  \n\n\n\n\n\n\n\n\nDescribe the subset of borrowers who are expected to get an interest rate of 10.726% based on our model. Is this interpretation meaningful? Why or why not?"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#mean-centering",
    "href": "slides/09-mlr-predictors.html#mean-centering",
    "title": "MLR: Types of predictors",
    "section": "Mean-centering",
    "text": "Mean-centering\nIf we are interested in interpreting the intercept, we can mean-center the quantitative predictors in the model.\nWe can mean-center a quantitative predictor \\(X_j\\) using the following:\n\\[X_{j_{Cent}} = X_{j}- \\bar{X}_{j}\\]\n\nIf we mean-center all quantitative variables, then the intercept is interpreted as the expected value of the response variable when all quantitative variables are at their mean value."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#data-manipulation-2-mean-center-numeric-predictors",
    "href": "slides/09-mlr-predictors.html#data-manipulation-2-mean-center-numeric-predictors",
    "title": "MLR: Types of predictors",
    "section": "Data manipulation 2: Mean-center numeric predictors",
    "text": "Data manipulation 2: Mean-center numeric predictors\n\nloan50 <- loan50 |>\n  mutate(\n    debt_inc_cent = debt_to_income - mean(debt_to_income), \n    annual_income_th_cent = annual_income_th - mean(annual_income_th)\n    )"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#visualize-mean-centered-predictors",
    "href": "slides/09-mlr-predictors.html#visualize-mean-centered-predictors",
    "title": "MLR: Types of predictors",
    "section": "Visualize mean-centered predictors",
    "text": "Visualize mean-centered predictors"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#using-mean-centered-variables-in-the-model",
    "href": "slides/09-mlr-predictors.html#using-mean-centered-variables-in-the-model",
    "title": "MLR: Types of predictors",
    "section": "Using mean-centered variables in the model",
    "text": "Using mean-centered variables in the model\n\nHow do you expect the model to change if we use the debt_inc_cent and annual_income_cent in the model?\n\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n    conf.low \n    conf.high \n  \n \n\n  \n    (Intercept) \n    9.444 \n    0.977 \n    9.663 \n    0.000 \n    7.476 \n    11.413 \n  \n  \n    debt_inc_cent \n    0.671 \n    0.676 \n    0.993 \n    0.326 \n    -0.690 \n    2.033 \n  \n  \n    verified_incomeSource Verified \n    2.211 \n    1.399 \n    1.581 \n    0.121 \n    -0.606 \n    5.028 \n  \n  \n    verified_incomeVerified \n    6.880 \n    1.801 \n    3.820 \n    0.000 \n    3.253 \n    10.508 \n  \n  \n    annual_income_th_cent \n    -0.021 \n    0.011 \n    -1.804 \n    0.078 \n    -0.043 \n    0.002"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#original-vs.-mean-centered-model",
    "href": "slides/09-mlr-predictors.html#original-vs.-mean-centered-model",
    "title": "MLR: Types of predictors",
    "section": "Original vs.Â mean-centered model",
    "text": "Original vs.Â mean-centered model\n\n\n\n\n\n\n \n  \n    term \n    estimate \n  \n \n\n  \n    (Intercept) \n    10.726 \n  \n  \n    debt_to_income \n    0.671 \n  \n  \n    verified_incomeSource Verified \n    2.211 \n  \n  \n    verified_incomeVerified \n    6.880 \n  \n  \n    annual_income_th \n    -0.021 \n  \n\n\n\n\n\n\n\n\n\n\n \n  \n    term \n    estimate \n  \n \n\n  \n    (Intercept) \n    9.444 \n  \n  \n    debt_inc_cent \n    0.671 \n  \n  \n    verified_incomeSource Verified \n    2.211 \n  \n  \n    verified_incomeVerified \n    6.880 \n  \n  \n    annual_income_th_cent \n    -0.021"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#indicator-variables-1",
    "href": "slides/09-mlr-predictors.html#indicator-variables-1",
    "title": "MLR: Types of predictors",
    "section": "Indicator variables",
    "text": "Indicator variables\n\nSuppose there is a categorical variable with \\(K\\) categories (levels)\nWe can make \\(K\\) indicator variables - one indicator for each category\nAn indicator variable takes values 1 or 0\n\n1 if the observation belongs to that category\n0 if the observation does not belong to that category"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#data-manipulation-3-create-indicator-variables-for-verified_income",
    "href": "slides/09-mlr-predictors.html#data-manipulation-3-create-indicator-variables-for-verified_income",
    "title": "MLR: Types of predictors",
    "section": "Data manipulation 3: Create indicator variables for verified_income",
    "text": "Data manipulation 3: Create indicator variables for verified_income\n\nloan50 <- loan50 |>\n  mutate(\n    not_verified = if_else(verified_income == \"Not Verified\", 1, 0),\n    source_verified = if_else(verified_income == \"Source Verified\", 1, 0),\n    verified = if_else(verified_income == \"Verified\", 1, 0)\n  )\n\n\n\n\n# A tibble: 3 Ã— 4\n  verified_income not_verified source_verified verified\n  <fct>                  <dbl>           <dbl>    <dbl>\n1 Not Verified               1               0        0\n2 Verified                   0               0        1\n3 Source Verified            0               1        0"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#indicators-in-the-model",
    "href": "slides/09-mlr-predictors.html#indicators-in-the-model",
    "title": "MLR: Types of predictors",
    "section": "Indicators in the model",
    "text": "Indicators in the model\n\nWe will use \\(K-1\\) of the indicator variables in the model.\nThe baseline is the category that doesnâ€™t have a term in the model.\nThe coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant.\nThis approach is also called dummy coding.\n\n\n\nloan50 |>\n  select(verified_income, source_verified, verified) |>\n  slice(1, 3, 6)\n\n# A tibble: 3 Ã— 3\n  verified_income source_verified verified\n  <fct>                     <dbl>    <dbl>\n1 Not Verified                  0        0\n2 Verified                      0        1\n3 Source Verified               1        0"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#interpreting-verified_income",
    "href": "slides/09-mlr-predictors.html#interpreting-verified_income",
    "title": "MLR: Types of predictors",
    "section": "Interpreting verified_income",
    "text": "Interpreting verified_income\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n    conf.low \n    conf.high \n  \n \n\n  \n    (Intercept) \n    9.444 \n    0.977 \n    9.663 \n    0.000 \n    7.476 \n    11.413 \n  \n  \n    debt_inc_cent \n    0.671 \n    0.676 \n    0.993 \n    0.326 \n    -0.690 \n    2.033 \n  \n  \n    verified_incomeSource Verified \n    2.211 \n    1.399 \n    1.581 \n    0.121 \n    -0.606 \n    5.028 \n  \n  \n    verified_incomeVerified \n    6.880 \n    1.801 \n    3.820 \n    0.000 \n    3.253 \n    10.508 \n  \n  \n    annual_income_th_cent \n    -0.021 \n    0.011 \n    -1.804 \n    0.078 \n    -0.043 \n    0.002 \n  \n\n\n\n\n\n\n\n\nThe baseline category is Not verified.\nPeople with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant.\nPeople with verified income are expected to take a loan with an interest rate that is 6.880% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#interaction-terms-1",
    "href": "slides/09-mlr-predictors.html#interaction-terms-1",
    "title": "MLR: Types of predictors",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#interest-rate-vs.-annual-income",
    "href": "slides/09-mlr-predictors.html#interest-rate-vs.-annual-income",
    "title": "MLR: Types of predictors",
    "section": "Interest rate vs.Â annual income",
    "text": "Interest rate vs.Â annual income\nThe lines are not parallel indicating there is an interaction effect. The slope of annual income differs based on the income verification."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#interaction-term-in-model",
    "href": "slides/09-mlr-predictors.html#interaction-term-in-model",
    "title": "MLR: Types of predictors",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\nint_cent_int_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(interest_rate ~ debt_inc_cent + verified_income + annual_income_th_cent + verified_income * annual_income_th_cent,\n      data = loan50)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    9.484 \n    0.989 \n    9.586 \n    0.000 \n  \n  \n    debt_inc_cent \n    0.691 \n    0.685 \n    1.009 \n    0.319 \n  \n  \n    verified_incomeSource Verified \n    2.157 \n    1.418 \n    1.522 \n    0.135 \n  \n  \n    verified_incomeVerified \n    7.181 \n    1.870 \n    3.840 \n    0.000 \n  \n  \n    annual_income_th_cent \n    -0.007 \n    0.020 \n    -0.341 \n    0.735 \n  \n  \n    verified_incomeSource Verified:annual_income_th_cent \n    -0.016 \n    0.026 \n    -0.643 \n    0.523 \n  \n  \n    verified_incomeVerified:annual_income_th_cent \n    -0.032 \n    0.033 \n    -0.979 \n    0.333"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#interpreting-interaction-terms",
    "href": "slides/09-mlr-predictors.html#interpreting-interaction-terms",
    "title": "MLR: Types of predictors",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/09-mlr-predictors.html#data-manipulation-4-create-interaction-variables",
    "href": "slides/09-mlr-predictors.html#data-manipulation-4-create-interaction-variables",
    "title": "MLR: Types of predictors",
    "section": "Data manipulation 4: Create interaction variables",
    "text": "Data manipulation 4: Create interaction variables\nDefining the interaction variable in the model formula as verified_income * annual_income_th_cent is an implicit data manipulation step as well\n\n\nRows: 50\nColumns: 9\n$ `(Intercept)`                                          <dbl> 1, 1, 1, 1, 1, â€¦\n$ debt_inc_cent                                          <dbl> -0.16511719, 0.â€¦\n$ annual_income_th_cent                                  <dbl> -27.17, -26.17,â€¦\n$ `verified_incomeNot Verified`                          <dbl> 1, 1, 0, 1, 1, â€¦\n$ `verified_incomeSource Verified`                       <dbl> 0, 0, 0, 0, 0, â€¦\n$ verified_incomeVerified                                <dbl> 0, 0, 1, 0, 0, â€¦\n$ `annual_income_th_cent:verified_incomeNot Verified`    <dbl> -27.17, -26.17,â€¦\n$ `annual_income_th_cent:verified_incomeSource Verified` <dbl> 0.00, 0.00, 0.0â€¦\n$ `annual_income_th_cent:verified_incomeVerified`        <dbl> 0.00, 0.00, -11â€¦"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#recap",
    "href": "slides/09-mlr-predictors.html#recap",
    "title": "MLR: Types of predictors",
    "section": "Recap",
    "text": "Recap\n\nMean-centering quantitative predictors\nUsing indicator variables for categorical predictors\nUsing interaction terms"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#looking-backward",
    "href": "slides/09-mlr-predictors.html#looking-backward",
    "title": "MLR: Types of predictors",
    "section": "Looking backward",
    "text": "Looking backward\nData manipulation, with dplyr (from tidyverse):\n\nloan50 |>\n  select(interest_rate, annual_income, debt_to_income, verified_income) |>\n  mutate(\n    # 1. rescale income\n    annual_income_th = annual_income / 1000,\n    # 2. mean-center quantitative predictors\n    debt_inc_cent = debt_to_income - mean(debt_to_income),\n    annual_income_th_cent = annual_income_th - mean(annual_income_th),\n    # 3. create dummy variables for verified_income\n    source_verified = if_else(verified_income == \"Source Verified\", 1, 0),\n    verified = if_else(verified_income == \"Verified\", 1, 0),\n    # 4. create interaction variables\n    `annual_income_th_cent:verified_incomeSource Verified` = annual_income_th_cent * source_verified,\n    `annual_income_th_cent:verified_incomeVerified` = annual_income_th_cent * verified\n  )"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#looking-forward",
    "href": "slides/09-mlr-predictors.html#looking-forward",
    "title": "MLR: Types of predictors",
    "section": "Looking forward",
    "text": "Looking forward\nFeature engineering, with recipes (from tidymodels):\n\nloan_rec <- recipe( ~ ., data = loan50) |>\n  # 1. rescale income\n  step_mutate(annual_income_th = annual_income / 1000) |>\n  # 2. mean-center quantitative predictors\n  step_center(all_numeric_predictors()) |>\n  # 3. create dummy variables for verified_income\n  step_dummy(verified_income) |>\n  # 4. create interaction variables\n  step_interact(terms = ~ annual_income_th:verified_income)"
  },
  {
    "objectID": "slides/09-mlr-predictors.html#recipe",
    "href": "slides/09-mlr-predictors.html#recipe",
    "title": "MLR: Types of predictors",
    "section": "Recipe",
    "text": "Recipe\n\nloan_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n predictor         24\n\nOperations:\n\nVariable mutation for annual_income / 1000\nCentering for all_numeric_predictors()\nDummy variables from verified_income\nInteractions with annual_income_th:verified_income\n\n\n\n\n\nðŸ”— Week 05"
  },
  {
    "objectID": "slides/lab-01.html#computing-toolkit-for-reproducibility",
    "href": "slides/lab-01.html#computing-toolkit-for-reproducibility",
    "title": "Lab 01",
    "section": "Computing toolkit for reproducibility",
    "text": "Computing toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub\n\n\n\nYou discussed R and RStudio in class this week, so we will focus on version control using Git and GitHub."
  },
  {
    "objectID": "slides/lab-01.html#git-and-github",
    "href": "slides/lab-01.html#git-and-github",
    "title": "Lab 01",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\nGit is a version control system â€“ like â€œTrack Changesâ€ features from Microsoft Word.\nGitHub is the home for your Git-based projects on the internet (like DropBox but much better).\nWe will use GitHub as the home for course assignments and activities and for collaboration"
  },
  {
    "objectID": "slides/lab-01.html#what-is-versioning",
    "href": "slides/lab-01.html#what-is-versioning",
    "title": "Lab 01",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/lab-01.html#what-is-versioning-1",
    "href": "slides/lab-01.html#what-is-versioning-1",
    "title": "Lab 01",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/lab-01.html#git-and-github-tips",
    "href": "slides/lab-01.html#git-and-github-tips",
    "title": "Lab 01",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\n\nThere are a lot of Git commands and very few people know them all. 99% of the time you will use git to commit, push, and pull.\nWe will be doing git things and interfacing with GitHub through RStudio\n\nIf you Google for help, skip any methods for using git through the command line.\n\nThere is a great resource for working with git and R: happygitwithr.com.\n\nSome of the content in there is beyond the scope of this course, but itâ€™s a good place to look for help."
  },
  {
    "objectID": "slides/lab-01.html#do-you-have-the-lab-01-repo",
    "href": "slides/lab-01.html#do-you-have-the-lab-01-repo",
    "title": "Lab 01",
    "section": "Do you have the lab-01 repo?",
    "text": "Do you have the lab-01 repo?\n\nGo to the GitHub course organization: https://github.com/sta210-fa22\nYou should see a repo with the prefix lab-01- followed by your GitHub username\nIf you do not have this repo, please let your TA know!"
  },
  {
    "objectID": "slides/lab-01.html#demo",
    "href": "slides/lab-01.html#demo",
    "title": "Lab 01",
    "section": "Demo",
    "text": "Demo\nFollow along as your TA demonstrates the following:\n\nConfigure Git using SSH\nClone repo (using SSH) and start new project in RStudio\nRender document and produce PDF\nUpdate name in YAML\n\nRender, commit, push changes to GitHub\nSee updates in your GitHub repo"
  },
  {
    "objectID": "slides/lab-01.html#tips-for-working-on-lab",
    "href": "slides/lab-01.html#tips-for-working-on-lab",
    "title": "Lab 01",
    "section": "Tips for working on lab",
    "text": "Tips for working on lab\n\nYou do not have to finish the lab in class, they will always be due the following Monday (Thursday labs) or Tuesday (Friday labs). One work strategy is to get through portions that you think will be most challenging (which initially might be the coding component) during lab when a TA can help you on the spot and leave the narrative writing until later.\nDo not pressure each other to finish early (particularly once you start working on teams); use the time wisely to really learn the material and produce a quality report."
  },
  {
    "objectID": "slides/lab-01.html#when-youre-done-with-lab",
    "href": "slides/lab-01.html#when-youre-done-with-lab",
    "title": "Lab 01",
    "section": "When you're done with lab",
    "text": "When you're done with lab\n\nMake sure all your final changes have been pushed to your GitHub repo\nSubmit the PDF of your responses to Gradescope\n\nYou can access Gradescope through Sakai or the course website\nLogin using your Duke NetID credentials\nSee Lab 01 instructions for details on submitting an assignment on Gradescope\n\n\n\n\n\n\n\nðŸ”— Week 02"
  },
  {
    "objectID": "slides/lab-00.html#meet-your-ta",
    "href": "slides/lab-00.html#meet-your-ta",
    "title": "Welcome to STA 210 Labs!",
    "section": "Meet your TA!",
    "text": "Meet your TA!"
  },
  {
    "objectID": "slides/lab-00.html#meet-each-other",
    "href": "slides/lab-00.html#meet-each-other",
    "title": "Welcome to STA 210 Labs!",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\nGet into groups of 4 - 5.\nIntroduce yourself - Name, year, major\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to todayâ€™s date.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Duke student\nNot clothes (weâ€™re all wearing socks)\nNot body parts (we all have a nose)\n\nReporter will share list with the class.\n\n\n\n\n\n06:00"
  },
  {
    "objectID": "slides/lab-00.html#what-to-expect-in-lab",
    "href": "slides/lab-00.html#what-to-expect-in-lab",
    "title": "Welcome to STA 210 Labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the lab assignment (~ 5 - 10 minutes)\nWork on the lab assignment (individual at first, but in teams for the rest of the semester)\nLab instructions will be posted on the course website\nStart each lab by finding your assignment repo in the course GitHub organization\n\nMore on the computing tools in Mondayâ€™s lecture"
  },
  {
    "objectID": "slides/lab-00.html#for-todays-lab",
    "href": "slides/lab-00.html#for-todays-lab",
    "title": "Welcome to STA 210 Labs!",
    "section": "For todayâ€™s lab",
    "text": "For todayâ€™s lab\n\nComplete the STA 210 Student Survey (will ask for a GitHub username)\n\nClick here for information on registering for a GitHub account and choosing a username.\n\nReserve a STA 210 Docker Container\n\nMake sure to reserve the container titled â€œSTA210â€, not â€œRStudioâ€\n\n\n\n\n\nðŸ”— Week 01"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#announcements",
    "href": "slides/03-slr-tidymodels.html#announcements",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Announcements",
    "text": "Announcements\n\nNo office hours today. Office hours start Tuesday, September 6. Click here for full schedule\nCheck your email for an email to join the course GitHub organization. You will receive one by Tuesday, September 6.\nSee Week 02 for this weekâ€™s activities."
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#topics",
    "href": "slides/03-slr-tidymodels.html#topics",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Topics",
    "text": "Topics\n\nIntroduce the computing toolkit - RStudio and GitHub\nUse tidymodels to fit and summarize regression models in R\nComplete an application exercise on exploratory data analysis and modeling"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#computational-setup",
    "href": "slides/03-slr-tidymodels.html#computational-setup",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(fivethirtyeight) # for the fandango dataset\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#reproducibility-checklist",
    "href": "slides/03-slr-tidymodels.html#reproducibility-checklist",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\nâœ”ï¸ Are the tables and figures reproducible from the code and data?\nâœ”ï¸ Does the code actually do what you think it does?\nâœ”ï¸ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\nâœ”ï¸ Can the code be used for other data?\nâœ”ï¸ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#toolkit",
    "href": "slides/03-slr-tidymodels.html#toolkit",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub\n\nMore on this in this weekâ€™s lab"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#what-are-r-and-rstudio",
    "href": "slides/03-slr-tidymodels.html#what-are-r-and-rstudio",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "What are R and RStudio?",
    "text": "What are R and RStudio?\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\n\nSource: Modern Dive"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#rstudio-ide",
    "href": "slides/03-slr-tidymodels.html#rstudio-ide",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#quarto",
    "href": "slides/03-slr-tidymodels.html#quarto",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports â€“ the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#quarto-1",
    "href": "slides/03-slr-tidymodels.html#quarto-1",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#how-will-we-use-quarto",
    "href": "slides/03-slr-tidymodels.html#how-will-we-use-quarto",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYouâ€™ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#application-exercise",
    "href": "slides/03-slr-tidymodels.html#application-exercise",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Application exercise",
    "text": "Application exercise\n\nðŸ“‹ github.com/sta210-fa22/ae-02-bikeshare"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#recap-of-last-lecture",
    "href": "slides/03-slr-tidymodels.html#recap-of-last-lecture",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Recap of last lecture",
    "text": "Recap of last lecture\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative outcome variable.\nUsed the least squares method to estimate the slope and intercept.\nWe interpreted the slope and intercept.\n\n\nSlope: For every one unit increase in \\(x\\), we expect y to be higher/lower by \\(\\hat{\\beta}_1\\) units, on average.\nIntercept: If \\(x\\) is 0, then we expect \\(y\\) to be \\(\\hat{\\beta}_0\\) units.\n\n\nPredicted the response given a value of the predictor variable.\nDefined extrapolation and why we should avoid it."
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#movie-ratings",
    "href": "slides/03-slr-tidymodels.html#movie-ratings",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Movie ratings",
    "text": "Movie ratings\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandangoâ€™s\nIn the fivethirtyeight package: fandango\nContains every film that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#data-prep",
    "href": "slides/03-slr-tidymodels.html#data-prep",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores <- fandango |>\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#tidymodels",
    "href": "slides/03-slr-tidymodels.html#tidymodels",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "tidymodels",
    "text": "tidymodels\n\nThe tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\n\n\n\nlibrary(tidymodels)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.0.0 â”€â”€\n\n\nâœ” broom        1.0.0     âœ” rsample      1.0.0\nâœ” dials        1.0.0     âœ” tune         1.0.0\nâœ” infer        1.0.2     âœ” workflows    1.0.0\nâœ” modeldata    1.0.0     âœ” workflowsets 1.0.0\nâœ” parsnip      1.0.0     âœ” yardstick    1.0.0\nâœ” recipes      1.0.1     \n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– scales::discard() masks purrr::discard()\nâœ– dplyr::filter()   masks stats::filter()\nâœ– recipes::fixed()  masks stringr::fixed()\nâœ– dplyr::lag()      masks stats::lag()\nâœ– yardstick::spec() masks readr::spec()\nâœ– recipes::step()   masks stats::step()\nâ€¢ Search for functions across packages at https://www.tidymodels.org/find/"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#why-tidymodels",
    "href": "slides/03-slr-tidymodels.html#why-tidymodels",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Why tidymodels?",
    "text": "Why tidymodels?\n\nConsistent syntax for different model types (linear, logistic, random forest, Bayesian, etc.)\nStreamline modeling workflow\n\nSplit data into train and test sets\nTransform and create new variables\nAssess model performance\nUse model for prediction and inference"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#step-1-specify-model",
    "href": "slides/03-slr-tidymodels.html#step-1-specify-model",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Step 1: Specify model",
    "text": "Step 1: Specify model\n\nlinear_reg()\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#step-2-set-model-fitting-engine",
    "href": "slides/03-slr-tidymodels.html#step-2-set-model-fitting-engine",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Step 2: Set model fitting engine",
    "text": "Step 2: Set model fitting engine\n\nlinear_reg() |>\n  set_engine(\"lm\") # lm: linear model\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#a-closer-look-at-model-output",
    "href": "slides/03-slr-tidymodels.html#a-closer-look-at-model-output",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "A closer look at model output",
    "text": "A closer look at model output\n\nmovie_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(audience ~ critics, data = movie_scores)\n\nmovie_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = audience ~ critics, data = data)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187  \n\n\n\\[\\widehat{\\text{audience}} = 32.3155 + 0.5187 \\times \\text{critics}\\]\n\n\nNote: The intercept is off by a tiny bit from the hand-calculated intercept, this is likely just due to rounding in the hand calculation."
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#the-regression-output",
    "href": "slides/03-slr-tidymodels.html#the-regression-output",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "The regression output",
    "text": "The regression output\nWeâ€™ll focus on the first column for nowâ€¦\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(audience ~ critics, data = movie_scores) |>\n  tidy() \n\n# A tibble: 2 Ã— 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#prediction",
    "href": "slides/03-slr-tidymodels.html#prediction",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Prediction",
    "text": "Prediction\n\n# create a data frame for a new movie\nnew_movie <- tibble(critics = 70)\n\n# predict the outcome for a new movie\npredict(movie_fit, new_movie)\n\n# A tibble: 1 Ã— 1\n  .pred\n  <dbl>\n1  68.6"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#application-exercise-1",
    "href": "slides/03-slr-tidymodels.html#application-exercise-1",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Application exercise",
    "text": "Application exercise\n\nðŸ“‹ github.com/sta210-fa22/ae-02-bikeshare"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#recap",
    "href": "slides/03-slr-tidymodels.html#recap",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Recap",
    "text": "Recap\n\nIntroduced the computing toolkit - RStudio and GitHub\nUsed tidymodels to fit and summarize regression models in R\nCompleted an application exercise on exploratory data analysis and modeling\n\n\n\n\nðŸ”— Week 02"
  },
  {
    "objectID": "slides/07-slr-math-models.html#announcements",
    "href": "slides/07-slr-math-models.html#announcements",
    "title": "SLR: Mathematical models for inference",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due\n\nToday at 11:59pm (Thursday labs)\nTue, Sep 20 at 11:59pm (Friday labs)\n\nHW 01: due Wed, Sep 21 at 11:59pm\nStatistics experience - due Fri, Dec 09 at 11:59pm\nLab 01 solutions posted in Resources folder in Sakai\nSee Week 04 for this weekâ€™s activities."
  },
  {
    "objectID": "slides/07-slr-math-models.html#topics",
    "href": "slides/07-slr-math-models.html#topics",
    "title": "SLR: Mathematical models for inference",
    "section": "Topics",
    "text": "Topics\n\nDefine mathematical models to conduct inference for the slope\nUse mathematical models to\n\ncalculate confidence interval for the slope\nconduct a hypothesis test for the slope"
  },
  {
    "objectID": "slides/07-slr-math-models.html#computational-setup",
    "href": "slides/07-slr-math-models.html#computational-setup",
    "title": "SLR: Mathematical models for inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/07-slr-math-models.html#the-regression-model-revisited",
    "href": "slides/07-slr-math-models.html#the-regression-model-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |>\n  kable(digits = 3)\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.325 \n    53302.463 \n    2.188 \n    0.031 \n  \n  \n    area \n    159.483 \n    18.171 \n    8.777 \n    0.000"
  },
  {
    "objectID": "slides/07-slr-math-models.html#inference-revisited",
    "href": "slides/07-slr-math-models.html#inference-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow weâ€™ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/07-slr-math-models.html#mathematical-representation-of-the-model",
    "href": "slides/07-slr-math-models.html#mathematical-representation-of-the-model",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= Model + Error \\\\\n&= f(X) + \\epsilon \\\\\n&= \\mu_{Y|X} + \\epsilon \\\\\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed:\n\n\nindependent: Knowing the error term for one observation doesnâ€™t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/07-slr-math-models.html#mathematical-representation-visualized",
    "href": "slides/07-slr-math-models.html#mathematical-representation-visualized",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the predicted value based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/07-slr-math-models.html#regression-standard-error",
    "href": "slides/07-slr-math-models.html#regression-standard-error",
    "title": "SLR: Mathematical models for inference",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error (the spread of the distribution of the response, for a given value of the predictor variable):\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/07-slr-math-models.html#standard-error-of-hatbeta_1",
    "href": "slides/07-slr-math-models.html#standard-error-of-hatbeta_1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n\norâ€¦\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00"
  },
  {
    "objectID": "slides/07-slr-math-models.html#hypothesis-test-for-the-slope",
    "href": "slides/07-slr-math-models.html#hypothesis-test-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test for the slope",
    "text": "Hypothesis test for the slope\nHypotheses: \\(H_0: \\beta_1 = 0\\) vs.Â \\(H_A: \\beta_1 \\ne 0\\)\n\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\nT = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\n\np-value: Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| > |\\text{test statistic}),\n\\]\ncalculated from a \\(t\\) distribution with \\(n - 2\\) degrees of freedom"
  },
  {
    "objectID": "slides/07-slr-math-models.html#hypothesis-test-test-statistic",
    "href": "slides/07-slr-math-models.html#hypothesis-test-test-statistic",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Test statistic",
    "text": "Hypothesis test: Test statistic\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00 \n  \n\n\n\n\n\n\\[\nT = \\frac{\\hat{\\beta}_1 - 0}{SE_{\\hat{\\beta}_1}} = \\frac{159.48 - 0}{18.17} = 8.78\n\\]"
  },
  {
    "objectID": "slides/07-slr-math-models.html#hypothesis-test-p-value",
    "href": "slides/07-slr-math-models.html#hypothesis-test-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00"
  },
  {
    "objectID": "slides/07-slr-math-models.html#understanding-the-p-value",
    "href": "slides/07-slr-math-models.html#understanding-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value < 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 < p-value < 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 < p-value < 0.1\nweak evidence against \\(H_0\\)\n\n\np-value > 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/07-slr-math-models.html#hypothesis-test-conclusion-in-context",
    "href": "slides/07-slr-math-models.html#hypothesis-test-conclusion-in-context",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Conclusion, in context",
    "text": "Hypothesis test: Conclusion, in context\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00 \n  \n\n\n\n\n\n\nThe data provide convincing evidence that the population slope \\(\\beta_1\\) is different from 0.\nThe data provide convincing evidence of a linear relationship between area and price of houses in Duke Forest."
  },
  {
    "objectID": "slides/07-slr-math-models.html#confidence-interval-for-the-slope",
    "href": "slides/07-slr-math-models.html#confidence-interval-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE_{\\hat{\\beta}_1}\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-2\\) degrees of freedom"
  },
  {
    "objectID": "slides/07-slr-math-models.html#confidence-interval-critical-value",
    "href": "slides/07-slr-math-models.html#confidence-interval-critical-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(duke_forest) - 2)\n\n[1] 1.984984\n\n# confidence level: 90%\nqt(0.95, df = nrow(duke_forest) - 2)\n\n[1] 1.660881\n\n# confidence level: 99%\nqt(0.995, df = nrow(duke_forest) - 2)\n\n[1] 2.628016"
  },
  {
    "objectID": "slides/07-slr-math-models.html#ci-for-the-slope-calculation",
    "href": "slides/07-slr-math-models.html#ci-for-the-slope-calculation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Calculation",
    "text": "95% CI for the slope: Calculation\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00 \n  \n\n\n\n\n\n\\[\\hat{\\beta}_1 = 159.48 \\hspace{15mm} t^* = 1.98 \\hspace{15mm} SE_{\\hat{\\beta}_1} = 18.17\\]\n\n\\[\n159.48 \\pm 1.98 \\times 18.17 = (123.50, 195.46)\n\\]"
  },
  {
    "objectID": "slides/07-slr-math-models.html#ci-for-the-slope-computation",
    "href": "slides/07-slr-math-models.html#ci-for-the-slope-computation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Computation",
    "text": "95% CI for the slope: Computation\n\ntidy(df_fit, conf.int = TRUE, conf.level = 0.95) |> \n  kable(digits = 2)\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n    conf.low \n    conf.high \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n    10847.77 \n    222456.88 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00 \n    123.41 \n    195.55"
  },
  {
    "objectID": "slides/07-slr-math-models.html#intervals-for-predictions-1",
    "href": "slides/07-slr-math-models.html#intervals-for-predictions-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Intervals for predictions",
    "text": "Intervals for predictions\n\nSuppose we want to answer the question â€œWhat is the predicted sale price of a Duke Forest house that is 2,800 square feet?â€\nWe said reporting a single estimate for the slope is not wise, and we should report a plausible range instead\nSimilarly, reporting a single prediction for a new value is not wise, and we should report a plausible range instead"
  },
  {
    "objectID": "slides/07-slr-math-models.html#two-types-of-predictions",
    "href": "slides/07-slr-math-models.html#two-types-of-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Two types of predictions",
    "text": "Two types of predictions\n\nPrediction for the mean: â€œWhat is the average predicted sale price of Duke Forest houses that are 2,800 square feet?â€\nPrediction for an individual observation: â€œWhat is the predicted sale price of a Duke Forest house that is 2,800 square feet?â€\n\n\n\nWhich would you expect to be more variable? The average prediction or the prediction for an individual observation? Based on your answer, how would you expect the widths of plausible ranges for these two predictions to compare?"
  },
  {
    "objectID": "slides/07-slr-math-models.html#uncertainty-in-predictions",
    "href": "slides/07-slr-math-models.html#uncertainty-in-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Uncertainty in predictions",
    "text": "Uncertainty in predictions\nConfidence interval for the mean outcome: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE}_{\\hat{\\boldsymbol{\\mu}}}}}\\]\n\nPrediction interval for an individual observation: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE_{\\hat{y}}}}}\\]"
  },
  {
    "objectID": "slides/07-slr-math-models.html#standard-errors",
    "href": "slides/07-slr-math-models.html#standard-errors",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\n\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{1 + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/07-slr-math-models.html#standard-errors-1",
    "href": "slides/07-slr-math-models.html#standard-errors-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\mathbf{\\color{purple}{\\Large{1}}} + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/07-slr-math-models.html#confidence-interval",
    "href": "slides/07-slr-math-models.html#confidence-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval",
    "text": "Confidence interval\nThe 95% confidence interval for the mean outcome:\n\nnew_house <- tibble(area = 2800)\n\npredict(df_fit, new_data = new_house, type = \"conf_int\", level = 0.95) |>\n  kable()\n\n\n\n \n  \n    .pred_lower \n    .pred_upper \n  \n \n\n  \n    529351 \n    597060.1 \n  \n\n\n\n\n\n\n\n\n\nWe are 95% confident that mean sale price of Duke Forest houses that are 2,800 square feet is between $529,351 and $597,060."
  },
  {
    "objectID": "slides/07-slr-math-models.html#prediction-interval",
    "href": "slides/07-slr-math-models.html#prediction-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Prediction interval",
    "text": "Prediction interval\nThe 95% prediction interval for an individual outcome:\n\npredict(df_fit, new_data = new_house, type = \"pred_int\", level = 0.95) |>\n  kable()\n\n\n\n \n  \n    .pred_lower \n    .pred_upper \n  \n \n\n  \n    226438.3 \n    899972.7 \n  \n\n\n\n\n\n\n\n\n\nWe are 95% confident that predicted sale price of a Duke Forest house that is 2,800 square feet is between $226,438 and $899,973."
  },
  {
    "objectID": "slides/07-slr-math-models.html#comparing-intervals",
    "href": "slides/07-slr-math-models.html#comparing-intervals",
    "title": "SLR: Mathematical models for inference",
    "section": "Comparing intervals",
    "text": "Comparing intervals"
  },
  {
    "objectID": "slides/07-slr-math-models.html#extrapolation",
    "href": "slides/07-slr-math-models.html#extrapolation",
    "title": "SLR: Mathematical models for inference",
    "section": "Extrapolation",
    "text": "Extrapolation\n\n\n\nCalculate the prediction interval for the sale price of a â€œtiny houseâ€ in Duke Forest that is 225 square feet.\n\n\n\n\n\n\n\n\n\n\nNo, thanks!\n\n\n\nðŸ”— Week 04"
  },
  {
    "objectID": "slides/01-welcome.html#meet-the-professor",
    "href": "slides/01-welcome.html#meet-the-professor",
    "title": "Welcome to STA 210!",
    "section": "Meet the professor",
    "text": "Meet the professor\n\n\n\n\n\n\n\n\nDr.Â Maria Tackett\n\n\n\nAssistant Professor of the Practice, Department of Statistical Science\nWork focuses on statistics education, specifically active learning, motivation, and classroom community\nFind out more at maria-tackett.netlify.app"
  },
  {
    "objectID": "slides/01-welcome.html#meet-tas",
    "href": "slides/01-welcome.html#meet-tas",
    "title": "Welcome to STA 210!",
    "section": "Meet TAs",
    "text": "Meet TAs\n\n\n\nCarson Garcia (UG)\nSara Meta (UG)\nMedy Mu (UG)\nGlenn Palmer (PhD)\nBraden Scherting (PhD)\n\n\n\nLuke Vrotsos (PhD)\nBen Wallace (UG)\nAaditya Warrier (UG)\nGrace Zhao (MS)"
  },
  {
    "objectID": "slides/01-welcome.html#check-in-on-ed-discussion",
    "href": "slides/01-welcome.html#check-in-on-ed-discussion",
    "title": "Welcome to STA 210!",
    "section": "Check in on Ed Discussion!",
    "text": "Check in on Ed Discussion!\n\nGo to the class Ed Discussion\n\nSection 001 (10:15am lecture)\nSection 002 (3:30pm lecture)\n\nAnswer the poll question: How are you doing?"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-regression-analysis",
    "href": "slides/01-welcome.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\nâ€œIn statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or â€˜predictorsâ€™). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or â€˜criterion variableâ€™) changes when any one of the independent variables is varied, while the other independent variables are held fixed.â€\n\nSource: Wikipedia (previous definition)"
  },
  {
    "objectID": "slides/01-welcome.html#course-faq",
    "href": "slides/01-welcome.html#course-faq",
    "title": "Welcome to STA 210!",
    "section": "Course FAQ",
    "text": "Course FAQ\nQ - What background is assumed for the course?\nA - Introductory statistics or probability course at Duke\n\nQ - Will we be doing computing?\nA - Yes. We will use the computing language R and version control platform GitHub\n\n\nQ - Will we learn the mathematical theory of regression?\nA - Yes and No.Â The course is primarily focused on application; however, we will discuss some of the mathematics of simple linear regression. There a 0.5-credit course STA 211: Mathematics of Regression to take simultaneously or after this course to dive into more of the mathematics."
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nAnalyze real-world data to answer questions about multivariable relationships.\nFit and evaluate linear and logistic regression models.\nAssess whether a proposed model is appropriate and describe its limitations.\nUse Quarto to write reproducible reports and GitHub for version control and collaboration.\nCommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 210!",
    "section": "Course topics",
    "text": "Course topics\n\n\nUnit 1: Quantitative Response Variable\n\nSimple Linear Regression\nMultiple Linear Regression\n\n\nUnit 2: Categorical Response Variable\n\nLogistic Regression\n\n\nUnit 3: Looking Ahead\n\nMixed and random effects\nIntroduction to linear mixed models\nPresenting statistical results"
  },
  {
    "objectID": "slides/01-welcome.html#examples-of-regression-in-practice",
    "href": "slides/01-welcome.html#examples-of-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Examples of regression in practice",
    "text": "Examples of regression in practice\n\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\nHow FiveThirtyEightâ€™s 2020 Presidential Forecast Works â€” And Whatâ€™s Different Because Of COVID-19\nEffect of Forensic Evidence on Criminal Justice Case Processing\nWhy itâ€™s so freaking hard to make a good COVID-19 model"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nCourse website: sta210-fa22.netlify.app\n\nCentral hub for the course!\nTour of the website\n\nSakai: sakai.duke.edu\n\nGradebook\nAnnouncements\nGradescope\n\nEd Discussion: edstem.org/us/courses/26900/discussion\n\nClass Q&A and discussion forum"
  },
  {
    "objectID": "slides/01-welcome.html#computing-toolkit",
    "href": "slides/01-welcome.html#computing-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through STA 210 Docker Containers"
  },
  {
    "objectID": "slides/01-welcome.html#computing-toolkit-1",
    "href": "slides/01-welcome.html#computing-toolkit-1",
    "title": "Welcome to STA 210!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\nAccess assignments\n\n\n\nFacilitates version control and collaboration\nAll work in STA 210 course organization"
  },
  {
    "objectID": "slides/01-welcome.html#activities-prepare-participate-practice-perform",
    "href": "slides/01-welcome.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to STA 210!",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\n\n\nPrepare: Introduce new content and prepare for lectures by completing the readings (and sometimes watching the videos)\nParticipate: Attend and actively participate in lectures and labs, office hours, team meetings\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what youâ€™ve learned to analyze real-world data\n\nLab assignments (first individual, later team-based)\nHomework assignments (individual)\nTwo take-home exams\nTerm project presented during the final exam period"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n35%\n\n\nFinal project\n15%\n\n\nLab\n15%\n\n\nExam 01\n15%\n\n\nExam 02\n15%\n\n\nApplication Exercises\n2.5%\n\n\nTeamwork\n2.5%\n\n\n\nSee the syllabus for details on how the final letter grade will be calculated."
  },
  {
    "objectID": "slides/01-welcome.html#support",
    "href": "slides/01-welcome.html#support",
    "title": "Welcome to STA 210!",
    "section": "Support",
    "text": "Support\n\nAttend office hours to meet with a member of the teaching team\n\nFull office hours schedule begins Tuesday, September 6\n\nAsk and answer questions on course discussion forum\nUse email for questions regarding personal matters and/or grades\nRead the Course Support page for more details"
  },
  {
    "objectID": "slides/01-welcome.html#diversity-inclusion",
    "href": "slides/01-welcome.html#diversity-inclusion",
    "title": "Welcome to STA 210!",
    "section": "Diversity & inclusion",
    "text": "Diversity & inclusion\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that studentsâ€™ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please donâ€™t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and Iâ€™m always learning how to do this better. If any course component is not accessible to you in any way, please donâ€™t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#covid-policies",
    "href": "slides/01-welcome.html#covid-policies",
    "title": "Welcome to STA 210!",
    "section": "COVID policies",
    "text": "COVID policies\n\nðŸ˜· Wear a mask at all times in lectures and labs based on current university policy\nRead and follow the university guidelines"
  },
  {
    "objectID": "slides/01-welcome.html#late-work-waivers-and-regrade-requests",
    "href": "slides/01-welcome.html#late-work-waivers-and-regrade-requests",
    "title": "Welcome to STA 210!",
    "section": "Late work, waivers, and regrade requests",
    "text": "Late work, waivers, and regrade requests\n\nWe have policies!\nRead about them in the syllabus and refer back to them as needed"
  },
  {
    "objectID": "slides/01-welcome.html#collaboration-sharing-code",
    "href": "slides/01-welcome.html#collaboration-sharing-code",
    "title": "Welcome to STA 210!",
    "section": "Collaboration & sharing code",
    "text": "Collaboration & sharing code\n\nWe have policies!\nRead about them in the syllabus and refer to them as needed\nWeâ€™ll discuss these more before the first assignments"
  },
  {
    "objectID": "slides/01-welcome.html#academic-integrity",
    "href": "slides/01-welcome.html#academic-integrity",
    "title": "Welcome to STA 210!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\nBy participating in this course, you are agreeing that all your work and conduct will be in accordance with the Duke Community Standard."
  },
  {
    "objectID": "slides/01-welcome.html#if-youre-not-sure",
    "href": "slides/01-welcome.html#if-youre-not-sure",
    "title": "Welcome to STA 210!",
    "section": "If youâ€™re not sureâ€¦",
    "text": "If youâ€™re not sureâ€¦\nAsk if youâ€™re not sure if something violates a policy!"
  },
  {
    "objectID": "slides/01-welcome.html#five-tips-for-success",
    "href": "slides/01-welcome.html#five-tips-for-success",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work (readings and videos) before class.\nAsk questions.\nDo the homeworks and labs and get started on homework early when possible.\nDonâ€™t procrastinate and donâ€™t let a week pass by with lingering questions.\nStay up-to-date on announcements (posted on Sakai & sent via email)."
  },
  {
    "objectID": "slides/01-welcome.html#learning-during-a-pandemic",
    "href": "slides/01-welcome.html#learning-during-a-pandemic",
    "title": "Welcome to STA 210!",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please donâ€™t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but youâ€™re always welcome to talk to me. If I canâ€™t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded.\n\nSee the Course Support page for information on Dukeâ€™s academic and wellness resources."
  },
  {
    "objectID": "slides/01-welcome.html#application-exercise",
    "href": "slides/01-welcome.html#application-exercise",
    "title": "Welcome to STA 210!",
    "section": "Application exercise",
    "text": "Application exercise\n\nðŸ“‹ AE 01 - Movie Budgets and Revenues"
  },
  {
    "objectID": "slides/01-welcome.html#for-this-week",
    "href": "slides/01-welcome.html#for-this-week",
    "title": "Welcome to STA 210!",
    "section": "For this weekâ€¦",
    "text": "For this weekâ€¦\n\nRead the syllabus\nSee Week 01 on the schedule for lecture slides, assignments, and readings.\nComplete the STA 210 Student Survey (will ask for a GitHub username)\n\nClick here for information on registering for a GitHub account and choosing a username.\nYou will go over this in lab this week.\n\nReserve an STA 210 Docker Container\n\n\n\n\nðŸ”— Week 01"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#announcements",
    "href": "slides/06-slr-sim-testing.html#announcements",
    "title": "SLR: Simulation-based inference",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01\n\nReleased later today (will get email when HW is available)\ndue Wed, Sep 21 at 11:59pm\n\nStatistics experience - due Fri, Dec 09 at 11:59pm\nSee Week 03 for this weekâ€™s activities."
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#topics",
    "href": "slides/06-slr-sim-testing.html#topics",
    "title": "SLR: Simulation-based inference",
    "section": "Topics",
    "text": "Topics\n\nEvaluate a claim about the slope using hypothesis testing\nDefine mathematical models to conduct inference for slope"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#computational-setup",
    "href": "slides/06-slr-sim-testing.html#computational-setup",
    "title": "SLR: Simulation-based inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#data-duke-forest-houses",
    "href": "slides/06-slr-sim-testing.html#data-duke-forest-houses",
    "title": "SLR: Simulation-based inference",
    "section": "Data: Duke Forest houses",
    "text": "Data: Duke Forest houses"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#the-regression-model",
    "href": "slides/06-slr-sim-testing.html#the-regression-model",
    "title": "SLR: Simulation-based inference",
    "section": "The regression model",
    "text": "The regression model\n\ndf_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |>\n  kable(digits = 2)\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00 \n  \n\n\n\n\n\n\n\n\n\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, on average, for $116,652.\nSlope: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159."
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#inference-for-simple-linear-regression",
    "href": "slides/06-slr-sim-testing.html#inference-for-simple-linear-regression",
    "title": "SLR: Simulation-based inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope, \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#sampling-is-natural",
    "href": "slides/06-slr-sim-testing.html#sampling-is-natural",
    "title": "SLR: Simulation-based inference",
    "section": "Sampling is natural",
    "text": "Sampling is natural\n\n\nWhen you taste a spoonful of soup and decide the spoonful you tasted isnâ€™t salty enough, thatâ€™s exploratory analysis\nIf you generalize and conclude that your entire soup needs salt, thatâ€™s an inference\nFor your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#confidence-interval-via-bootstrapping",
    "href": "slides/06-slr-sim-testing.html#confidence-interval-via-bootstrapping",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval via bootstrapping",
    "text": "Confidence interval via bootstrapping\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#bootstrapping-pipeline-i",
    "href": "slides/06-slr-sim-testing.html#bootstrapping-pipeline-i",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrapping pipeline I",
    "text": "Bootstrapping pipeline I\n\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 Ã— 2\n     price  area\n     <dbl> <dbl>\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# â€¦ with 88 more rows"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#bootstrapping-pipeline-ii",
    "href": "slides/06-slr-sim-testing.html#bootstrapping-pipeline-ii",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrapping pipeline II",
    "text": "Bootstrapping pipeline II\n\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area) |>\n  generate(reps = 1000, type = \"bootstrap\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate   price  area\n       <int>   <dbl> <dbl>\n 1         1  290000  2414\n 2         1  285000  2108\n 3         1  265000  1300\n 4         1  416000  2949\n 5         1  541000  2740\n 6         1  525000  2256\n 7         1 1270000  3909\n 8         1  265000  1300\n 9         1  815000  3904\n10         1  535000  2937\n# â€¦ with 97,990 more rows"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#bootstrapping-pipeline-iii",
    "href": "slides/06-slr-sim-testing.html#bootstrapping-pipeline-iii",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrapping pipeline III",
    "text": "Bootstrapping pipeline III\n\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  fit()\n\n# A tibble: 2,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       <int> <chr>        <dbl>\n 1         1 intercept   80699.\n 2         1 area          168.\n 3         2 intercept  -18821.\n 4         2 area          205.\n 5         3 intercept  234297.\n 6         3 area          117.\n 7         4 intercept  134481.\n 8         4 area          150.\n 9         5 intercept   23861.\n10         5 area          190.\n# â€¦ with 1,990 more rows"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#bootstrapping-pipeline-iv",
    "href": "slides/06-slr-sim-testing.html#bootstrapping-pipeline-iv",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrapping pipeline IV",
    "text": "Bootstrapping pipeline IV\n\nset.seed(210)\n\nboot_dist <- duke_forest |>\n  specify(price ~ area) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  fit()"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#visualize-the-bootstrap-distribution",
    "href": "slides/06-slr-sim-testing.html#visualize-the-bootstrap-distribution",
    "title": "SLR: Simulation-based inference",
    "section": "Visualize the bootstrap distribution",
    "text": "Visualize the bootstrap distribution\n\nboot_dist |>\n  filter(term == \"area\") |>\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10)"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#compute-the-ci",
    "href": "slides/06-slr-sim-testing.html#compute-the-ci",
    "title": "SLR: Simulation-based inference",
    "section": "Compute the CI",
    "text": "Compute the CI"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#but-first",
    "href": "slides/06-slr-sim-testing.html#but-first",
    "title": "SLR: Simulation-based inference",
    "section": "But firstâ€¦",
    "text": "But firstâ€¦\n\nobs_fit <- duke_forest |>\n  specify(price ~ area) |>\n  fit()\n\nobs_fit\n\n# A tibble: 2 Ã— 2\n  term      estimate\n  <chr>        <dbl>\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#compute-95-confidence-interval",
    "href": "slides/06-slr-sim-testing.html#compute-95-confidence-interval",
    "title": "SLR: Simulation-based inference",
    "section": "Compute 95% confidence interval",
    "text": "Compute 95% confidence interval\n\nboot_dist |>\n  get_confidence_interval(\n    level = 0.95,\n    type = \"percentile\",\n    point_estimate = obs_fit\n  )\n\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          91.7     211.\n2 intercept -18290.   287711."
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#research-question-and-hypotheses",
    "href": "slides/06-slr-sim-testing.html#research-question-and-hypotheses",
    "title": "SLR: Simulation-based inference",
    "section": "Research question and hypotheses",
    "text": "Research question and hypotheses\n\nâ€œDo the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?â€\nNull hypothesis: there is no linear relationship between area and price\n\\[\nH_0: \\beta_1 = 0\n\\]\nAlternative hypothesis: there is a linear relationship between area and price\n\\[\nH_A: \\beta_1 \\ne 0\n\\]"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#hypothesis-testing-as-a-court-trial",
    "href": "slides/06-slr-sim-testing.html#hypothesis-testing-as-a-court-trial",
    "title": "SLR: Simulation-based inference",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\nPresent the evidence: Collect data\nJudge the evidence: â€œCould these data plausibly have happened by chance if the null hypothesis were true?â€\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#hypothesis-testing-framework",
    "href": "slides/06-slr-sim-testing.html#hypothesis-testing-framework",
    "title": "SLR: Simulation-based inference",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\) that represents the status quo\nSet an alternative hypothesis, \\(H_A\\) that represents the research question, i.e.Â what weâ€™re testing for\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#quantify-the-variability-of-the-slope",
    "href": "slides/06-slr-sim-testing.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Simulation-based inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor testing\n\n\nTwo approaches:\n\nVia simulation\nVia mathematical models\n\nRandomization to quantify the variability of the slope for the purpose of testing, under the assumption that the null hypothesis is true:\n\nSimulate new samples from the original sample via permutation\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to conduct a hypothesis test"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#permutation-described",
    "href": "slides/06-slr-sim-testing.html#permutation-described",
    "title": "SLR: Simulation-based inference",
    "section": "Permutation, described",
    "text": "Permutation, described\n\n\n\nSet the null hypothesis to be true, and measure the natural variability in the data due to sampling but not due to variables being correlated by permuting\n\nPermute one variable to eliminate any existing relationship between the variables\n\nEach price value is randomly assigned to area of a given house, i.e.Â area and price are no longer matched for a given house\n\n\n\n\n# A tibble: 98 Ã— 3\n   price_Observed price_Permuted  area\n            <dbl>          <dbl> <dbl>\n 1        1520000         342500  6040\n 2        1030000         750000  4475\n 3         420000         645000  1745\n 4         680000         697500  2091\n 5         428500         428500  1772\n 6         456000         481000  1950\n 7        1270000         610000  3909\n 8         557450         680000  2841\n 9         697500         485000  3924\n10         650000         105000  2173\n# â€¦ with 88 more rows"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#permutation-visualized",
    "href": "slides/06-slr-sim-testing.html#permutation-visualized",
    "title": "SLR: Simulation-based inference",
    "section": "Permutation, visualized",
    "text": "Permutation, visualized\n\n\n\nEach of the observed values for area (and for price) exist in both the observed data plot as well as the permuted price plot\nThe permutation removes the linear relationship between area and price"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#permutation-repeated",
    "href": "slides/06-slr-sim-testing.html#permutation-repeated",
    "title": "SLR: Simulation-based inference",
    "section": "Permutation, repeated",
    "text": "Permutation, repeated\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#concluding-the-hypothesis-test",
    "href": "slides/06-slr-sim-testing.html#concluding-the-hypothesis-test",
    "title": "SLR: Simulation-based inference",
    "section": "Concluding the hypothesis test",
    "text": "Concluding the hypothesis test\n\nIs the observed slope of \\(\\hat{\\beta_1} = 159\\) (or an even more extreme slope) a likely outcome under the null hypothesis that \\(\\beta = 0\\)? What does this mean for our original question: â€œDo the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?â€"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#permutation-pipeline-i",
    "href": "slides/06-slr-sim-testing.html#permutation-pipeline-i",
    "title": "SLR: Simulation-based inference",
    "section": "Permutation pipeline I",
    "text": "Permutation pipeline I\n\nset.seed(1125)\n\nduke_forest |>\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 Ã— 2\n     price  area\n     <dbl> <dbl>\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# â€¦ with 88 more rows"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#permutation-pipeline-ii",
    "href": "slides/06-slr-sim-testing.html#permutation-pipeline-ii",
    "title": "SLR: Simulation-based inference",
    "section": "Permutation pipeline II",
    "text": "Permutation pipeline II\n\nset.seed(1125)\n\nduke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98 Ã— 2\n     price  area\n     <dbl> <dbl>\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# â€¦ with 88 more rows"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#permutation-pipeline-iii",
    "href": "slides/06-slr-sim-testing.html#permutation-pipeline-iii",
    "title": "SLR: Simulation-based inference",
    "section": "Permutation pipeline III",
    "text": "Permutation pipeline III\n\nset.seed(1125)\n\nduke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98,000 Ã— 3\n# Groups:   replicate [1,000]\n     price  area replicate\n     <dbl> <dbl>     <int>\n 1  465000  6040         1\n 2  481000  4475         1\n 3 1020000  1745         1\n 4  520000  2091         1\n 5  592000  1772         1\n 6  650000  1950         1\n 7  473000  3909         1\n 8  705000  2841         1\n 9  785000  3924         1\n10  671500  2173         1\n# â€¦ with 97,990 more rows"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#permutation-pipeline-iv",
    "href": "slides/06-slr-sim-testing.html#permutation-pipeline-iv",
    "title": "SLR: Simulation-based inference",
    "section": "Permutation pipeline IV",
    "text": "Permutation pipeline IV\n\nset.seed(1125)\n\nduke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()\n\n# A tibble: 2,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate term       estimate\n       <int> <chr>         <dbl>\n 1         1 intercept 553355.  \n 2         1 area           2.35\n 3         2 intercept 635824.  \n 4         2 area         -27.3 \n 5         3 intercept 536072.  \n 6         3 area           8.57\n 7         4 intercept 598649.  \n 8         4 area         -13.9 \n 9         5 intercept 556202.  \n10         5 area           1.33\n# â€¦ with 1,990 more rows"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#permutation-pipeline-v",
    "href": "slides/06-slr-sim-testing.html#permutation-pipeline-v",
    "title": "SLR: Simulation-based inference",
    "section": "Permutation pipeline V",
    "text": "Permutation pipeline V\n\nset.seed(1125)\n\nnull_dist <- duke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#visualize-the-null-distribution",
    "href": "slides/06-slr-sim-testing.html#visualize-the-null-distribution",
    "title": "SLR: Simulation-based inference",
    "section": "Visualize the null distribution",
    "text": "Visualize the null distribution\n\nnull_dist |>\n  filter(term == \"area\") |>\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10, color = \"white\")"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#reason-around-the-p-value",
    "href": "slides/06-slr-sim-testing.html#reason-around-the-p-value",
    "title": "SLR: Simulation-based inference",
    "section": "Reason around the p-value",
    "text": "Reason around the p-value\n\nIn a world where the there is no relationship between the area of a Duke Forest house and in its price (\\(\\beta_1 = 0\\)), what is the probability that we observe a sample of 98 houses where the slope fo the model predicting price from area is 159 or even more extreme?"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#compute-the-p-value",
    "href": "slides/06-slr-sim-testing.html#compute-the-p-value",
    "title": "SLR: Simulation-based inference",
    "section": "Compute the p-value",
    "text": "Compute the p-value\n\nWhat does this warning mean?\n\n\nget_p_value(\n  null_dist,\n  obs_stat = obs_fit,\n  direction = \"two-sided\"\n)\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step. See\n`?get_p_value()` for more information.\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step. See\n`?get_p_value()` for more information.\n\n\n# A tibble: 2 Ã— 2\n  term      p_value\n  <chr>       <dbl>\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#the-regression-model-revisited",
    "href": "slides/06-slr-sim-testing.html#the-regression-model-revisited",
    "title": "SLR: Simulation-based inference",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |>\n  kable(digits = 3)\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.325 \n    53302.463 \n    2.188 \n    0.031 \n  \n  \n    area \n    159.483 \n    18.171 \n    8.777 \n    0.000"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#inference-revisited",
    "href": "slides/06-slr-sim-testing.html#inference-revisited",
    "title": "SLR: Simulation-based inference",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow weâ€™ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#mathematical-representation-of-the-model",
    "href": "slides/06-slr-sim-testing.html#mathematical-representation-of-the-model",
    "title": "SLR: Simulation-based inference",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= Model + Error \\\\\n&= f(X) + \\epsilon \\\\\n&= \\mu_{Y|X} + \\epsilon \\\\\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed:\n\n\nindependent: Knowing the error term for one observation doesnâ€™t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#mathematical-representation-visualized",
    "href": "slides/06-slr-sim-testing.html#mathematical-representation-visualized",
    "title": "SLR: Simulation-based inference",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the predicted value based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#regression-standard-error",
    "href": "slides/06-slr-sim-testing.html#regression-standard-error",
    "title": "SLR: Simulation-based inference",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error (the spread of the distribution of the response, for a given value of the predictor variable):\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/06-slr-sim-testing.html#standard-error-of-hatbeta_1",
    "href": "slides/06-slr-sim-testing.html#standard-error-of-hatbeta_1",
    "title": "SLR: Simulation-based inference",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n\norâ€¦\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00 \n  \n\n\n\n\n\n\n\n\nðŸ”— Week 03"
  },
  {
    "objectID": "slides/10-exam-01-review.html#announcements",
    "href": "slides/10-exam-01-review.html#announcements",
    "title": "Exam 01 review",
    "section": "Announcements",
    "text": "Announcements\n\nExam 01: Sep 28 - 30\n\nVideos for Weeks 01 - 05 available until Sep 28 at 11:59pm\n\nNo TA office hours Wed - Fri\nNo labs this week - use time to work on exam\nEd Discussion archived Wed 7pm - Sat 9am\nSee Week 05 for this weekâ€™s activities."
  },
  {
    "objectID": "slides/10-exam-01-review.html#exam-01",
    "href": "slides/10-exam-01-review.html#exam-01",
    "title": "Exam 01 review",
    "section": "Exam 01",
    "text": "Exam 01\n\nReleased today ~ 7pm (will receive email) and due Friday at 11:59pm\nExam instructions can be found in the README of the exam-01 Repo\n\nExercise prompts will be in exam-01.qmd\n\nCovers everything weâ€™ve done thus far - Weeks 01 - 05\nOffice Hours:\n\nThu, 10 - 11am (Prof.Â Tackett)\n\nHave clarification questions about exam instructions during the exam?\n\nEmail Prof.Â Tackett with â€œSTA 210 Examâ€ in the subject line"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#announcements",
    "href": "slides/04-slr-evaluation.html#announcements",
    "title": "SLR: Prediction + model evaluation",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours have started. Click here for full schedule.\nAccept the email invitation to join the sta210-fa22 GitHub organization by today at 11:59pm.\n\nYou may also go to the course organization and click to accept on the banner at the top of the page.\nIf you donâ€™t see the email or banner invitation, please email Prof.Â Tackett (maria.tackett@duke.edu).\n\nLab 01 this week - will need access to RStudio and to be a member of the course GitHub organization.\nSee Week 02 for this weekâ€™s activities."
  },
  {
    "objectID": "slides/04-slr-evaluation.html#topics",
    "href": "slides/04-slr-evaluation.html#topics",
    "title": "SLR: Prediction + model evaluation",
    "section": "Topics",
    "text": "Topics\n\nMotivate the importance of model evaluation\nDescribe how \\(R^2\\) and RMSE are used to evaluate models\nAssess modelâ€™s predictive importance using data splitting and bootstrapping"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#computational-setup",
    "href": "slides/04-slr-evaluation.html#computational-setup",
    "title": "SLR: Prediction + model evaluation",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#application-exercise",
    "href": "slides/04-slr-evaluation.html#application-exercise",
    "title": "SLR: Prediction + model evaluation",
    "section": "Application exercise",
    "text": "Application exercise\n\nðŸ“‹ github.com/sta210-fa22/ae-02-bikeshare"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#data-source",
    "href": "slides/04-slr-evaluation.html#data-source",
    "title": "SLR: Prediction + model evaluation",
    "section": "Data source",
    "text": "Data source\n\nThe data come from usdata::county_2019\nThese data have been compiled from the 2019 American Community Survey"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#uninsurance-rate",
    "href": "slides/04-slr-evaluation.html#uninsurance-rate",
    "title": "SLR: Prediction + model evaluation",
    "section": "Uninsurance rate",
    "text": "Uninsurance rate"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#high-school-graduation-rate",
    "href": "slides/04-slr-evaluation.html#high-school-graduation-rate",
    "title": "SLR: Prediction + model evaluation",
    "section": "High school graduation rate",
    "text": "High school graduation rate"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#examining-the-relationship",
    "href": "slides/04-slr-evaluation.html#examining-the-relationship",
    "title": "SLR: Prediction + model evaluation",
    "section": "Examining the relationship",
    "text": "Examining the relationship\n\n\nThe NC Labor and Economic Analysis Division (LEAD) â€œcollects data, conducts research and analysis and publishes reports about the stateâ€™s economy and labor market. Information and data produced by LEAD help stakeholders make more informed decisions on business recruitment, education and workforce policies and career development, as well as gain a more extensive view of North Carolinaâ€™s economy.â€\nSuppose that an analyst working for LEAD is interested in the relationship between uninsurance and high school graduation rates in NC counties.\n\n\n\n\nWhat type of visualization should the analyst make to examine the relationship between these two variables?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#data-prep",
    "href": "slides/04-slr-evaluation.html#data-prep",
    "title": "SLR: Prediction + model evaluation",
    "section": "Data prep",
    "text": "Data prep\n\ncounty_2019_nc <- county_2019 |>\n  as_tibble() |>\n  filter(state == \"North Carolina\") |>\n  select(name, hs_grad, uninsured)\n\ncounty_2019_nc\n\n# A tibble: 100 Ã— 3\n   name             hs_grad uninsured\n   <chr>              <dbl>     <dbl>\n 1 Alamance County     86.3      11.2\n 2 Alexander County    82.4       8.9\n 3 Alleghany County    77.5      11.3\n 4 Anson County        80.7      11.1\n 5 Ashe County         85.1      12.6\n 6 Avery County        83.6      15.9\n 7 Beaufort County     87.7      12  \n 8 Bertie County       78.4      11.9\n 9 Bladen County       81.3      12.9\n10 Brunswick County    91.3       9.8\n# â€¦ with 90 more rows"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#uninsurance-vs.-hs-graduation-rates",
    "href": "slides/04-slr-evaluation.html#uninsurance-vs.-hs-graduation-rates",
    "title": "SLR: Prediction + model evaluation",
    "section": "Uninsurance vs.Â HS graduation rates",
    "text": "Uninsurance vs.Â HS graduation rates\n\n\nCode\nggplot(county_2019_nc,\n       aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  ) +\n  geom_point(data = county_2019_nc |> filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured), shape = \"circle open\", color = \"#8F2D56\", size = 4, stroke = 2) +\n  geom_text(data = county_2019_nc |> filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured, label = name), color = \"#8F2D56\", fontface = \"bold\", nudge_y = 3, nudge_x = 2)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#modeling-the-relationship",
    "href": "slides/04-slr-evaluation.html#modeling-the-relationship",
    "title": "SLR: Prediction + model evaluation",
    "section": "Modeling the relationship",
    "text": "Modeling the relationship\n\n\nCode\nggplot(county_2019_nc, aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#8F2D56\") +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  )"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#fitting-the-model",
    "href": "slides/04-slr-evaluation.html#fitting-the-model",
    "title": "SLR: Prediction + model evaluation",
    "section": "Fitting the model",
    "text": "Fitting the model\nWith fit():\n\nnc_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(uninsured ~ hs_grad, data = county_2019_nc)\n\ntidy(nc_fit)\n\n# A tibble: 2 Ã— 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   33.9      3.99        8.50 2.12e-13\n2 hs_grad       -0.262    0.0468     -5.61 1.88e- 7"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#augmenting-the-data",
    "href": "slides/04-slr-evaluation.html#augmenting-the-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Augmenting the data",
    "text": "Augmenting the data\nWith augment() to add columns for predicted values (.fitted), residuals (.resid), etc.:\n\nnc_aug <- augment(nc_fit$fit)\nnc_aug\n\n# A tibble: 100 Ã— 8\n   uninsured hs_grad .fitted  .resid   .hat .sigma    .cooksd .std.resid\n       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>      <dbl>      <dbl>\n 1      11.2    86.3   11.3  -0.0633 0.0107   2.10 0.00000501    -0.0305\n 2       8.9    82.4   12.3  -3.39   0.0138   2.07 0.0186        -1.63  \n 3      11.3    77.5   13.6  -2.27   0.0393   2.09 0.0252        -1.11  \n 4      11.1    80.7   12.7  -1.63   0.0199   2.09 0.00633       -0.790 \n 5      12.6    85.1   11.6   1.02   0.0100   2.10 0.00122        0.492 \n 6      15.9    83.6   12.0   3.93   0.0112   2.06 0.0203         1.89  \n 7      12      87.7   10.9   1.10   0.0133   2.10 0.00191        0.532 \n 8      11.9    78.4   13.3  -1.44   0.0328   2.09 0.00830       -0.700 \n 9      12.9    81.3   12.6   0.324  0.0174   2.10 0.000218       0.157 \n10       9.8    91.3    9.95 -0.151  0.0291   2.10 0.0000806     -0.0734\n# â€¦ with 90 more rows"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#visualizing-the-model-i",
    "href": "slides/04-slr-evaluation.html#visualizing-the-model-i",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model I",
    "text": "Visualizing the model I\n\n\n\n\nBlack circles: Observed values (y = uninsured)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#visualizing-the-model-ii",
    "href": "slides/04-slr-evaluation.html#visualizing-the-model-ii",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model II",
    "text": "Visualizing the model II\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#visualizing-the-model-iii",
    "href": "slides/04-slr-evaluation.html#visualizing-the-model-iii",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model III",
    "text": "Visualizing the model III\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line\nMaroon triangles: Predicted values (y = .fitted)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#visualizing-the-model-iv",
    "href": "slides/04-slr-evaluation.html#visualizing-the-model-iv",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model IV",
    "text": "Visualizing the model IV\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line\nMaroon triangles: Predicted values (y = .fitted)\nGray dashed lines: Residuals"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#evaluating-the-model-fit",
    "href": "slides/04-slr-evaluation.html#evaluating-the-model-fit",
    "title": "SLR: Prediction + model evaluation",
    "section": "Evaluating the model fit",
    "text": "Evaluating the model fit\n\nHow can we evaluate whether the model for predicting uninsurance rate from high school graduation rate for NC counties is a good fit?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#two-statistics",
    "href": "slides/04-slr-evaluation.html#two-statistics",
    "title": "SLR: Prediction + model evaluation",
    "section": "Two statistics",
    "text": "Two statistics\n\n\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\\[\nR^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n\\]\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n\\]\n\n\n\n\nWhat indicates a good model fit? Higher or lower \\(R^2\\)? Higher or lower RMSE?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#r2",
    "href": "slides/04-slr-evaluation.html#r2",
    "title": "SLR: Prediction + model evaluation",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\n\nRanges between 0 (terrible predictor) and 1 (perfect predictor)\nHas no units\nCalculate with rsq() using the augmented data:\n\n\nrsq(nc_aug, truth = uninsured, estimate = .fitted)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.243"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#interpreting-r2",
    "href": "slides/04-slr-evaluation.html#interpreting-r2",
    "title": "SLR: Prediction + model evaluation",
    "section": "Interpreting \\(R^2\\)",
    "text": "Interpreting \\(R^2\\)\n\n\n\n\nðŸ—³ï¸ Vote on Ed Discussion\n\n\nThe \\(R^2\\) of the model for predicting uninsurance rate from high school graduation rate for NC counties is 24.3%. Which of the following is the correct interpretation of this value?\n\n\nHigh school graduation rates correctly predict 24.3% of uninsurance rates in NC counties.\n24.3% of the variability in uninsurance rates in NC counties can be explained by high school graduation rates.\n24.3% of the variability in high school graduation rates in NC counties can be explained by uninsurance rates.\n24.3% of the time uninsurance rates in NC counties can be predicted by high school graduation rates.\n\n\n\nVote - Section 001\nVote - Section 002"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#alternative-approach-for-r2",
    "href": "slides/04-slr-evaluation.html#alternative-approach-for-r2",
    "title": "SLR: Prediction + model evaluation",
    "section": "Alternative approach for \\(R^2\\)",
    "text": "Alternative approach for \\(R^2\\)\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(nc_fit)\n\n# A tibble: 1 Ã— 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.243         0.235  2.09      31.5 0.000000188     1  -214.  435.  443.\n# â€¦ with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\n\n\n\nglance(nc_fit)$r.squared\n\n[1] 0.2430694"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#rmse",
    "href": "slides/04-slr-evaluation.html#rmse",
    "title": "SLR: Prediction + model evaluation",
    "section": "RMSE",
    "text": "RMSE\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nCalculate with rmse() using the augmented data:\n\nrmse(nc_aug, truth = uninsured, estimate = .fitted)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        2.07\n\n\nThe value of RMSE is not very meaningful on its own, but itâ€™s useful for comparing across models (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#obtaining-r2-and-rmse",
    "href": "slides/04-slr-evaluation.html#obtaining-r2-and-rmse",
    "title": "SLR: Prediction + model evaluation",
    "section": "Obtaining \\(R^2\\) and RMSE",
    "text": "Obtaining \\(R^2\\) and RMSE\n\n\nUse rsq() and rmse(), respectively\n\nrsq(nc_aug, truth = uninsured, estimate = .fitted)\nrmse(nc_aug, truth = uninsured, estimate = .fitted)\n\nFirst argument: data frame containing truth and estimate columns\nSecond argument: name of the column containing truth (observed outcome)\nThird argument: name of the column containing estimate (predicted outcome)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#purpose-of-model-evaluation",
    "href": "slides/04-slr-evaluation.html#purpose-of-model-evaluation",
    "title": "SLR: Prediction + model evaluation",
    "section": "Purpose of model evaluation",
    "text": "Purpose of model evaluation\n\n\\(R^2\\) tells us how our model is doing to predict the data we already have\nBut generally we are interested in prediction for a new observation, not for one that is already in our sample, i.e.Â out-of-sample prediction\nWe have a couple ways of simulating out-of-sample prediction before actually getting new data to evaluate the performance of our models"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#spending-our-data",
    "href": "slides/04-slr-evaluation.html#spending-our-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Spending our data",
    "text": "Spending our data\n\n\nThere are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\nDoing all of this on the entire data we have available leaves us with no other data to assess our choices\nWe can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what weâ€™ve done so far)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#simulation-data-splitting",
    "href": "slides/04-slr-evaluation.html#simulation-data-splitting",
    "title": "SLR: Prediction + model evaluation",
    "section": "Simulation: data splitting",
    "text": "Simulation: data splitting\n\n\n\n\nTake a random sample of 10% of the data and set aside (testing data)\nFit a model on the remaining 90% of the data (training data)\nUse the coefficients from this model to make predictions for the testing data\nRepeat 10 times"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#predictive-performance",
    "href": "slides/04-slr-evaluation.html#predictive-performance",
    "title": "SLR: Prediction + model evaluation",
    "section": "Predictive performance",
    "text": "Predictive performance\n\n\n\n\n\nHow consistent are the predictions for different testing datasets?\nHow consistent are the predictions for counties with high school graduation rates in the middle of the plot vs.Â in the edges?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#bootstrapping-our-data",
    "href": "slides/04-slr-evaluation.html#bootstrapping-our-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Bootstrapping our data",
    "text": "Bootstrapping our data\n\n\nThe idea behind bootstrapping is that if a given observation exists in a sample, there may be more like it in the population\nWith bootstrapping, we simulate resampling from the population by resampling from the sample we observed\nBootstrap samples are the sampled with replacement from the original sample and same size as the original sample\n\nFor example, if our sample consists of the observations {A, B, C}, bootstrap samples could be {A, A, B}, {A, C, A}, {B, C, C}, {A, B, C}, etc."
  },
  {
    "objectID": "slides/04-slr-evaluation.html#simulation-bootstrapping",
    "href": "slides/04-slr-evaluation.html#simulation-bootstrapping",
    "title": "SLR: Prediction + model evaluation",
    "section": "Simulation: bootstrapping",
    "text": "Simulation: bootstrapping\n\n\n\n\nTake a bootstrap sample â€“ sample with replacement from the original data, same size as the original data\nFit model to the sample and make predictions for that sample\nRepeat many times"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#predictive-performance-1",
    "href": "slides/04-slr-evaluation.html#predictive-performance-1",
    "title": "SLR: Prediction + model evaluation",
    "section": "Predictive performance",
    "text": "Predictive performance\n\n\n\n\n\nHow consistent are the predictions for different bootstrap datasets?\nHow consistent are the predictions for counties with high school graduation rates in the middle of the plot vs.Â in the edges?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#recap",
    "href": "slides/04-slr-evaluation.html#recap",
    "title": "SLR: Prediction + model evaluation",
    "section": "Recap",
    "text": "Recap\n\nMotivated the importance of model evaluation\nDescribed how \\(R^2\\) and RMSE are used to evaluate models\nAssessed modelâ€™s predictive importance using data splitting and bootstrapping"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#next-week",
    "href": "slides/04-slr-evaluation.html#next-week",
    "title": "SLR: Prediction + model evaluation",
    "section": "Next week",
    "text": "Next week\nInference on the slope using\n\nSimulation-based methods\nMathematical models\n\n\n\n\nðŸ”— Week 02"
  },
  {
    "objectID": "slides/08-slr-conditions.html#announcements",
    "href": "slides/08-slr-conditions.html#announcements",
    "title": "SLR: Conditions",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01: due TODAY at 11:59pm\nStatistics experience - due Fri, Dec 09 at 11:59pm\nAadityaâ€™s office hours today: 1 - 2pm and 7 -8pm on Zoom (link in Sakai)\nSee Week 04 for this weekâ€™s activities.\nUpdated masking policy starting Sep 22\nLooking ahead: Exam 01: Sep 28 - 30"
  },
  {
    "objectID": "slides/08-slr-conditions.html#exam-01",
    "href": "slides/08-slr-conditions.html#exam-01",
    "title": "SLR: Conditions",
    "section": "Exam 01",
    "text": "Exam 01\n\nReleased Sep 28 late afternoon, due Sep 30 at 11:59pm.\n\nNo labs or office hours Sep 28 - 30\n\nCovers content Weeks 01 - 05\nConceptual questions + analysis problems\nWill receive exam through GitHub repo, use a reproducible workflow and submit on GitHub and Gradescope (like labs and HW)\nLecture recordings for Weeks 01 -05 available here until September 28 at 11:59pm.\nLab and HW solutions will be posted after the late submission deadlines.\nExam 01 review in class on September 28"
  },
  {
    "objectID": "slides/08-slr-conditions.html#computational-set-up",
    "href": "slides/08-slr-conditions.html#computational-set-up",
    "title": "SLR: Conditions",
    "section": "Computational set up",
    "text": "Computational set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/08-slr-conditions.html#regression-model-revisited",
    "href": "slides/08-slr-conditions.html#regression-model-revisited",
    "title": "SLR: Conditions",
    "section": "Regression model, revisited",
    "text": "Regression model, revisited\n\ndf_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |>\n  kable(digits = 3)\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.325 \n    53302.463 \n    2.188 \n    0.031 \n  \n  \n    area \n    159.483 \n    18.171 \n    8.777 \n    0.000"
  },
  {
    "objectID": "slides/08-slr-conditions.html#mathematical-representation-visualized",
    "href": "slides/08-slr-conditions.html#mathematical-representation-visualized",
    "title": "SLR: Conditions",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]"
  },
  {
    "objectID": "slides/08-slr-conditions.html#model-conditions",
    "href": "slides/08-slr-conditions.html#model-conditions",
    "title": "SLR: Conditions",
    "section": "Model conditions",
    "text": "Model conditions\n\nLinearity: There is a linear relationship between the outcome and predictor variables\nConstant variance: The variability of the errors is equal for all values of the predictor variable, i.e.Â the errors are homeoscedastic\nNormality: The errors follow a normal distribution\nIndependence: The errors are independent from each other"
  },
  {
    "objectID": "slides/08-slr-conditions.html#linearity",
    "href": "slides/08-slr-conditions.html#linearity",
    "title": "SLR: Conditions",
    "section": "Linearity",
    "text": "Linearity\nâœ… The residuals vs.Â fitted values plot should show a random scatter of residuals (no distinguishable pattern or structure)"
  },
  {
    "objectID": "slides/08-slr-conditions.html#residuals-vs.-fitted-values-code",
    "href": "slides/08-slr-conditions.html#residuals-vs.-fitted-values-code",
    "title": "SLR: Conditions",
    "section": "Residuals vs.Â fitted values (code)",
    "text": "Residuals vs.Â fitted values (code)\n\ndf_aug <- augment(df_fit$fit)\n\nggplot(df_aug, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ylim(-1000000, 1000000) +\n  labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Residuals vs. fitted values\"\n  )"
  },
  {
    "objectID": "slides/08-slr-conditions.html#non-linear-relationships",
    "href": "slides/08-slr-conditions.html#non-linear-relationships",
    "title": "SLR: Conditions",
    "section": "Non-linear relationships",
    "text": "Non-linear relationships"
  },
  {
    "objectID": "slides/08-slr-conditions.html#constant-variance",
    "href": "slides/08-slr-conditions.html#constant-variance",
    "title": "SLR: Conditions",
    "section": "Constant variance",
    "text": "Constant variance\nâœ… The vertical spread of the residuals should be relatively constant across the plot"
  },
  {
    "objectID": "slides/08-slr-conditions.html#non-constant-variance",
    "href": "slides/08-slr-conditions.html#non-constant-variance",
    "title": "SLR: Conditions",
    "section": "Non-constant variance",
    "text": "Non-constant variance"
  },
  {
    "objectID": "slides/08-slr-conditions.html#normality",
    "href": "slides/08-slr-conditions.html#normality",
    "title": "SLR: Conditions",
    "section": "Normality",
    "text": "Normality"
  },
  {
    "objectID": "slides/08-slr-conditions.html#independence",
    "href": "slides/08-slr-conditions.html#independence",
    "title": "SLR: Conditions",
    "section": "Independence",
    "text": "Independence\n\nWe can often check the independence assumption based on the context of the data and how the observations were collected\nIf the data were collected in a particular order, examine a scatterplot of the residuals versus order in which the data were collected\n\n\nâœ… If this is a random sample of Duke Houses, the error for one house does not tell us anything about the error for another use"
  },
  {
    "objectID": "slides/08-slr-conditions.html#recap",
    "href": "slides/08-slr-conditions.html#recap",
    "title": "SLR: Conditions",
    "section": "Recap",
    "text": "Recap\nUsed residual plots to check conditions for SLR:\n\n\n\n\nLinearity\nConstant variance\n\n\n\n\n\nNormality\nIndependence\n\n\n\n\n\n\nWhich of these conditions are required for fitting a SLR? Which for simulation-based inference for the slope for an SLR? Which for inference with mathematical models?\n\n\n\n\n03:00\n\n\n\n\n\n\nðŸ”— Week 04"
  },
  {
    "objectID": "slides/11-feature-engineering.html#announcements",
    "href": "slides/11-feature-engineering.html#announcements",
    "title": "Feature engineering",
    "section": "Announcements",
    "text": "Announcements\nClick here for slides from presentation about the Academic Resource Center."
  },
  {
    "objectID": "slides/11-feature-engineering.html#topics",
    "href": "slides/11-feature-engineering.html#topics",
    "title": "Feature engineering",
    "section": "Topics",
    "text": "Topics\n\nUnderstanding categorical predictors and interaction terms\nFeature engineering"
  },
  {
    "objectID": "slides/11-feature-engineering.html#computational-setup",
    "href": "slides/11-feature-engineering.html#computational-setup",
    "title": "Feature engineering",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(colorblindr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/11-feature-engineering.html#data-peer-to-peer-lender",
    "href": "slides/11-feature-engineering.html#data-peer-to-peer-lender",
    "title": "Feature engineering",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nTodayâ€™s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 Ã— 4\n   annual_income debt_to_income verified_income interest_rate\n           <dbl>          <dbl> <fct>                   <dbl>\n 1         59000         0.558  Not Verified            10.9 \n 2         60000         1.31   Not Verified             9.92\n 3         75000         1.06   Verified                26.3 \n 4         75000         0.574  Not Verified             9.92\n 5        254000         0.238  Not Verified             9.43\n 6         67000         1.08   Source Verified          9.92\n 7         28800         0.0997 Source Verified         17.1 \n 8         80000         0.351  Not Verified             6.08\n 9         34000         0.698  Not Verified             7.97\n10         80000         0.167  Source Verified         12.6 \n# â€¦ with 40 more rows"
  },
  {
    "objectID": "slides/11-feature-engineering.html#variables",
    "href": "slides/11-feature-engineering.html#variables",
    "title": "Feature engineering",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income: Annual income\ndebt_to_income: Debt-to-income ratio, i.e.Â the percentage of a borrowerâ€™s total debt divided by their total income\nverified_income: Whether borrowerâ€™s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nOutcome: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/11-feature-engineering.html#outcome-interest_rate",
    "href": "slides/11-feature-engineering.html#outcome-interest_rate",
    "title": "Feature engineering",
    "section": "Outcome: interest_rate",
    "text": "Outcome: interest_rate\n\n\n\n\n\n \n  \n    min \n    median \n    max \n    iqr \n  \n \n\n  \n    5.31 \n    9.93 \n    26.3 \n    5.755"
  },
  {
    "objectID": "slides/11-feature-engineering.html#predictors",
    "href": "slides/11-feature-engineering.html#predictors",
    "title": "Feature engineering",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/11-feature-engineering.html#data-manipulation-1-rescale-income",
    "href": "slides/11-feature-engineering.html#data-manipulation-1-rescale-income",
    "title": "Feature engineering",
    "section": "Data manipulation 1: Rescale income",
    "text": "Data manipulation 1: Rescale income\n\nloan50 <- loan50 |>\n  mutate(annual_income_th = annual_income / 1000)\n\nggplot(loan50, aes(x = annual_income_th)) +\n  geom_histogram(binwidth = 20) +\n  labs(title = \"Annual income (in $1000s)\", \n       x = \"\")"
  },
  {
    "objectID": "slides/11-feature-engineering.html#data-manipulation-2-mean-center-numeric-predictors",
    "href": "slides/11-feature-engineering.html#data-manipulation-2-mean-center-numeric-predictors",
    "title": "Feature engineering",
    "section": "Data manipulation 2: Mean-center numeric predictors",
    "text": "Data manipulation 2: Mean-center numeric predictors\n\nloan50 <- loan50 |>\n  mutate(\n    debt_inc_cent = debt_to_income - mean(debt_to_income), \n    annual_income_th_cent = annual_income_th - mean(annual_income_th)\n    )"
  },
  {
    "objectID": "slides/11-feature-engineering.html#data-manipulation-3-create-indicator-variables-for-verified_income",
    "href": "slides/11-feature-engineering.html#data-manipulation-3-create-indicator-variables-for-verified_income",
    "title": "Feature engineering",
    "section": "Data manipulation 3: Create indicator variables for verified_income",
    "text": "Data manipulation 3: Create indicator variables for verified_income\n\nloan50 <- loan50 |>\n  mutate(\n    not_verified = if_else(verified_income == \"Not Verified\", 1, 0),\n    source_verified = if_else(verified_income == \"Source Verified\", 1, 0),\n    verified = if_else(verified_income == \"Verified\", 1, 0)\n  )"
  },
  {
    "objectID": "slides/11-feature-engineering.html#interest-rate-vs.-annual-income",
    "href": "slides/11-feature-engineering.html#interest-rate-vs.-annual-income",
    "title": "Feature engineering",
    "section": "Interest rate vs.Â annual income",
    "text": "Interest rate vs.Â annual income\nThe lines are not parallel indicating there is an interaction effect. The slope of annual income differs based on the income verification."
  },
  {
    "objectID": "slides/11-feature-engineering.html#data-manipulation-4-create-interaction-variables",
    "href": "slides/11-feature-engineering.html#data-manipulation-4-create-interaction-variables",
    "title": "Feature engineering",
    "section": "Data manipulation 4: Create interaction variables",
    "text": "Data manipulation 4: Create interaction variables\nDefining the interaction variable in the model formula as verified_income * annual_income_th_cent is an implicit data manipulation step as well\n\n\nRows: 50\nColumns: 9\n$ `(Intercept)`                                          <dbl> 1, 1, 1, 1, 1, â€¦\n$ debt_inc_cent                                          <dbl> -0.16511719, 0.â€¦\n$ annual_income_th_cent                                  <dbl> -27.17, -26.17,â€¦\n$ `verified_incomeNot Verified`                          <dbl> 1, 1, 0, 1, 1, â€¦\n$ `verified_incomeSource Verified`                       <dbl> 0, 0, 0, 0, 0, â€¦\n$ verified_incomeVerified                                <dbl> 0, 0, 1, 0, 0, â€¦\n$ `annual_income_th_cent:verified_incomeNot Verified`    <dbl> -27.17, -26.17,â€¦\n$ `annual_income_th_cent:verified_incomeSource Verified` <dbl> 0.00, 0.00, 0.0â€¦\n$ `annual_income_th_cent:verified_incomeVerified`        <dbl> 0.00, 0.00, -11â€¦"
  },
  {
    "objectID": "slides/11-feature-engineering.html#interaction-term-in-the-model",
    "href": "slides/11-feature-engineering.html#interaction-term-in-the-model",
    "title": "Feature engineering",
    "section": "Interaction term in the model",
    "text": "Interaction term in the model\n\nint_cent_int_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(interest_rate ~ debt_inc_cent  +  verified_income + \n        annual_income_th_cent + verified_income * annual_income_th_cent,\n      data = loan50)\n\n\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    9.484 \n    0.989 \n    9.586 \n    0.000 \n  \n  \n    debt_inc_cent \n    0.691 \n    0.685 \n    1.009 \n    0.319 \n  \n  \n    verified_incomeSource Verified \n    2.157 \n    1.418 \n    1.522 \n    0.135 \n  \n  \n    verified_incomeVerified \n    7.181 \n    1.870 \n    3.840 \n    0.000 \n  \n  \n    annual_income_th_cent \n    -0.007 \n    0.020 \n    -0.341 \n    0.735 \n  \n  \n    verified_incomeSource Verified:annual_income_th_cent \n    -0.016 \n    0.026 \n    -0.643 \n    0.523 \n  \n  \n    verified_incomeVerified:annual_income_th_cent \n    -0.032 \n    0.033 \n    -0.979 \n    0.333"
  },
  {
    "objectID": "slides/11-feature-engineering.html#interpreting-interaction-terms",
    "href": "slides/11-feature-engineering.html#interpreting-interaction-terms",
    "title": "Feature engineering",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/11-feature-engineering.html#understanding-the-model",
    "href": "slides/11-feature-engineering.html#understanding-the-model",
    "title": "Feature engineering",
    "section": "Understanding the model",
    "text": "Understanding the model\n\\[\n\\begin{aligned}\n\\hat{interest\\_rate} &= 9.484 + 0.691 \\times debt\\_inc\\_cent\\\\ &- 0.007 \\times annual\\_income\\_th\\_cent \\\\ &+ 2.157 \\times SourceVerified + 7.181 \\times Verified \\\\ &- 0.016 \\times annual\\_inc\\_th\\_cent \\times SourceVerified\\\\ &- 0.032 \\times annual\\_inc\\_th\\_cent \\times Verified\n\\end{aligned}\n\\]\n\n\nWhat is \\(p\\), the number of predictor terms in the model?\nWrite the equation of the model to predict interest rate for applicants with Not Verified income.\nWrite the equation of the model to predict interest rate for applicants with Verified income."
  },
  {
    "objectID": "slides/11-feature-engineering.html#topics-1",
    "href": "slides/11-feature-engineering.html#topics-1",
    "title": "Feature engineering",
    "section": "Topics",
    "text": "Topics\n\n\nReview: Training and testing splits\nFeature engineering with recipes"
  },
  {
    "objectID": "slides/11-feature-engineering.html#computational-setup-1",
    "href": "slides/11-feature-engineering.html#computational-setup-1",
    "title": "Feature engineering",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gghighlight)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "slides/11-feature-engineering.html#the-office",
    "href": "slides/11-feature-engineering.html#the-office",
    "title": "Feature engineering",
    "section": "The Office",
    "text": "The Office"
  },
  {
    "objectID": "slides/11-feature-engineering.html#data",
    "href": "slides/11-feature-engineering.html#data",
    "title": "Feature engineering",
    "section": "Data",
    "text": "Data\nThe data come from data.world, by way of TidyTuesday\n\noffice_ratings <- read_csv(\"data/office_ratings.csv\")\noffice_ratings\n\n# A tibble: 188 Ã— 6\n   season episode title             imdb_rating total_votes air_date  \n    <dbl>   <dbl> <chr>                   <dbl>       <dbl> <date>    \n 1      1       1 Pilot                     7.6        3706 2005-03-24\n 2      1       2 Diversity Day             8.3        3566 2005-03-29\n 3      1       3 Health Care               7.9        2983 2005-04-05\n 4      1       4 The Alliance              8.1        2886 2005-04-12\n 5      1       5 Basketball                8.4        3179 2005-04-19\n 6      1       6 Hot Girl                  7.8        2852 2005-04-26\n 7      2       1 The Dundies               8.7        3213 2005-09-20\n 8      2       2 Sexual Harassment         8.2        2736 2005-09-27\n 9      2       3 Office Olympics           8.4        2742 2005-10-04\n10      2       4 The Fire                  8.4        2713 2005-10-11\n# â€¦ with 178 more rows"
  },
  {
    "objectID": "slides/11-feature-engineering.html#imdb-ratings",
    "href": "slides/11-feature-engineering.html#imdb-ratings",
    "title": "Feature engineering",
    "section": "IMDB ratings",
    "text": "IMDB ratings"
  },
  {
    "objectID": "slides/11-feature-engineering.html#imdb-ratings-vs.-number-of-votes",
    "href": "slides/11-feature-engineering.html#imdb-ratings-vs.-number-of-votes",
    "title": "Feature engineering",
    "section": "IMDB ratings vs.Â number of votes",
    "text": "IMDB ratings vs.Â number of votes"
  },
  {
    "objectID": "slides/11-feature-engineering.html#outliers",
    "href": "slides/11-feature-engineering.html#outliers",
    "title": "Feature engineering",
    "section": "Outliers",
    "text": "Outliers"
  },
  {
    "objectID": "slides/11-feature-engineering.html#imdb-ratings-vs.-air-date",
    "href": "slides/11-feature-engineering.html#imdb-ratings-vs.-air-date",
    "title": "Feature engineering",
    "section": "IMDB ratings vs.Â air date",
    "text": "IMDB ratings vs.Â air date"
  },
  {
    "objectID": "slides/11-feature-engineering.html#imdb-ratings-vs.-seasons",
    "href": "slides/11-feature-engineering.html#imdb-ratings-vs.-seasons",
    "title": "Feature engineering",
    "section": "IMDB ratings vs.Â seasons",
    "text": "IMDB ratings vs.Â seasons"
  },
  {
    "objectID": "slides/11-feature-engineering.html#spending-our-data",
    "href": "slides/11-feature-engineering.html#spending-our-data",
    "title": "Feature engineering",
    "section": "Spending our data",
    "text": "Spending our data\n\nThere are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\nDoing all of this on the entire data we have available leaves us with no other data to assess our choices\nWe can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what weâ€™ve done so far)"
  },
  {
    "objectID": "slides/11-feature-engineering.html#train-test",
    "href": "slides/11-feature-engineering.html#train-test",
    "title": "Feature engineering",
    "section": "Train / test",
    "text": "Train / test\nStep 1: Create an initial split:\n\nset.seed(123)\noffice_split <- initial_split(office_ratings) # prop = 3/4 by default\n\n\n\nStep 2: Save training data\n\noffice_train <- training(office_split)\ndim(office_train)\n\n[1] 141   6\n\n\n\n\n\nStep 3: Save testing data\n\noffice_test  <- testing(office_split)\ndim(office_test)\n\n[1] 47  6"
  },
  {
    "objectID": "slides/11-feature-engineering.html#training-data",
    "href": "slides/11-feature-engineering.html#training-data",
    "title": "Feature engineering",
    "section": "Training data",
    "text": "Training data\n\noffice_train\n\n# A tibble: 141 Ã— 6\n   season episode title               imdb_rating total_votes air_date  \n    <dbl>   <dbl> <chr>                     <dbl>       <dbl> <date>    \n 1      8      18 Last Day in Florida         7.8        1429 2012-03-08\n 2      9      14 Vandalism                   7.6        1402 2013-01-31\n 3      2       8 Performance Review          8.2        2416 2005-11-15\n 4      9       5 Here Comes Treble           7.1        1515 2012-10-25\n 5      3      22 Beach Games                 9.1        2783 2007-05-10\n 6      7       1 Nepotism                    8.4        1897 2010-09-23\n 7      3      15 Phyllis' Wedding            8.3        2283 2007-02-08\n 8      9      21 Livin' the Dream            8.9        2041 2013-05-02\n 9      9      18 Promos                      8          1445 2013-04-04\n10      8      12 Pool Party                  8          1612 2012-01-19\n# â€¦ with 131 more rows"
  },
  {
    "objectID": "slides/11-feature-engineering.html#feature-engineering-1",
    "href": "slides/11-feature-engineering.html#feature-engineering-1",
    "title": "Feature engineering",
    "section": "Feature engineering",
    "text": "Feature engineering\n\nWe prefer simple (parsimonious) models when possible, but parsimony does not mean sacrificing accuracy (or predictive performance) in the interest of simplicity\nVariables that go into the model and how they are represented are just as critical to success of the model\nFeature engineering allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance)"
  },
  {
    "objectID": "slides/11-feature-engineering.html#feature-engineering-with-dplyr",
    "href": "slides/11-feature-engineering.html#feature-engineering-with-dplyr",
    "title": "Feature engineering",
    "section": "Feature engineering with dplyr",
    "text": "Feature engineering with dplyr\n\n\n\n\noffice_train |>\n  mutate(\n    season = as_factor(season),\n    month = lubridate::month(air_date),\n    wday = lubridate::wday(air_date)\n  )\n\n# A tibble: 141 Ã— 8\n  season episode title               imdb_rating total_â€¦Â¹ air_date   month  wday\n  <fct>    <dbl> <chr>                     <dbl>    <dbl> <date>     <dbl> <dbl>\n1 8           18 Last Day in Florida         7.8     1429 2012-03-08     3     5\n2 9           14 Vandalism                   7.6     1402 2013-01-31     1     5\n3 2            8 Performance Review          8.2     2416 2005-11-15    11     3\n4 9            5 Here Comes Treble           7.1     1515 2012-10-25    10     5\n5 3           22 Beach Games                 9.1     2783 2007-05-10     5     5\n6 7            1 Nepotism                    8.4     1897 2010-09-23     9     5\n# â€¦ with 135 more rows, and abbreviated variable name Â¹â€‹total_votes\n\n\n\n\nCan you identify any potential problems with this approach?"
  },
  {
    "objectID": "slides/11-feature-engineering.html#modeling-workflow",
    "href": "slides/11-feature-engineering.html#modeling-workflow",
    "title": "Feature engineering",
    "section": "Modeling workflow",
    "text": "Modeling workflow\n\n\n\nCreate a recipe for feature engineering steps to be applied to the training data\nFit the model to the training data after these steps have been applied\nUsing the model estimates from the training data, predict outcomes for the test data\nEvaluate the performance of the model on the test data"
  },
  {
    "objectID": "slides/11-feature-engineering.html#initiate-a-recipe",
    "href": "slides/11-feature-engineering.html#initiate-a-recipe",
    "title": "Feature engineering",
    "section": "Initiate a recipe",
    "text": "Initiate a recipe\n\noffice_rec <- recipe(\n  imdb_rating ~ .,    # formula\n  data = office_train # data for cataloging names and types of variables\n  )\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          5"
  },
  {
    "objectID": "slides/11-feature-engineering.html#step-1-alter-roles",
    "href": "slides/11-feature-engineering.html#step-1-alter-roles",
    "title": "Feature engineering",
    "section": "Step 1: Alter roles",
    "text": "Step 1: Alter roles\ntitle isnâ€™t a predictor, but we might want to keep it around as an ID\n\noffice_rec <- office_rec |>\n  update_role(title, new_role = \"ID\")\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4"
  },
  {
    "objectID": "slides/11-feature-engineering.html#step-2-add-features",
    "href": "slides/11-feature-engineering.html#step-2-add-features",
    "title": "Feature engineering",
    "section": "Step 2: Add features",
    "text": "Step 2: Add features\nNew features for day of week and month\n\noffice_rec <- office_rec |>\n  step_date(air_date, features = c(\"dow\", \"month\"))\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date"
  },
  {
    "objectID": "slides/11-feature-engineering.html#step-3-add-more-features",
    "href": "slides/11-feature-engineering.html#step-3-add-more-features",
    "title": "Feature engineering",
    "section": "Step 3: Add more features",
    "text": "Step 3: Add more features\nIdentify holidays in air_date, then remove air_date\n\noffice_rec <- office_rec |>\n  step_holiday(\n    air_date, \n    holidays = c(\"USThanksgivingDay\", \"USChristmasDay\", \"USNewYearsDay\", \"USIndependenceDay\"), \n    keep_original_cols = FALSE\n  )\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date"
  },
  {
    "objectID": "slides/11-feature-engineering.html#step-4-convert-numbers-to-factors",
    "href": "slides/11-feature-engineering.html#step-4-convert-numbers-to-factors",
    "title": "Feature engineering",
    "section": "Step 4: Convert numbers to factors",
    "text": "Step 4: Convert numbers to factors\nConvert season to factor\n\noffice_rec <- office_rec |>\n  step_num2factor(season, levels = as.character(1:9))\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date\nFactor variables from season"
  },
  {
    "objectID": "slides/11-feature-engineering.html#step-5-make-dummy-variables",
    "href": "slides/11-feature-engineering.html#step-5-make-dummy-variables",
    "title": "Feature engineering",
    "section": "Step 5: Make dummy variables",
    "text": "Step 5: Make dummy variables\nConvert all nominal (categorical) predictors to factors\n\noffice_rec <- office_rec |>\n  step_dummy(all_nominal_predictors())\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date\nFactor variables from season\nDummy variables from all_nominal_predictors()"
  },
  {
    "objectID": "slides/11-feature-engineering.html#step-6-remove-zero-variance-predictors",
    "href": "slides/11-feature-engineering.html#step-6-remove-zero-variance-predictors",
    "title": "Feature engineering",
    "section": "Step 6: Remove zero variance predictors",
    "text": "Step 6: Remove zero variance predictors\nRemove all predictors that contain only a single value\n\noffice_rec <- office_rec |>\n  step_zv(all_predictors())\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date\nFactor variables from season\nDummy variables from all_nominal_predictors()\nZero variance filter on all_predictors()"
  },
  {
    "objectID": "slides/11-feature-engineering.html#putting-it-all-together",
    "href": "slides/11-feature-engineering.html#putting-it-all-together",
    "title": "Feature engineering",
    "section": "Putting it all together",
    "text": "Putting it all together\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) |>\n  # make title's role ID\n  update_role(title, new_role = \"ID\") |>\n  # extract day of week and month of air_date\n  step_date(air_date, features = c(\"dow\", \"month\")) |>\n  # identify holidays and add indicators\n  step_holiday(\n    air_date, \n    holidays = c(\"USThanksgivingDay\", \"USChristmasDay\", \"USNewYearsDay\", \"USIndependenceDay\"), \n    keep_original_cols = FALSE\n  ) |>\n  # turn season into factor\n  step_num2factor(season, levels = as.character(1:9)) |>\n  # make dummy variables\n  step_dummy(all_nominal_predictors()) |>\n  # remove zero variance predictors\n  step_zv(all_predictors())"
  },
  {
    "objectID": "slides/11-feature-engineering.html#putting-it-all-together-1",
    "href": "slides/11-feature-engineering.html#putting-it-all-together-1",
    "title": "Feature engineering",
    "section": "Putting it all together",
    "text": "Putting it all together\n\noffice_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          1\n   outcome          1\n predictor          4\n\nOperations:\n\nDate features from air_date\nHoliday features from air_date\nFactor variables from season\nDummy variables from all_nominal_predictors()\nZero variance filter on all_predictors()"
  },
  {
    "objectID": "slides/11-feature-engineering.html#next-step",
    "href": "slides/11-feature-engineering.html#next-step",
    "title": "Feature engineering",
    "section": "Next stepâ€¦",
    "text": "Next stepâ€¦\nWe will complete the workflow to fit a model predicting IMDB ratings that includes the following predictors:\n\nepisode\ntotal_votes\nindicator variables for season\nindicator variables for day of week aired (created using air_date)\nindicator variables for month aired (created using air_date)\n\n\n\nWhat feature will not end up in the final model? Why is it not included?"
  },
  {
    "objectID": "slides/11-feature-engineering.html#recap",
    "href": "slides/11-feature-engineering.html#recap",
    "title": "Feature engineering",
    "section": "Recap",
    "text": "Recap\n\n\nReview: Training and testing splits\nFeature engineering with recipes\n\n\n\n\n\nðŸ”— Week 06"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#announcements",
    "href": "slides/05-slr-sim-inference.html#announcements",
    "title": "SLR: Simulation-based inference",
    "section": "Announcements",
    "text": "Announcements\n\nLab 01 due\n\nTODAY, 11:59pm (Thursday labs)\nTuesday, 11:59pm (Friday labs)\nMake sure all work is pushed to GitHub and the PDF is submitted on Gradescope by the deadline\n\n\n\n\nSee Week 03 for this weekâ€™s activities."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#topics",
    "href": "slides/05-slr-sim-inference.html#topics",
    "title": "SLR: Simulation-based inference",
    "section": "Topics",
    "text": "Topics\n\nAssess modelâ€™s predictive importance using data splitting and bootstrapping\nFind range of plausible values for the slope using bootstrap confidence intervals"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#computational-setup",
    "href": "slides/05-slr-sim-inference.html#computational-setup",
    "title": "SLR: Simulation-based inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#uninsurance-vs.-hs-graduation-rates",
    "href": "slides/05-slr-sim-inference.html#uninsurance-vs.-hs-graduation-rates",
    "title": "SLR: Simulation-based inference",
    "section": "Uninsurance vs.Â HS graduation rates",
    "text": "Uninsurance vs.Â HS graduation rates\n\n\n\n\n\nCode\nggplot(county_2019_nc, aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#8F2D56\") +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  )"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#fitting-the-model",
    "href": "slides/05-slr-sim-inference.html#fitting-the-model",
    "title": "SLR: Simulation-based inference",
    "section": "Fitting the model",
    "text": "Fitting the model\n\nnc_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(uninsured ~ hs_grad, data = county_2019_nc)\n\ntidy(nc_fit)\n\n# A tibble: 2 Ã— 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   33.9      3.99        8.50 2.12e-13\n2 hs_grad       -0.262    0.0468     -5.61 1.88e- 7"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#augmenting-the-data",
    "href": "slides/05-slr-sim-inference.html#augmenting-the-data",
    "title": "SLR: Simulation-based inference",
    "section": "Augmenting the data",
    "text": "Augmenting the data\nWith augment() to add columns for predicted values (.fitted), residuals (.resid), etc.:\n\nnc_aug <- augment(nc_fit$fit)\nnc_aug\n\n# A tibble: 100 Ã— 8\n   uninsured hs_grad .fitted  .resid   .hat .sigma    .cooksd .std.resid\n       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>      <dbl>      <dbl>\n 1      11.2    86.3   11.3  -0.0633 0.0107   2.10 0.00000501    -0.0305\n 2       8.9    82.4   12.3  -3.39   0.0138   2.07 0.0186        -1.63  \n 3      11.3    77.5   13.6  -2.27   0.0393   2.09 0.0252        -1.11  \n 4      11.1    80.7   12.7  -1.63   0.0199   2.09 0.00633       -0.790 \n 5      12.6    85.1   11.6   1.02   0.0100   2.10 0.00122        0.492 \n 6      15.9    83.6   12.0   3.93   0.0112   2.06 0.0203         1.89  \n 7      12      87.7   10.9   1.10   0.0133   2.10 0.00191        0.532 \n 8      11.9    78.4   13.3  -1.44   0.0328   2.09 0.00830       -0.700 \n 9      12.9    81.3   12.6   0.324  0.0174   2.10 0.000218       0.157 \n10       9.8    91.3    9.95 -0.151  0.0291   2.10 0.0000806     -0.0734\n# â€¦ with 90 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#statistics-for-model-evaluation",
    "href": "slides/05-slr-sim-inference.html#statistics-for-model-evaluation",
    "title": "SLR: Simulation-based inference",
    "section": "Statistics for model evaluation",
    "text": "Statistics for model evaluation\n\n\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\\[\nR^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n\\]\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n\\]"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#obtaining-r2-and-rmse",
    "href": "slides/05-slr-sim-inference.html#obtaining-r2-and-rmse",
    "title": "SLR: Simulation-based inference",
    "section": "Obtaining \\(R^2\\) and RMSE",
    "text": "Obtaining \\(R^2\\) and RMSE\n\nUse rsq() and rmse(), respectively\n\nrsq(nc_aug, truth = uninsured, estimate = .fitted)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.243\n\nrmse(nc_aug, truth = uninsured, estimate = .fitted)\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        2.07"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#purpose-of-model-evaluation",
    "href": "slides/05-slr-sim-inference.html#purpose-of-model-evaluation",
    "title": "SLR: Simulation-based inference",
    "section": "Purpose of model evaluation",
    "text": "Purpose of model evaluation\n\n\\(R^2\\) tells us how our model is doing to predict the data we already have\nBut generally we are interested in prediction for a new observation, not for one that is already in our sample, i.e.Â out-of-sample prediction\nWe have a couple ways of simulating out-of-sample prediction before actually getting new data to evaluate the performance of our models"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#spending-our-data",
    "href": "slides/05-slr-sim-inference.html#spending-our-data",
    "title": "SLR: Simulation-based inference",
    "section": "Spending our data",
    "text": "Spending our data\n\n\nThere are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\nDoing all of this on the entire data we have available leaves us with no other data to assess our choices\nWe can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what weâ€™ve done so far)"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#simulation-data-splitting",
    "href": "slides/05-slr-sim-inference.html#simulation-data-splitting",
    "title": "SLR: Simulation-based inference",
    "section": "Simulation: data splitting",
    "text": "Simulation: data splitting\n\n\n\n\nTake a random sample of 10% of the data and set aside (testing data)\nFit a model on the remaining 90% of the data (training data)\nUse the coefficients from this model to make predictions for the testing data\nRepeat 10 times"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#predictive-performance",
    "href": "slides/05-slr-sim-inference.html#predictive-performance",
    "title": "SLR: Simulation-based inference",
    "section": "Predictive performance",
    "text": "Predictive performance\n\n\n\n\n\nHow consistent are the predictions for different testing datasets?\nHow consistent are the predictions for counties with high school graduation rates in the middle of the plot vs.Â in the edges?"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#bootstrapping-our-data",
    "href": "slides/05-slr-sim-inference.html#bootstrapping-our-data",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrapping our data",
    "text": "Bootstrapping our data\n\n\nThe idea behind bootstrapping is that if a given observation exists in a sample, there may be more like it in the population\nWith bootstrapping, we simulate resampling from the population by resampling from the sample we observed\nBootstrap samples are the sampled with replacement from the original sample and same size as the original sample\n\nFor example, if our sample consists of the observations {A, B, C}, bootstrap samples could be {A, A, B}, {A, C, A}, {B, C, C}, {A, B, C}, etc."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#simulation-bootstrapping",
    "href": "slides/05-slr-sim-inference.html#simulation-bootstrapping",
    "title": "SLR: Simulation-based inference",
    "section": "Simulation: bootstrapping",
    "text": "Simulation: bootstrapping\n\n\n\n\nTake a bootstrap sample â€“ sample with replacement from the original data, same size as the original data\nFit model to the sample and make predictions for that sample\nRepeat many times"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#predictive-performance-1",
    "href": "slides/05-slr-sim-inference.html#predictive-performance-1",
    "title": "SLR: Simulation-based inference",
    "section": "Predictive performance",
    "text": "Predictive performance\n\n\n\n\n\nHow consistent are the predictions for different bootstrap datasets?\nHow consistent are the predictions for counties with high school graduation rates in the middle of the plot vs.Â in the edges?"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#recap",
    "href": "slides/05-slr-sim-inference.html#recap",
    "title": "SLR: Simulation-based inference",
    "section": "Recap",
    "text": "Recap\n\nMotivated the importance of model evaluation\nDescribed how \\(R^2\\) and RMSE are used to evaluate models\nAssessed modelâ€™s predictive importance using data splitting and bootstrapping"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#data-houses-in-duke-forest",
    "href": "slides/05-slr-sim-inference.html#data-houses-in-duke-forest",
    "title": "SLR: Simulation-based inference",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#exploratory-data-analysis",
    "href": "slides/05-slr-sim-inference.html#exploratory-data-analysis",
    "title": "SLR: Simulation-based inference",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\nCode\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#modeling",
    "href": "slides/05-slr-sim-inference.html#modeling",
    "title": "SLR: Simulation-based inference",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |>\n  kable(digits = 2) #neatly format table to 2 digits\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    116652.33 \n    53302.46 \n    2.19 \n    0.03 \n  \n  \n    area \n    159.48 \n    18.17 \n    8.78 \n    0.00 \n  \n\n\n\n\n\n\n\n\n\n\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, on average, for $116,652.\nSlope: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#from-sample-to-population",
    "href": "slides/05-slr-sim-inference.html#from-sample-to-population",
    "title": "SLR: Simulation-based inference",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if weâ€™re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#statistical-inference",
    "href": "slides/05-slr-sim-inference.html#statistical-inference",
    "title": "SLR: Simulation-based inference",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical inference provide methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be random and representative of the population weâ€™re interested in"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#inference-for-simple-linear-regression",
    "href": "slides/05-slr-sim-inference.html#inference-for-simple-linear-regression",
    "title": "SLR: Simulation-based inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope,\\(\\beta_1\\)"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#confidence-interval",
    "href": "slides/05-slr-sim-inference.html#confidence-interval",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval",
    "text": "Confidence interval\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#confidence-interval-for-the-slope-1",
    "href": "slides/05-slr-sim-inference.html#confidence-interval-for-the-slope-1",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like â€œFor each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.â€\n\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#quantify-the-variability-of-the-slope",
    "href": "slides/05-slr-sim-inference.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Simulation-based inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\n\nTwo approaches:\n\nVia simulation (what weâ€™ll do today)\nVia mathematical models (what weâ€™ll do in the next class)\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#bootstrap-sample-1",
    "href": "slides/05-slr-sim-inference.html#bootstrap-sample-1",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#bootstrap-sample-2",
    "href": "slides/05-slr-sim-inference.html#bootstrap-sample-2",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#bootstrap-sample-3",
    "href": "slides/05-slr-sim-inference.html#bootstrap-sample-3",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#bootstrap-sample-4",
    "href": "slides/05-slr-sim-inference.html#bootstrap-sample-4",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#bootstrap-sample-5",
    "href": "slides/05-slr-sim-inference.html#bootstrap-sample-5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nso on and so forthâ€¦"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#bootstrap-samples-1---5",
    "href": "slides/05-slr-sim-inference.html#bootstrap-samples-1---5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#bootstrap-samples-1---100",
    "href": "slides/05-slr-sim-inference.html#bootstrap-samples-1---100",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#slopes-of-bootstrap-samples",
    "href": "slides/05-slr-sim-inference.html#slopes-of-bootstrap-samples",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#slopes-of-bootstrap-samples-1",
    "href": "slides/05-slr-sim-inference.html#slopes-of-bootstrap-samples-1",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#confidence-level",
    "href": "slides/05-slr-sim-inference.html#confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#confidence-interval-1",
    "href": "slides/05-slr-sim-inference.html#confidence-interval-1",
    "title": "SLR: Simulation-based inference",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#application-exercise",
    "href": "slides/05-slr-sim-inference.html#application-exercise",
    "title": "SLR: Simulation-based inference",
    "section": "Application exercise",
    "text": "Application exercise\n\nðŸ“‹ AE 03: Bootstrap confidence intervals"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#computing-the-ci-for-the-slope-i",
    "href": "slides/05-slr-sim-inference.html#computing-the-ci-for-the-slope-i",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit <- duke_forest |>\n  specify(price ~ area) |>\n  fit()\n\nobserved_fit\n\n# A tibble: 2 Ã— 2\n  term      estimate\n  <chr>        <dbl>\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/05-slr-sim-inference.html#computing-the-ci-for-the-slope-ii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits <- duke_forest |>\n  specify(price ~ area) |>\n  generate(reps = 100, type = \"bootstrap\") |>\n  fit()\n\nboot_fits\n\n# A tibble: 200 Ã— 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       <int> <chr>        <dbl>\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# â€¦ with 190 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/05-slr-sim-inference.html#computing-the-ci-for-the-slope-iii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#computing-the-ci-for-the-slope-iv",
    "href": "slides/05-slr-sim-inference.html#computing-the-ci-for-the-slope-iv",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope IV",
    "text": "Computing the CI for the slope IV\nStandard error method: Alternatively, compute the 95% CI as the point estimate \\(\\pm\\) ~2 standard deviations of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"se\"\n)\n\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          90.8     228.\n2 intercept -56788.   290093."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#precision-vs.-accuracy",
    "href": "slides/05-slr-sim-inference.html#precision-vs.-accuracy",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs.Â accuracy",
    "text": "Precision vs.Â accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#precision-vs.-accuracy-1",
    "href": "slides/05-slr-sim-inference.html#precision-vs.-accuracy-1",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs.Â accuracy",
    "text": "Precision vs.Â accuracy\n\nHow can we get best of both worlds â€“ high precision and high accuracy?"
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#changing-confidence-level",
    "href": "slides/05-slr-sim-inference.html#changing-confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#changing-confidence-level-1",
    "href": "slides/05-slr-sim-inference.html#changing-confidence-level-1",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/05-slr-sim-inference.html#recap-1",
    "href": "slides/05-slr-sim-inference.html#recap-1",
    "title": "SLR: Simulation-based inference",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we canâ€™t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability\n\n\n\n\nðŸ”— Week 03"
  },
  {
    "objectID": "slides/02-slr-intro.html#announcements",
    "href": "slides/02-slr-intro.html#announcements",
    "title": "Simple Linear Regression",
    "section": "Announcements",
    "text": "Announcements\n\nR Resources page updated on the course website\nUpcoming R workshops by Duke Center for Data and Visualization Sciences:\n\nâ€‹R for data science: getting started, EDA, data wrangling - Thu, Sep 15 at 1pm\nR for data science: visualization, pivot, join, regression - Thu, Sep 22 at 1pm\n\nPolicyon requesting class recordings\nSee Week 01 for lecture notes, readings, AEs, and assignments"
  },
  {
    "objectID": "slides/02-slr-intro.html#meet-your-neighbor",
    "href": "slides/02-slr-intro.html#meet-your-neighbor",
    "title": "Simple Linear Regression",
    "section": "Meet your neighbor",
    "text": "Meet your neighbor\nTake a few moments to meet or (reconnect with) your neighbor!\n\nName\nYear\nMajor\nA highlight or something that stood out in the first two days of class\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/02-slr-intro.html#topics",
    "href": "slides/02-slr-intro.html#topics",
    "title": "Simple Linear Regression",
    "section": "Topics",
    "text": "Topics\n\n\nUse simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nEstimate the slope and intercept of the regression line using the least squares method.\nInterpret the slope and intercept of the regression line.\nPredict the response given a value of the predictor variable.\nDefined extrapolation and why we should avoid it."
  },
  {
    "objectID": "slides/02-slr-intro.html#computation-set-up",
    "href": "slides/02-slr-intro.html#computation-set-up",
    "title": "Simple Linear Regression",
    "section": "Computation set up",
    "text": "Computation set up\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(fivethirtyeight) # for the fandango dataset\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/02-slr-intro.html#movie-ratings",
    "href": "slides/02-slr-intro.html#movie-ratings",
    "title": "Simple Linear Regression",
    "section": "Movie ratings",
    "text": "Movie ratings\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandangoâ€™s\nIn the fivethirtyeight package: fandango\nContains every film that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/02-slr-intro.html#data-prep",
    "href": "slides/02-slr-intro.html#data-prep",
    "title": "Simple Linear Regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores <- fandango |>\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)"
  },
  {
    "objectID": "slides/02-slr-intro.html#data-overview",
    "href": "slides/02-slr-intro.html#data-overview",
    "title": "Simple Linear Regression",
    "section": "Data overview",
    "text": "Data overview\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 23\n$ film                       <chr> \"Avengers: Age of Ultron\", \"Cinderella\", \"Aâ€¦\n$ year                       <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2â€¦\n$ critics                    <int> 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84,â€¦\n$ audience                   <int> 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77,â€¦\n$ metacritic                 <int> 66, 67, 64, 22, 29, 50, 53, 81, 81, 80, 71,â€¦\n$ metacritic_user            <dbl> 7.1, 7.5, 8.1, 4.7, 3.4, 6.8, 7.6, 6.8, 8.8â€¦\n$ imdb                       <dbl> 7.8, 7.1, 7.8, 5.4, 5.1, 7.2, 6.9, 6.5, 7.4â€¦\n$ fandango_stars             <dbl> 5.0, 5.0, 5.0, 5.0, 3.5, 4.5, 4.0, 4.0, 4.5â€¦\n$ fandango_ratingvalue       <dbl> 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 3.5, 3.5, 4.0â€¦\n$ rt_norm                    <dbl> 3.70, 4.25, 4.00, 0.90, 0.70, 3.15, 2.10, 4â€¦\n$ rt_user_norm               <dbl> 4.30, 4.00, 4.50, 4.20, 1.40, 3.10, 2.65, 3â€¦\n$ metacritic_norm            <dbl> 3.30, 3.35, 3.20, 1.10, 1.45, 2.50, 2.65, 4â€¦\n$ metacritic_user_nom        <dbl> 3.55, 3.75, 4.05, 2.35, 1.70, 3.40, 3.80, 3â€¦\n$ imdb_norm                  <dbl> 3.90, 3.55, 3.90, 2.70, 2.55, 3.60, 3.45, 3â€¦\n$ rt_norm_round              <dbl> 3.5, 4.5, 4.0, 1.0, 0.5, 3.0, 2.0, 4.5, 5.0â€¦\n$ rt_user_norm_round         <dbl> 4.5, 4.0, 4.5, 4.0, 1.5, 3.0, 2.5, 3.0, 4.0â€¦\n$ metacritic_norm_round      <dbl> 3.5, 3.5, 3.0, 1.0, 1.5, 2.5, 2.5, 4.0, 4.0â€¦\n$ metacritic_user_norm_round <dbl> 3.5, 4.0, 4.0, 2.5, 1.5, 3.5, 4.0, 3.5, 4.5â€¦\n$ imdb_norm_round            <dbl> 4.0, 3.5, 4.0, 2.5, 2.5, 3.5, 3.5, 3.5, 3.5â€¦\n$ metacritic_user_vote_count <int> 1330, 249, 627, 31, 88, 34, 17, 124, 62, 54â€¦\n$ imdb_user_vote_count       <int> 271107, 65709, 103660, 3136, 19560, 39373, â€¦\n$ fandango_votes             <int> 14846, 12640, 12055, 1793, 1021, 397, 252, â€¦\n$ fandango_difference        <dbl> 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5â€¦"
  },
  {
    "objectID": "slides/02-slr-intro.html#movie-ratings-data",
    "href": "slides/02-slr-intro.html#movie-ratings-data",
    "title": "Simple Linear Regression",
    "section": "Movie ratings data",
    "text": "Movie ratings data\nThe data set contains the â€œTomatometerâ€ score (critics) and audience score (audience) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/02-slr-intro.html#movie-ratings-data-1",
    "href": "slides/02-slr-intro.html#movie-ratings-data-1",
    "title": "Simple Linear Regression",
    "section": "Movie ratings data",
    "text": "Movie ratings data\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/02-slr-intro.html#why-fit-a-line",
    "href": "slides/02-slr-intro.html#why-fit-a-line",
    "title": "Simple Linear Regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n\n\nPrediction\n\nWhat is the audience score expected to be for an upcoming movie that received 35% from the critics?\n\n\n\n\nInference\n\nIs the critics score a useful predictor of the audience score? By how much is the audience score expected to change for each additional point in the critics score?"
  },
  {
    "objectID": "slides/02-slr-intro.html#terminology",
    "href": "slides/02-slr-intro.html#terminology",
    "title": "Simple Linear Regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, Y: variable describing the outcome of interest\nPredictor, X: variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/02-slr-intro.html#regression-model",
    "href": "slides/02-slr-intro.html#regression-model",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr-intro.html#regression-model-1",
    "href": "slides/02-slr-intro.html#regression-model-1",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mu_{Y|X}\\) is the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/02-slr-intro.html#regression-model-2",
    "href": "slides/02-slr-intro.html#regression-model-2",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[5pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[5pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[5pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr-intro.html#simple-linear-regression-1",
    "href": "slides/02-slr-intro.html#simple-linear-regression-1",
    "title": "Simple Linear Regression",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\). \\[\\Large{Y = \\mathbf{\\beta_0 + \\beta_1 X} + \\epsilon}\\]\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error"
  },
  {
    "objectID": "slides/02-slr-intro.html#simple-linear-regression-2",
    "href": "slides/02-slr-intro.html#simple-linear-regression-2",
    "title": "Simple Linear Regression",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\\Large{\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X}\\]\n\n\\(\\hat{\\beta}_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!"
  },
  {
    "objectID": "slides/02-slr-intro.html#choosing-values-for-hatbeta_1-and-hatbeta_0",
    "href": "slides/02-slr-intro.html#choosing-values-for-hatbeta_1-and-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Choosing values for \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Choosing values for \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/02-slr-intro.html#residuals",
    "href": "slides/02-slr-intro.html#residuals",
    "title": "Simple Linear Regression",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\\]"
  },
  {
    "objectID": "slides/02-slr-intro.html#least-squares-line",
    "href": "slides/02-slr-intro.html#least-squares-line",
    "title": "Simple Linear Regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/02-slr-intro.html#properties-of-least-squares-regression",
    "href": "slides/02-slr-intro.html#properties-of-least-squares-regression",
    "title": "Simple Linear Regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(X\\) and average \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/02-slr-intro.html#estimating-the-slope",
    "href": "slides/02-slr-intro.html#estimating-the-slope",
    "title": "Simple Linear Regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\\begin{aligned}\ns_X &= 30.1688 \\\\\ns_Y &=  20.0244 \\\\\nr &= 0.7814\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\n\\hat{\\beta}_1 &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\\n&= 0.5187\\end{aligned}\\]\n\n\n\n\nClick here for details on deriving the equations for slope and intercept."
  },
  {
    "objectID": "slides/02-slr-intro.html#estimating-the-intercept",
    "href": "slides/02-slr-intro.html#estimating-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}\\]\n\n\n\\[\\begin{aligned}\n&\\bar{x} = 60.8493 \\\\\n&\\bar{y} = 63.8767 \\\\\n&\\hat{\\beta}_1 = 0.5187\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= 32.3142\n\\end{aligned}\\]\n\n\n\n\nClick here for details on deriving the equations for slope and intercept."
  },
  {
    "objectID": "slides/02-slr-intro.html#interpretation",
    "href": "slides/02-slr-intro.html#interpretation",
    "title": "Simple Linear Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\n\nPost your answers to the following questions on Ed Discussion:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n\n\n\nLink for Section 001 (10:15am lecture)\nLink for Section 002 (3:30pm lecture)\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/02-slr-intro.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/02-slr-intro.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n\nâœ… The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n\n\nðŸ›‘ Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/02-slr-intro.html#making-a-prediction",
    "href": "slides/02-slr-intro.html#making-a-prediction",
    "title": "Simple Linear Regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movieâ€™s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= 68.6232\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr-intro.html#extrapolation",
    "href": "slides/02-slr-intro.html#extrapolation",
    "title": "Simple Linear Regression",
    "section": "âš ï¸ Extrapolation",
    "text": "âš ï¸ Extrapolation\n\nUsing the model to predict for values outside the range of the original data is extrapolation.\n\n\n\n\nSuppose that a movie has a critics score of 0. According to this model, what is the movieâ€™s predicted audience score?"
  },
  {
    "objectID": "slides/02-slr-intro.html#recap",
    "href": "slides/02-slr-intro.html#recap",
    "title": "Simple Linear Regression",
    "section": "Recap",
    "text": "Recap\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nUsed the least squares method to estimate the slope and intercept.\nWe interpreted the slope and intercept.\n\nSlope: For every one unit increase in \\(x\\), we expect y to change by \\(\\hat{\\beta}_1\\) units, on average.\nIntercept: If \\(x\\) is 0, then we expect \\(y\\) to be \\(\\hat{\\beta}_0\\) units\n\nPredicted the response given a value of the predictor variable.\nDefined extrapolation and why we should avoid it."
  },
  {
    "objectID": "slides/02-slr-intro.html#next-class",
    "href": "slides/02-slr-intro.html#next-class",
    "title": "Simple Linear Regression",
    "section": "Next class",
    "text": "Next class\nWe will talk about fitting linear models in R with tidymodels.\n\nReserve STA 210 Docker Container before Mondayâ€™s lecture\nComplete the STA 210 Student Survey (will ask for a GitHub username) by Friday at 11:59pm\n\n\n\n\nðŸ”— Week 01"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\nðŸ”— on Duke Container Manager\n\n\nCourse GitHub organization\nðŸ”— on GitHub\n\n\nDiscussion forum\nðŸ”— on Ed Discussion\n\n\nGradescope (Section 001)\nðŸ”— on Sakai\n\n\nGradescope (Section 002)\nðŸ”— on Sakai\n\n\nZoom links\nðŸ”— on Sakai"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF of the syllabus."
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\n\n\n\n\n\nLecture\nSection 01\nMon & Wed 10:15 - 11:30 am\nReuben-Cooke 130\n\n\n\nSection 02\nMon & Wed 3:30 - 4:45pm\nSocial Sciences 136\n\n\nLab\nLab 01\nThu 3:30 - 4:45pm\nPerkins Link #5\n\n\n\nLab 02\nThu 5:15 - 6:30pm\nPerkins Link #5\n\n\n\nLab 03\nFri 12 - 1:15pm\nPerkins Link #5\n\n\n\nLab 04\nFri 1:45 - 3pm\nOld Chemistry 003"
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\nBy the end of the semester, you will be able toâ€¦\n\nanalyze real-world data to answer questions about multivariable relationships.\nfit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nuse Quarto to write reproducible reports and GitHub for version control and collaboration.\ncommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that studentsâ€™ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Dukeâ€™s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please donâ€™t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, sta210-fa22.netlify.app.\nAnnouncements will be emailed through Sakai Announcements periodically. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nGetting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\n\n\nEmail\nIf there is a question thatâ€™s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include â€œSTA 210â€ in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\nCheck out the Support page for more resources."
  },
  {
    "objectID": "syllabus.html#textbook",
    "href": "syllabus.html#textbook",
    "title": "Syllabus",
    "section": "Textbook",
    "text": "Textbook\nWhile there is no official textbook for the course, readings will primarily be assigned from the following texts (all freely available online).\n\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine Ã‡etinkaya-Rundel and Johanna Hardin\nTidy modeling with R by Max Kuhn and Julia Silge\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler"
  },
  {
    "objectID": "syllabus.html#lectures-and-labs",
    "href": "syllabus.html#lectures-and-labs",
    "title": "Syllabus",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nThe goal of both the lectures and the labs is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to prepare for lectures by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded for completion.\nYou are expected to bring a laptop, tablet, or Chromebook to each class so that you can take part in the in-class exercises. Please make sure your device is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone."
  },
  {
    "objectID": "syllabus.html#teams",
    "href": "syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the labs and project and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the teamâ€™s overall mark.\nYou are expected to make use of the provided GitHub repository as their central collaborative platform. Commits to this repository will be used as a metric (one of several) of each team memberâ€™s relative contribution for each project."
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on six components: application exercises, homework, labs, exams, project, and teamwork.\n\nApplication Exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the prepare assignment. These AEs are due within three days of the corresponding lecture period. Specifically, AEs from Monday lectures are due Thursday by 11:59p ET, and AEs from Wednesday lectures are due Saturday by 11:59p ET.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the teamâ€™s Git repository on the courseâ€™s GitHub page as the central platform for collaboration. Commits to this repository will be used as a metric of each team memberâ€™s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what youâ€™ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material youâ€™re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two take-home, open-note exams. Through these exams you have the opportunity to demonstrate what youâ€™ve learned in the course thus far. The exams will focus on both conceptual understanding of the content and application through analysis and computational tasks. The content of the exam will be related to the content in reading assignments, lectures, application exercises, homeworks, and labs. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the final project is to apply what youâ€™ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n35%\n\n\nFinal project\n15%\n\n\nLab\n15%\n\n\nExam 01\n15%\n\n\nExam 02\n15%\n\n\nApplication Exercises\n2.5%\n\n\nTeamwork\n2.5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If youâ€™re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework and lab.The earlier you start, the better. Itâ€™s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDonâ€™t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Donâ€™t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Donâ€™t cheat!\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity(e.g., completing oneâ€™s own work, following proper citation of sources,adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nCollaboration policy\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss whatâ€™s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g.Â StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\n\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work is accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email Professor Tackett before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let Professor Tackett know if you need help contacting your academic dean.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nClass recordings request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week. To request a particular lectureâ€™s video, please fill out the form at https://forms.office.com/r/qU8ANXb6tB.\nPlease also make sure that any official documentation, such as STINFs, Deanâ€™s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\nAbout one week before each exam, the class recordings will be available to all students. These videos will be available until the exam deadline.\n\n\n\nAttendance policy\n\nCOVID Symptoms, Exposure, or Infection: Student health, safety, and well-being are the universityâ€™s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19or have possible symptoms and have not yet been tested.If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919-681-9355). Learn more about current university policy related to COVID-19 at coronavirus.duke.edu.\nReligious accommodations: Students are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays"
  },
  {
    "objectID": "syllabus.html#academic-and-wellness-support",
    "href": "syllabus.html#academic-and-wellness-support",
    "title": "Syllabus",
    "section": "Academic and wellness support",
    "text": "Academic and wellness support\n\nAcademic Resource Center\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.\n\n\nCAPS\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000."
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAug 29: Classes begin\nSep 9: Drop/add ends\nOct 10 - 11: Fall break\nNov 11 Last day to withdraw with W\nNov 23 - 25: Thanksgiving recess\nDec 9: Classes end\nDec 10 - 13 Reading period\nDec 14 - 19: Final exams\n\nClick here for the full Duke academic calendar."
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if itâ€™s been resolved. If thereâ€™s a deadline coming up soon, post on the course forum to let us know that thereâ€™s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We donâ€™t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what youâ€™ve tried and the errors you see (including verbatim errors and/or screenshots)."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here."
  },
  {
    "objectID": "schedule.html#weekly-schedule",
    "href": "schedule.html#weekly-schedule",
    "title": "Schedule",
    "section": "Weekly schedule",
    "text": "Weekly schedule\n\n\n\n\n\n\nWeek\n\n\nDates\n\n\nTopic\n\n\nAssignments\n\n\n\n\n\n\nWeek 01\n\n\nAug 29 - Sep 02\n\n\nWelcome to Regression Analysis\n\n\nCompelete STA 210 Student Survey\n\n\n\n\nWeek 02\n\n\nSep 05 - 09\n\n\nSLR: Tidymodels + Model evaluation\n\n\nLab 01, Statistics experience assigned\n\n\n\n\nWeek 03\n\n\nSep 12 - 16\n\n\nSLR: Inference\n\n\nLab 02, HW 01, Statistics experience assigned\n\n\n\n\nWeek 04\n\n\nSep 19 - 23\n\n\nMultiple Linear Regression (MLR)\n\n\nLab 03\n\n\n\n\nWeek 05\n\n\nSep 26 - 30\n\n\nMLR: Types of Predictors\n\n\nExam 01\n\n\n\n\nWeek 06\n\n\nOct 03 - 07\n\n\nFeature Engineering\n\n\nLab 04\n\n\n\n\nWeek 07\n\n\nOct 10 - 14\n\n\nVariable transformations\n\n\nIntroduce project, HW 02\n\n\n\n\nWeek 08\n\n\nOct 17 - 21\n\n\nModel evaluation\n\n\nLab 05\n\n\n\n\nWeek 09\n\n\nOct 24 - 28\n\n\nMLR: Inference\n\n\nLab 06, HW 03\n\n\n\n\nWeek 10\n\n\nOct 31 - Nov 04\n\n\nOdds + Odds Ratios\n\n\nLab 07\n\n\n\n\nWeek 11\n\n\nNov 07 - 11\n\n\nLogistic regression (LR)\n\n\nProject peer review, HW 04\n\n\n\n\nWeek 12\n\n\nNov 14 - 18\n\n\nLR: Inference\n\n\nLab 08\n\n\n\n\nWeek 13\n\n\nNov 21 - 25\n\n\nMixed effects models\n\n\n\n\n\n\n\nWeek 14\n\n\nNov 28 - Dec 02\n\n\nMixed effects models\n\n\nExam 02\n\n\n\n\nWeek 15\n\n\nDec 05 - 09\n\n\nLooking ahead\n\n\nStatistics experience due\n\n\n\n\nWeek 16\n\n\nDec 12 - 19\n\n\nFinal exam period\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html#notes",
    "href": "schedule.html#notes",
    "title": "Schedule",
    "section": "Notes",
    "text": "Notes\n\nHomework will be due on Wednesdays at 11:59pm. You will have one week to complete each homework assignment.\nLab:\n\nLab sections 01 & 02 (Thursdays): Labs will be due on Mondays at 11:59pm.\nLab sections 03 & 04 (Fridays): Labs will be due on Tuesdays at 11:59pm.\n\nProject dates will be added when the project is assigned."
  }
]