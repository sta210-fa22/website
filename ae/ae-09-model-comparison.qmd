---
title: "AE 09: Model comparison"
subtitle: "Restaurant tips"
date: "Oct 19, 2022"
editor: visual
---

::: callout-important
Go to the [course GitHub organization](https://github.com/sta210-fa22) and locate your `ae-09`- to get started.

The AE is due on GitHub by Saturday, October 22 at 11:59pm.
:::

## Packages

```{r load-packages}
#| message: false
library(tidyverse)
library(tidymodels)
library(viridis)
library(knitr)
library(patchwork)
```

## Load data

```{r}
#| message: false
tips <- read_csv("data/tip-data.csv") |>
  filter(!is.na(Party))
```

```{r}
# relevel factors
tips <- tips |>
  mutate(
    Meal = fct_relevel(Meal, "Lunch", "Dinner", "Late Night"),
    Age  = fct_relevel(Age, "Yadult", "Middle", "SenCit")
  )
```

## Exploratory data analysis

### Response variable

```{r}
ggplot(tips, aes(x = Tip)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Distribution of tips")
```

### Predictor variables

```{r}
p1 <- ggplot(tips, aes(x = Party)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Number of people in party")

p2 <- ggplot(tips, aes(x = Meal, fill = Meal)) +
  geom_bar() +
  labs(title = "Meal type") +
  scale_fill_viridis_d()

p3 <- ggplot(tips, aes(x = Age, fill = Age)) +
  geom_bar() +
  labs(title = "Age of payer") +
  scale_fill_viridis_d(option = "E", end = 0.8)

p1 + (p2 / p3)
```

### Response vs. predictors

```{r}
#| fig.width: 12
#| fig.height: 4

p4 <- ggplot(tips, aes(x = Party, y = Tip)) +
  geom_point(color = "#5B888C")

p5 <- ggplot(tips, aes(x = Meal, y = Tip, fill = Meal)) +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_viridis_d()

p6 <- ggplot(tips, aes(x = Age, y = Tip, fill = Age)) +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_viridis_d(option = "E", end = 0.8)

p4 + p5 + p6
```

## Models

### Model 1: Tips vs. Age & Party

```{r}
tip_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(Tip ~ Party + Age, data = tips)

tidy(tip_fit) |>
  kable(digits = 3)
```

### Model 2: Tips vs. Age, Party, Meal & Day

```{r}
tip_fit_2 <- linear_reg() |>
  set_engine("lm") |>
  fit(Tip ~ Party +  Age + Meal +  Day, 
      data = tips)

tidy(tip_fit_2) |>
  kable(digits = 3)
```

::: {.callout-note appearance="minimal" icon="false"}
Why did we not use the full `recipe()` workflow to fit Model 1 or Model 2?
:::

## $R^2$ and Adjusted $R^2$

Fill in the code below to calculate $R^2$ and Adjusted $R^2$ for Model 1. Put `eval: true` once the code is updated.

```{r}
#| eval: false
glance(______) |>
  select(r.squared, adj.r.squared)
```

Calculate $R^2$ and Adjusted $R^2$ for Model 2.

```{r}
# r-sq and adj. r-sq for model 2
```

::: {.callout-note appearance="minimal" icon="false"}
We would like to choose the model that better fits the data.

-   Which model would we choose based on $R^2$?

-   Which model would we choose based on Adjusted $R^2$?

-   Which statistic should we use to choose the final model - $R^2$ or Adjusted $R^2$? Why?
:::

## AIC & BIC

Use the `glance()` function to calculate AIC and BIC for Models 1 and 2.

```{r}
## AIC and BIC for Model 1
```

```{r}
## AIC and BIC for Model 2
```

::: {.callout-note appearance="minimal"}
We would like to choose the model that better fits the data.

-   Which model would we choose based on AIC?

-   Which model would we choose based on BIC?
:::

## Evaluating analysis process

::: {.callout-note appearance="minimal"}
We fit and evaluated these models using the entire data set. What is a limitation to using the entire data set to fit and evaluate models?
:::
